{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHXk_L8g3fDh"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tVH9mlCdXrkw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\胡家豪\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "import math\n",
        "import random\n",
        "from collections import OrderedDict, defaultdict\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import *\n",
        "from torch.optim.lr_scheduler import *\n",
        "import torchvision.models as models\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.datasets import *\n",
        "from torchvision.transforms import *\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "no_cuda = False\n",
        "use_gpu = not no_cuda and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_gpu else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _make_divisible(v, divisor, min_value=None):\n",
        "    \"\"\"\n",
        "    This function is taken from the original tf repo.\n",
        "    It ensures that all layers have a channel number that is divisible by 8\n",
        "    It can be seen here:\n",
        "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
        "    :param v:\n",
        "    :param divisor:\n",
        "    :param min_value:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if min_value is None:\n",
        "        min_value = divisor\n",
        "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "    # Make sure that round down does not go down by more than 10%.\n",
        "    if new_v < 0.9 * v:\n",
        "        new_v += divisor\n",
        "    return new_v\n",
        "\n",
        "class h_sigmoid(nn.Module):\n",
        "    def __init__(self, inplace=True):\n",
        "        super(h_sigmoid, self).__init__()\n",
        "        self.relu = nn.ReLU6(inplace=inplace)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.relu(x + 3) / 6\n",
        "\n",
        "\n",
        "class h_swish(nn.Module):\n",
        "    def __init__(self, inplace=True):\n",
        "        super(h_swish, self).__init__()\n",
        "        self.sigmoid = h_sigmoid(inplace=inplace)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * self.sigmoid(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class SELayer(nn.Module):\n",
        "    def __init__(self, channel, reduction=4):\n",
        "        super(SELayer, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "                nn.Linear(channel, _make_divisible(channel // reduction, 8),bias=False),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(_make_divisible(channel // reduction, 8), channel,bias=False),\n",
        "                nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk1U6PcMXtDB",
        "outputId": "58b165e2-e66b-41c5-987d-4fcc1b6a26fa"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "#Dataset\n",
        "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "#Dataloader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzMtMm9n3hsZ"
      },
      "source": [
        "Create NN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-pKE7xJbOc7",
        "outputId": "fce122fd-5aa8-4d0c-fe2c-94bb60cc64ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ToyModel(\n",
            "  (Conv): Sequential(\n",
            "    (0): Conv2d(1, 5, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): h_swish(\n",
            "      (sigmoid): h_sigmoid(\n",
            "        (relu): ReLU6(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (2): SELayer(\n",
            "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "      (fc): Sequential(\n",
            "        (0): Linear(in_features=5, out_features=8, bias=False)\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Linear(in_features=8, out_features=5, bias=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (3): Conv2d(5, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (4): h_swish(\n",
            "      (sigmoid): h_sigmoid(\n",
            "        (relu): ReLU6(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (backbone): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=120, bias=False)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=120, out_features=84, bias=False)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=84, out_features=10, bias=False)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class ToyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.Conv = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=1, out_channels=5, kernel_size=1, stride=1,padding= 0, bias=True),\n",
        "      h_swish(inplace=True),\n",
        "      SELayer(5),\n",
        "      nn.Conv2d(in_channels=5, out_channels=1, kernel_size=1, stride=1,padding= 0, bias=True),\n",
        "      h_swish(inplace=True)\n",
        "    )  \n",
        "    self.backbone = nn.Sequential(\n",
        "      nn.Linear(28*28, 120, bias=False),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(120, 84, bias=False),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(84, 10, bias=False)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x=self.Conv(x)\n",
        "    x = x.view(-1, 28 * 28) #transform 28*28 figure to 784 vector\n",
        "    x = self.backbone(x)\n",
        "    return x\n",
        "\n",
        "FP32_model = ToyModel()\n",
        "print(FP32_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MOyeqSPDbvr5"
      },
      "outputs": [],
      "source": [
        "#train model\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  #Set the model to train mode\n",
        "  model.train()\n",
        "  for batch, (x, y) in enumerate(dataloader):\n",
        "    if use_gpu:\n",
        "      x, y = x.cuda(), y.cuda()\n",
        "    optimizer.zero_grad()\n",
        "    #forward\n",
        "    pred = model(x)\n",
        "\n",
        "    #loss\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    #backward\n",
        "    loss.backward()\n",
        "\n",
        "    #optimize\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), (batch + 1) * len(x)\n",
        "      print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "  #set model to evaluate mode\n",
        "  model.eval()\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for x, y in dataloader:\n",
        "      if use_gpu:\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "      pred = model(x)\n",
        "      test_loss = loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item() #calculate accuracy\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LsfzIw4b1AU",
        "outputId": "03aeb700-d0fe-4e88-a24e-d000b63c4184"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ToyModel(\n",
              "  (Conv): Sequential(\n",
              "    (0): Conv2d(1, 5, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): h_swish(\n",
              "      (sigmoid): h_sigmoid(\n",
              "        (relu): ReLU6(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (2): SELayer(\n",
              "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "      (fc): Sequential(\n",
              "        (0): Linear(in_features=5, out_features=8, bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Linear(in_features=8, out_features=5, bias=False)\n",
              "        (3): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (3): Conv2d(5, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (4): h_swish(\n",
              "      (sigmoid): h_sigmoid(\n",
              "        (relu): ReLU6(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (backbone): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=120, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=120, out_features=84, bias=False)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=84, out_features=10, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "learning_rate = 1e-3\n",
        "epochs = 3\n",
        "loss_fn = nn.CrossEntropyLoss() #define loss function\n",
        "optimizer = torch.optim.Adam(FP32_model.parameters(), lr=learning_rate)  #define optimizer\n",
        "\n",
        "FP32_model.to(device) #let model on GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LH6kt0eqb9tl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.301034  [   32/60000]\n",
            "loss: 2.298515  [ 3232/60000]\n",
            "loss: 0.732727  [ 6432/60000]\n",
            "loss: 0.697841  [ 9632/60000]\n",
            "loss: 0.479789  [12832/60000]\n",
            "loss: 0.778010  [16032/60000]\n",
            "loss: 0.850822  [19232/60000]\n",
            "loss: 0.400197  [22432/60000]\n",
            "loss: 0.270578  [25632/60000]\n",
            "loss: 0.476100  [28832/60000]\n",
            "loss: 0.479734  [32032/60000]\n",
            "loss: 0.378428  [35232/60000]\n",
            "loss: 0.369649  [38432/60000]\n",
            "loss: 0.454270  [41632/60000]\n",
            "loss: 0.295298  [44832/60000]\n",
            "loss: 0.469126  [48032/60000]\n",
            "loss: 0.606738  [51232/60000]\n",
            "loss: 0.302891  [54432/60000]\n",
            "loss: 0.362274  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 85.4%, Avg loss: 0.000738 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.320355  [   32/60000]\n",
            "loss: 0.468879  [ 3232/60000]\n",
            "loss: 0.421206  [ 6432/60000]\n",
            "loss: 0.350934  [ 9632/60000]\n",
            "loss: 0.383314  [12832/60000]\n",
            "loss: 0.402451  [16032/60000]\n",
            "loss: 0.343051  [19232/60000]\n",
            "loss: 0.355927  [22432/60000]\n",
            "loss: 0.267395  [25632/60000]\n",
            "loss: 0.453346  [28832/60000]\n",
            "loss: 0.363615  [32032/60000]\n",
            "loss: 0.337264  [35232/60000]\n",
            "loss: 0.297007  [38432/60000]\n",
            "loss: 0.236782  [41632/60000]\n",
            "loss: 0.411423  [44832/60000]\n",
            "loss: 0.199472  [48032/60000]\n",
            "loss: 0.156486  [51232/60000]\n",
            "loss: 0.373789  [54432/60000]\n",
            "loss: 0.200534  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.8%, Avg loss: 0.000619 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.170048  [   32/60000]\n",
            "loss: 0.483360  [ 3232/60000]\n",
            "loss: 0.279160  [ 6432/60000]\n",
            "loss: 0.227758  [ 9632/60000]\n",
            "loss: 0.620195  [12832/60000]\n",
            "loss: 0.341477  [16032/60000]\n",
            "loss: 0.338710  [19232/60000]\n",
            "loss: 0.285351  [22432/60000]\n",
            "loss: 0.256278  [25632/60000]\n",
            "loss: 0.223259  [28832/60000]\n",
            "loss: 0.112916  [32032/60000]\n",
            "loss: 0.235341  [35232/60000]\n",
            "loss: 0.373335  [38432/60000]\n",
            "loss: 0.252743  [41632/60000]\n",
            "loss: 0.167118  [44832/60000]\n",
            "loss: 0.437337  [48032/60000]\n",
            "loss: 0.472944  [51232/60000]\n",
            "loss: 0.648263  [54432/60000]\n",
            "loss: 0.140646  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.9%, Avg loss: 0.000380 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Training\n",
        "for i in range(epochs):\n",
        "  print(f\"Epoch {i+1}\\n-------------------------------\")\n",
        "  train_loop(train_loader, FP32_model, loss_fn, optimizer)\n",
        "  test_loop(test_loader, FP32_model, loss_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTAK3-fH3qGh"
      },
      "source": [
        "# Quantization definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lWzxrde4G5i"
      },
      "source": [
        "####Question 1.####\n",
        "\n",
        "Use\n",
        ">$S=(r_{\\mathrm{max}} - r_{\\mathrm{min}}) / (q_{\\mathrm{max}} - q_{\\mathrm{min}})$\n",
        "\n",
        ">$Z = q_{\\mathrm{min}} - r_{\\mathrm{min}} / S$\n",
        "\n",
        "to calculate scale factor and zero point of a tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kJIr-5SpcgQr"
      },
      "outputs": [],
      "source": [
        "def get_scale_and_zero_point(fp32_tensor, bitwidth=8):\n",
        "  q_min, q_max = -(2**(bitwidth-1)), 2**(bitwidth-1) - 1\n",
        "  fp_min = fp32_tensor.min().item()\n",
        "  fp_max = fp32_tensor.max().item()\n",
        "  \n",
        "  #####################################################\n",
        "\n",
        "  scale = (fp_max-fp_min) / (q_max-q_min)\n",
        "  zero_point = q_min-fp_min /scale\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "\n",
        "  zero_point = round(zero_point)          #round\n",
        "  zero_point = max(q_min, min(zero_point, q_max)) #clip\n",
        "\n",
        "  return scale, int(zero_point)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4YA7ano5nS1"
      },
      "source": [
        "####Question 2.####\n",
        "\n",
        "Use $q=r/S + Z$ to quantize a tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sBMKB5Le54wr"
      },
      "outputs": [],
      "source": [
        "def linear_quantize(fp32_tensor, bitwidth=8):\n",
        "  q_min, q_max = -(2**(bitwidth-1)), 2**(bitwidth-1) - 1\n",
        "\n",
        "  scale, zero_point = get_scale_and_zero_point(fp32_tensor)\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "  q_tensor = torch.round( fp32_tensor/scale ) +zero_point\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "  #clamp\n",
        "  q_tensor = torch.clamp(q_tensor, q_min, q_max)\n",
        "  return q_tensor, scale, zero_point  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0taJXSmz6KDS"
      },
      "source": [
        "####Question 3.####\n",
        "\n",
        "Use\n",
        "> $q_{\\mathrm{output}} = M * \\mathrm{Linear}[q_{\\mathrm{input}}, q_{\\mathrm{weight}}] + Z_{\\mathrm{output}}$\n",
        "\n",
        "> $M = S_{\\mathrm{input}} * S_{\\mathrm{weight}} / S_{\\mathrm{output}}$\n",
        "\n",
        "to compute quantized linear operation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sbXY0vaCcn7l"
      },
      "outputs": [],
      "source": [
        "def quantized_linear(input, weights, input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point, device, bitwidth=8, activation_bitwidth=8):\n",
        "  input, weights = input.to(device), weights.to(device)\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "  M = input_scale * weight_scale / output_scale\n",
        "  output = torch.nn.functional.linear((input - input_zero_point ), (weights - weight_zero_point))\n",
        "  output *= M\n",
        "  output += output_zero_point\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "  #clamp and round\n",
        "  output = output.round().clamp(-(2**(activation_bitwidth-1)), 2**(activation_bitwidth-1)-1)\n",
        "\n",
        "  return output\n",
        "\n",
        "def quantized_conv(input, bias,weights,stride, padding,groups,input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point, device, bitwidth=8, activation_bitwidth=16):\n",
        "  input, weights = input.to(device), weights.to(device)\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "  M = input_scale * weight_scale \n",
        "  conv_bias = bias /M\n",
        "  conv_bias = conv_bias.round()\n",
        "  output_only_conv = torch.nn.functional.conv2d((input - input_zero_point ), (weights - weight_zero_point),bias = conv_bias ,stride=stride,padding=padding,groups=groups)\n",
        "  output = M * output_only_conv\n",
        "  #output += output_zero_point\n",
        "  #####################################################\n",
        "\n",
        "  #clamp and round\n",
        "  output = output.clamp(-(2**(activation_bitwidth-1)), 2**(activation_bitwidth-1)-1)\n",
        "  return output\n",
        "\n",
        "def do_requant(input, scale,zero_point,bitwidth=8):\n",
        "    output = input / scale\n",
        "    output = output.round()\n",
        "    output += zero_point\n",
        "    output = output.round().clamp(-(2**(bitwidth-1)), 2**(bitwidth-1)-1)\n",
        "    return output\n",
        "\n",
        "def do_fake_quant(input, deq_scale, q_scale, q_zero_point,bitwidth=8):\n",
        "    M = deq_scale/q_scale\n",
        "    N = q_zero_point\n",
        "    output = input * M\n",
        "    output += N\n",
        "    output = output.round().clamp(-(2**(bitwidth-1)), 2**(bitwidth-1)-1)\n",
        "    return output\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vK10k10R7II7"
      },
      "source": [
        "# Design quantized linear layer and preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IwrXNVKadKfG"
      },
      "outputs": [],
      "source": [
        "class Q_SELayer(nn.Module):\n",
        "  def __init__(self,weights1,input_scale1,weight_scale1,output_scale1, input_zero_point1, weight_zero_point1, output_zero_point1,\n",
        "               weights2, input_scale2, weight_scale2, output_scale2, input_zero_point2, weight_zero_point2, output_zero_point2,\n",
        "               input_SE_scale,in_SE_zero_point,\n",
        "               output_SE_scale,output_SE_zero_point,\n",
        "               out_pool_scale,out_pool_zero_point):\n",
        "    super().__init__()\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "    self.fc = nn.Sequential(\n",
        "        QuantizedLinear(weights1,input_scale1,weight_scale1,output_scale1, input_zero_point1, weight_zero_point1, output_zero_point1),\n",
        "        QuantizedLinear(weights2, input_scale2, weight_scale2, output_scale2, input_zero_point2, weight_zero_point2, output_zero_point2)\n",
        "    )   \n",
        "    self.input_SE_scale, self.in_SE_zero_point = input_SE_scale,in_SE_zero_point\n",
        "    self.output_SE_scale, self.output_SE_zero_point = output_SE_scale, output_SE_zero_point,\n",
        "    self.out_pool_scale, self.out_pool_zero_point = out_pool_scale,out_pool_zero_point\n",
        "    self.linear_out_scale, self.linear_out_zero_point = output_scale2, output_zero_point2\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    b, c, _, _ = x.size()\n",
        "    y = self.avg_pool(x).view(b, c)\n",
        "    y = (y- self.in_SE_zero_point) \n",
        "    y = do_fake_quant(y, self.input_SE_scale, self.out_pool_scale, self.out_pool_zero_point,bitwidth=8)\n",
        "    y = self.fc(y).view(b, c, 1, 1)\n",
        "    z = (x-self.in_SE_zero_point)*(y-self.linear_out_zero_point)\n",
        "    return do_fake_quant(z, deq_scale=(self.input_SE_scale *self.linear_out_scale), \n",
        "                         q_scale=self.output_SE_scale, q_zero_point=self.output_SE_zero_point,bitwidth=8)\n",
        "  \n",
        "  def __repr__(self):\n",
        "    return f\"Quantized_SE(in_channels={self.fc[0].weights.size(1)}, out_channels={self.fc[1].weights.size(0)})\"\n",
        "    \n",
        "\n",
        "\n",
        "class QuantizedConv(nn.Module):\n",
        "  def __init__(self,bias ,weights,stride,padding,groups ,input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point, bitwidth=8, activation_bitwidth=8):\n",
        "    super().__init__()\n",
        "    self.stride, self.padding, self.groups = stride, padding,groups\n",
        "    self.weights = weights\n",
        "    self.input_scale, self.input_zero_point = input_scale, input_zero_point\n",
        "    self.weight_scale, self.weight_zero_point = weight_scale, weight_zero_point\n",
        "    self.output_scale, self.output_zero_point = output_scale, output_zero_point\n",
        "    self.bias = bias\n",
        "    self.bitwidth = bitwidth\n",
        "    self.activation_bitwidth = activation_bitwidth\n",
        "    self.q_bias = torch.round(bias / (input_scale*weight_scale))\n",
        "    self.q_weight = weights - weight_zero_point\n",
        "    self.DeQ_scale = input_scale*weight_scale*8192\n",
        "  def forward(self, x):\n",
        "    return quantized_conv(x, self.bias, self.weights, self.stride, self.padding, self.groups, self.input_scale, self.weight_scale, self.output_scale, self.input_zero_point, self.weight_zero_point, self.output_zero_point, device)\n",
        "  def __repr__(self):\n",
        "    return f\"QuantizedConv(in_channels={self.weights.size(1)}, out_channels={self.weights.size(0)})\"\n",
        "\n",
        "class QuantizedLinear(nn.Module):\n",
        "  def __init__(self, weights, input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point, bitwidth=8, activation_bitwidth=8):\n",
        "    super().__init__()\n",
        "    self.weights = weights\n",
        "    self.input_scale, self.input_zero_point = input_scale, input_zero_point\n",
        "    self.weight_scale, self.weight_zero_point = weight_scale, weight_zero_point\n",
        "    self.output_scale, self.output_zero_point = output_scale, output_zero_point\n",
        "\n",
        "    self.bitwidth = bitwidth\n",
        "    self.activation_bitwidth = activation_bitwidth\n",
        "\n",
        "  def forward(self, x):\n",
        "    return quantized_linear(x, self.weights, self.input_scale, self.weight_scale, self.output_scale, self.input_zero_point, self.weight_zero_point, self.output_zero_point, device)\n",
        "  def __repr__(self):\n",
        "    return f\"QuantizedLinear(in_channels={self.weights.size(1)}, out_channels={self.weights.size(0)})\"\n",
        "\n",
        "#Transform input data to correct integer range\n",
        "class Preprocess(nn.Module):\n",
        "  def __init__(self, input_scale, input_zero_point, activation_bitwidth=8):\n",
        "    super().__init__()\n",
        "    self.input_scale, self.input_zero_point = input_scale, input_zero_point\n",
        "    self.activation_bitwidth = activation_bitwidth\n",
        "  def forward(self, x):\n",
        "    x = x / self.input_scale + self.input_zero_point\n",
        "    x = x.round() \n",
        "    return x\n",
        "  \n",
        "class Quantizer(nn.Module):\n",
        "  def __init__(self,scale,zero_point,bitwidth=8):\n",
        "    super().__init__()\n",
        "    self.scale = scale\n",
        "    self.zero = zero_point\n",
        "    self.store_scale = scale *64\n",
        "\n",
        "  def forward(self,x):\n",
        "    return do_requant(x,self.scale,self.zero)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUpiPDiu7RCH"
      },
      "source": [
        "# Calibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "cBdXFnr5dZqT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['Conv.0', 'Conv.1', 'Conv.2.avg_pool', 'Conv.2.fc.0', 'Conv.2.fc.1', 'Conv.2.fc.2', 'Conv.2.fc.3', 'Conv.3', 'Conv.4', 'backbone.0', 'backbone.1', 'backbone.2', 'backbone.3', 'backbone.4'])\n"
          ]
        }
      ],
      "source": [
        "# add hook to record the min max value of the activation\n",
        "input_activation = {}\n",
        "output_activation = {}\n",
        "\n",
        "#Define a hook to record the feature map of each layer\n",
        "def add_range_recoder_hook(model):\n",
        "    import functools\n",
        "    def _record_range(self, x, y, module_name):\n",
        "        x = x[0]\n",
        "        input_activation[module_name] = x.detach()\n",
        "        output_activation[module_name] = y.detach()\n",
        "\n",
        "    all_hooks = []\n",
        "    for name, m in model.named_modules():\n",
        "        if isinstance(m, (nn.Linear, nn.ReLU,nn.Conv2d,h_swish,nn.AdaptiveAvgPool2d)):\n",
        "            all_hooks.append(m.register_forward_hook(\n",
        "                functools.partial(_record_range, module_name=name)))\n",
        "\n",
        "\n",
        "    return all_hooks\n",
        "\n",
        "hooks = add_range_recoder_hook(FP32_model)\n",
        "sample_data = iter(train_loader).__next__()[0].to(device) #Use a batch of training data to calibrate\n",
        "FP32_model(sample_data) #Forward to use hook\n",
        "# print(output_activation['Conv.1'])\n",
        "# print(\"==\")\n",
        "# print(input_activation['Conv.2.avg_pool'])\n",
        "print(output_activation.keys())\n",
        "# remove hooks\n",
        "for h in hooks:\n",
        "    h.remove()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVf8vpiVTsDa"
      },
      "source": [
        "# Quantize model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "SVh-SRj8eOrs"
      },
      "outputs": [],
      "source": [
        "#copy original model\n",
        "quantized_model = copy.deepcopy(FP32_model)\n",
        "\n",
        "#Record each layer in original model\n",
        "quantized_backbone = []\n",
        "quantized_Conv = []\n",
        "i = 0\n",
        "\n",
        "#Record input scale and zero point\n",
        "input_scale, input_zero_point = get_scale_and_zero_point(input_activation[\"Conv.0\"])\n",
        "preprocess = Preprocess(input_scale, input_zero_point)\n",
        "quantized_Conv.append(preprocess)\n",
        "\n",
        "input_scale, input_zero_point = get_scale_and_zero_point(input_activation['Conv.0'])\n",
        "output_scale, output_zero_point = get_scale_and_zero_point(output_activation['Conv.0'])\n",
        "quantized_weights12, weight_scale, weight_zero_point = linear_quantize(FP32_model.Conv[0].weight.data)\n",
        "Conv_bias = FP32_model.Conv[0].bias.data\n",
        "quantizedConv1 = QuantizedConv(Conv_bias,quantized_weights12, 1,0,1,input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point)\n",
        "h_swish1 = h_swish()\n",
        "#quantized_model.Conv[0] = quantizedConv1 \n",
        "\n",
        "req_scale , output_zero_point = get_scale_and_zero_point(output_activation['Conv.1'])\n",
        "req1 = Quantizer(req_scale,output_zero_point)\n",
        "\n",
        "quantized_Conv.append(quantizedConv1)\n",
        "quantized_Conv.append(h_swish1)\n",
        "quantized_Conv.append(req1)\n",
        "###############\n",
        "input_scale1, input_zero_point1 = get_scale_and_zero_point(input_activation['Conv.2.fc.0'])\n",
        "output_scale1, output_zero_point1 = get_scale_and_zero_point(output_activation['Conv.2.fc.1'])\n",
        "quantized_weights1, weight_scale1, weight_zero_point1 = linear_quantize(FP32_model.Conv[2].fc[0].weight.data)\n",
        "\n",
        "input_scale2, input_zero_point2 = get_scale_and_zero_point(input_activation['Conv.2.fc.2'])\n",
        "output_scale2, output_zero_point2 = get_scale_and_zero_point(output_activation['Conv.2.fc.3'])\n",
        "quantized_weights2, weight_scale2, weight_zero_point2 = linear_quantize(FP32_model.Conv[2].fc[2].weight.data)\n",
        "\n",
        "SE_in_scale, SE_in_zero_point = get_scale_and_zero_point(output_activation['Conv.1'])\n",
        "\n",
        "SE_out_scale, SE_out_zero_point = get_scale_and_zero_point(input_activation['Conv.3'])\n",
        "\n",
        "SE_out_pool_scale, SE_out_pool_zero_point = get_scale_and_zero_point(output_activation['Conv.2.avg_pool'])\n",
        "\n",
        "quantizedSE_linear1 =Q_SELayer(quantized_weights1,input_scale1,weight_scale1,output_scale1,input_zero_point1,weight_zero_point1,output_zero_point1, \n",
        "                               quantized_weights2,input_scale2,weight_scale2,output_scale2,input_zero_point2,weight_zero_point2,output_zero_point2,\n",
        "                               SE_in_scale, SE_in_zero_point,\n",
        "                               SE_out_scale, SE_out_zero_point,\n",
        "                               SE_out_pool_scale, SE_out_pool_zero_point)\n",
        "##################\n",
        "quantized_Conv.append(quantizedSE_linear1)\n",
        "\n",
        "\n",
        "input_scale, input_zero_point = get_scale_and_zero_point(input_activation['Conv.3'])\n",
        "output_scale, output_zero_point = get_scale_and_zero_point(output_activation['Conv.3'])\n",
        "quantized_weights, weight_scale, weight_zero_point = linear_quantize(FP32_model.Conv[3].weight.data)\n",
        "Conv_bias = FP32_model.Conv[3].bias.data\n",
        "quantizedConv2 = QuantizedConv(Conv_bias,quantized_weights, 1,0,1,input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point)\n",
        "#quantized_model.Conv[2] = quantizedConv2 \n",
        "\n",
        "h_swish2 = h_swish()\n",
        "#quantized_model.Conv[0] = quantizedConv1 \n",
        "\n",
        "req_scale , output_zero_point = get_scale_and_zero_point(output_activation['Conv.4'])\n",
        "req2 = Quantizer(req_scale,output_zero_point)\n",
        "\n",
        "quantized_Conv.append(quantizedConv2)\n",
        "quantized_Conv.append(h_swish2)\n",
        "quantized_Conv.append(req2)\n",
        "\n",
        "\n",
        "################# below is linear\n",
        "\n",
        "input_scale, input_zero_point = get_scale_and_zero_point(input_activation['backbone.0'])\n",
        "output_scale, output_zero_point = get_scale_and_zero_point(output_activation['backbone.1'])\n",
        "quantized_weights, weight_scale, weight_zero_point = linear_quantize(FP32_model.backbone[0].weight.data)\n",
        "quantizedLinear1 = QuantizedLinear(quantized_weights, input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point)\n",
        "quantized_backbone.append(quantizedLinear1)\n",
        "\n",
        "input_scale, input_zero_point = get_scale_and_zero_point(input_activation['backbone.2'])\n",
        "output_scale, output_zero_point = get_scale_and_zero_point(output_activation['backbone.3'])\n",
        "quantized_weights, weight_scale, weight_zero_point = linear_quantize(FP32_model.backbone[2].weight.data)\n",
        "quantizedLinear2 = QuantizedLinear(quantized_weights, input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point)\n",
        "quantized_backbone.append(quantizedLinear2)\n",
        "\n",
        "# #Record Linear + ReLU of the model (except the last Linear)\n",
        "# while i < len(quantized_model.backbone) - 1:\n",
        "#   if isinstance(quantized_model.backbone[i], nn.Linear) and isinstance(quantized_model.backbone[i+1], nn.ReLU):\n",
        "#     linear = quantized_model.backbone[i]\n",
        "#     linear_name = f\"backbone.{i}\"\n",
        "#     relu = quantized_model.backbone[i + 1]\n",
        "#     relu_name = f\"backbone.{i + 1}\"\n",
        "\n",
        "#     #Use the calibration data to calculate scale and zero point of each layer\n",
        "#     input_scale, input_zero_point = get_scale_and_zero_point(input_activation[linear_name])\n",
        "#     output_scale, output_zero_point = get_scale_and_zero_point(output_activation[relu_name])\n",
        "#     quantized_weights, weight_scale, weight_zero_point = linear_quantize(linear.weight.data)\n",
        "\n",
        "#     quantizedLinear = QuantizedLinear(quantized_weights, input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point)\n",
        "\n",
        "#     quantized_backbone.append(quantizedLinear)\n",
        "#     i += 2\n",
        "\n",
        "#Record the last Linear layer\n",
        "linear = quantized_model.backbone[4]\n",
        "linear_name = f\"backbone.4\"\n",
        "input_scale, input_zero_point = get_scale_and_zero_point(input_activation[linear_name])\n",
        "output_scale, output_zero_point = get_scale_and_zero_point(output_activation[linear_name])\n",
        "quantized_weights, weight_scale, weight_zero_point = linear_quantize(linear.weight.data)\n",
        "quantizedLinear3 = QuantizedLinear(quantized_weights, input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point)\n",
        "quantized_backbone.append(quantizedLinear3)\n",
        "\n",
        "quantized_model.Conv = nn.Sequential(*quantized_Conv)\n",
        "quantized_model.backbone = nn.Sequential(*quantized_backbone)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRB96PKbfNX4",
        "outputId": "58ce882a-3521-4b40-ff98-44dcea373546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ToyModel(\n",
            "  (Conv): Sequential(\n",
            "    (0): Preprocess()\n",
            "    (1): QuantizedConv(in_channels=1, out_channels=5)\n",
            "    (2): h_swish(\n",
            "      (sigmoid): h_sigmoid(\n",
            "        (relu): ReLU6(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (3): Quantizer()\n",
            "    (4): Quantized_SE(in_channels=5, out_channels=5)\n",
            "    (5): QuantizedConv(in_channels=5, out_channels=1)\n",
            "    (6): h_swish(\n",
            "      (sigmoid): h_sigmoid(\n",
            "        (relu): ReLU6(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (7): Quantizer()\n",
            "  )\n",
            "  (backbone): Sequential(\n",
            "    (0): QuantizedLinear(in_channels=784, out_channels=120)\n",
            "    (1): QuantizedLinear(in_channels=120, out_channels=84)\n",
            "    (2): QuantizedLinear(in_channels=84, out_channels=10)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(quantized_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['Conv.0', 'Conv.1', 'Conv.2', 'Conv.3', 'Conv.4.avg_pool', 'Conv.4.fc.0', 'Conv.4.fc.1', 'Conv.4', 'Conv.5', 'Conv.6', 'Conv.7', 'backbone.0', 'backbone.1', 'backbone.2'])\n",
            "tensor([[[[-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          ...,\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.]],\n",
            "\n",
            "         [[-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          ...,\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.]],\n",
            "\n",
            "         [[ -39.,  -39.,  -39.,  ...,  -39.,  -39.,  -39.],\n",
            "          [ -39.,  -39.,  -39.,  ...,  -39.,  -39.,  -39.],\n",
            "          [ -39.,  -39.,  -39.,  ...,  -39.,  -39.,  -39.],\n",
            "          ...,\n",
            "          [ -39.,  -39.,  -39.,  ...,  -39.,  -39.,  -39.],\n",
            "          [ -39.,  -39.,  -39.,  ...,  -39.,  -39.,  -39.],\n",
            "          [ -39.,  -39.,  -39.,  ...,  -39.,  -39.,  -39.]],\n",
            "\n",
            "         [[ 103.,  103.,  103.,  ...,  103.,  103.,  103.],\n",
            "          [ 103.,  103.,  103.,  ...,  103.,  103.,  103.],\n",
            "          [ 103.,  103.,  103.,  ...,  103.,  103.,  103.],\n",
            "          ...,\n",
            "          [ 103.,  103.,  103.,  ...,  103.,  103.,  103.],\n",
            "          [ 103.,  103.,  103.,  ...,  103.,  103.,  103.],\n",
            "          [ 103.,  103.,  103.,  ...,  103.,  103.,  103.]],\n",
            "\n",
            "         [[-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          ...,\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.]]],\n",
            "\n",
            "\n",
            "        [[[-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          ...,\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.]],\n",
            "\n",
            "         [[-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          ...,\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.]],\n",
            "\n",
            "         [[ -69.,  -69.,  -69.,  ...,  -69.,  -69.,  -69.],\n",
            "          [ -69.,  -69.,  -69.,  ...,  -69.,  -69.,  -69.],\n",
            "          [ -69.,  -69.,  -69.,  ...,  -69.,  -69.,  -69.],\n",
            "          ...,\n",
            "          [ -69.,  -69.,  -69.,  ...,  -69.,  -69.,  -69.],\n",
            "          [ -69.,  -69.,  -69.,  ...,  -69.,  -69.,  -69.],\n",
            "          [ -69.,  -69.,  -69.,  ...,  -69.,  -69.,  -69.]],\n",
            "\n",
            "         [[  48.,   48.,   48.,  ...,   48.,   48.,   48.],\n",
            "          [  48.,   48.,   48.,  ...,   48.,   48.,   48.],\n",
            "          [  48.,   48.,   48.,  ...,   48.,   48.,   48.],\n",
            "          ...,\n",
            "          [  48.,   48.,   48.,  ...,   48.,   48.,   48.],\n",
            "          [  48.,   48.,   48.,  ...,   48.,   48.,   48.],\n",
            "          [  48.,   48.,   48.,  ...,   48.,   48.,   48.]],\n",
            "\n",
            "         [[-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          ...,\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.]]],\n",
            "\n",
            "\n",
            "        [[[-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          ...,\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.]],\n",
            "\n",
            "         [[-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          ...,\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.]],\n",
            "\n",
            "         [[ -46.,  -46.,  -46.,  ...,  -46.,  -46.,  -46.],\n",
            "          [ -46.,  -46.,  -46.,  ...,  -46.,  -46.,  -46.],\n",
            "          [ -46.,  -46.,  -46.,  ...,  -46.,  -46.,  -46.],\n",
            "          ...,\n",
            "          [ -46.,  -46.,  -46.,  ...,  -46.,  -46.,  -46.],\n",
            "          [ -46.,  -46.,  -46.,  ...,  -46.,  -46.,  -46.],\n",
            "          [ -46.,  -46.,  -46.,  ...,  -46.,  -46.,  -46.]],\n",
            "\n",
            "         [[  88.,   88.,   88.,  ...,   88.,   88.,   88.],\n",
            "          [  88.,   88.,   88.,  ...,   88.,   88.,   88.],\n",
            "          [  88.,   88.,   88.,  ...,   88.,   88.,   88.],\n",
            "          ...,\n",
            "          [  88.,   88.,   88.,  ...,   88.,   88.,   88.],\n",
            "          [  88.,   88.,   88.,  ...,   88.,   88.,   88.],\n",
            "          [  88.,   88.,   88.,  ...,   88.,   88.,   88.]],\n",
            "\n",
            "         [[-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          ...,\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          ...,\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.]],\n",
            "\n",
            "         [[-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          ...,\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.]],\n",
            "\n",
            "         [[ -56.,  -56.,  -56.,  ...,  -56.,  -56.,  -56.],\n",
            "          [ -56.,  -56.,  -56.,  ...,  -56.,  -56.,  -56.],\n",
            "          [ -56.,  -56.,  -56.,  ...,  -56.,  -56.,  -56.],\n",
            "          ...,\n",
            "          [ -56.,  -56.,  -56.,  ...,  -56.,  -56.,  -56.],\n",
            "          [ -56.,  -56.,  -56.,  ...,  -56.,  -56.,  -56.],\n",
            "          [ -56.,  -56.,  -56.,  ...,  -56.,  -56.,  -56.]],\n",
            "\n",
            "         [[  69.,   69.,   69.,  ...,   69.,   69.,   69.],\n",
            "          [  69.,   69.,   69.,  ...,   69.,   69.,   69.],\n",
            "          [  69.,   69.,   69.,  ...,   69.,   69.,   69.],\n",
            "          ...,\n",
            "          [  69.,   69.,   69.,  ...,   69.,   69.,   69.],\n",
            "          [  69.,   69.,   69.,  ...,   69.,   69.,   69.],\n",
            "          [  69.,   69.,   69.,  ...,   69.,   69.,   69.]],\n",
            "\n",
            "         [[-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          ...,\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.]]],\n",
            "\n",
            "\n",
            "        [[[-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          ...,\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.]],\n",
            "\n",
            "         [[-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          ...,\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.]],\n",
            "\n",
            "         [[ -67.,  -67.,  -67.,  ...,  -67.,  -67.,  -67.],\n",
            "          [ -67.,  -67.,  -67.,  ...,  -67.,  -67.,  -67.],\n",
            "          [ -67.,  -67.,  -67.,  ...,  -67.,  -67.,  -67.],\n",
            "          ...,\n",
            "          [ -67.,  -67.,  -67.,  ...,  -17.,  -14.,  -24.],\n",
            "          [ -67.,  -67.,  -67.,  ...,  -31.,  -28.,  -46.],\n",
            "          [ -67.,  -67.,  -67.,  ...,  -67.,  -67.,  -67.]],\n",
            "\n",
            "         [[  51.,   51.,   51.,  ...,   51.,   51.,   51.],\n",
            "          [  51.,   51.,   51.,  ...,   51.,   51.,   51.],\n",
            "          [  51.,   51.,   51.,  ...,   51.,   51.,   51.],\n",
            "          ...,\n",
            "          [  51.,   51.,   51.,  ..., -113., -118., -102.],\n",
            "          [  51.,   51.,   51.,  ...,  -88.,  -94.,  -42.],\n",
            "          [  51.,   51.,   51.,  ...,   51.,   51.,   51.]],\n",
            "\n",
            "         [[-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          ...,\n",
            "          [-108., -108., -108.,  ...,  -69.,  -65.,  -74.],\n",
            "          [-108., -108., -108.,  ...,  -81.,  -78.,  -94.],\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.]]],\n",
            "\n",
            "\n",
            "        [[[-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          ...,\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.]],\n",
            "\n",
            "         [[-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          ...,\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.],\n",
            "          [-107., -107., -107.,  ..., -107., -107., -107.]],\n",
            "\n",
            "         [[ -40.,  -40.,  -40.,  ...,  -40.,  -40.,  -40.],\n",
            "          [ -40.,  -40.,  -40.,  ...,  -40.,  -40.,  -40.],\n",
            "          [ -40.,  -40.,  -40.,  ...,  -40.,  -40.,  -40.],\n",
            "          ...,\n",
            "          [ -40.,  -40.,  -40.,  ...,  -40.,  -40.,  -40.],\n",
            "          [ -40.,  -40.,  -40.,  ...,  -40.,  -40.,  -40.],\n",
            "          [ -40.,  -40.,  -40.,  ...,  -40.,  -40.,  -40.]],\n",
            "\n",
            "         [[  99.,   99.,   99.,  ...,   99.,   99.,   99.],\n",
            "          [  99.,   99.,   99.,  ...,   99.,   99.,   99.],\n",
            "          [  99.,   99.,   99.,  ...,   99.,   99.,   99.],\n",
            "          ...,\n",
            "          [  99.,   99.,   99.,  ...,   99.,   99.,   99.],\n",
            "          [  99.,   99.,   99.,  ...,   99.,   99.,   99.],\n",
            "          [  99.,   99.,   99.,  ...,   99.,   99.,   99.]],\n",
            "\n",
            "         [[-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          ...,\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.],\n",
            "          [-108., -108., -108.,  ..., -108., -108., -108.]]]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# add hook to record the min max value of the activation\n",
        "q_input_activation = {}\n",
        "q_output_activation = {}\n",
        "\n",
        "#Define a hook to record the feature map of each layer\n",
        "def add_range_recoder_hook(model):\n",
        "    import functools\n",
        "    def _record_range(self, x, y, module_name):\n",
        "        x = x[0]\n",
        "        q_input_activation[module_name] = x.detach()\n",
        "        q_output_activation[module_name] = y.detach()\n",
        "\n",
        "    all_hooks = []\n",
        "    for name, m in model.named_modules():\n",
        "        if isinstance(m, (QuantizedConv,  QuantizedLinear,h_swish,Quantizer,Preprocess,Q_SELayer,nn.AdaptiveAvgPool2d)):\n",
        "            all_hooks.append(m.register_forward_hook(\n",
        "                functools.partial(_record_range, module_name=name)))\n",
        "\n",
        "\n",
        "    return all_hooks\n",
        "\n",
        "\n",
        "q_test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
        "hooks = add_range_recoder_hook(quantized_model)\n",
        "sample_data = iter(test_loader).__next__()[0].to(device) #Use a batch of training data to calibrate\n",
        "quantized_model(sample_data) #Forward to use hook\n",
        "\n",
        "print(q_output_activation.keys())\n",
        "#print(q_intput_activation.keys())\n",
        "#print(quantized_model.Conv[4].weights2)\n",
        "print(q_output_activation[\"Conv.4\"])\n",
        "# remove hooks\n",
        "for h in hooks:\n",
        "    h.remove()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "00\n",
            "byte0: 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 82 81 81 81 81 81 9c 81 81 81 81 81 81 d9 81 de 81 81 81 81 02 1e 29 81 81 81 83 03 20 18 81 81 83 81 eb 1d 1e 81 82 81 81 df 18 20 81 81 82 e3 ef 16 1f 81 82 81 f6 09 1b 14 84 81 b6 e8 10 1b 0b 81 c2 01 f7 06 1c 2d 81 f0 f4 10 1b 23 1a c7 e3 e3 f8 1d 44 46 91 3c 08 13 50 75 77 81 c4 48 50 89 32 23 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 b2 81 81 81 81 f9 6d 77 c9 81 81 81 7c 6e 66 7b 81 81 81 64 66 68 60 81 81 81 67 67 64 6b 81 81 81 7f 64 6e 5c 81 81 81 7f 6d 56 7f 81 81 87 7f 7f b0 7f 81 81 a0 7f d5 a0 7f 81 81 b6 7a 96 6c 73 81 81 d1 70 a8 58 7f 81 81 e6 74 50 7f 7f 81 81 ff 78 70 67 7e 84 81 14 36 66 6b 50 a4 81 24 d7 6b 6a fe b8 81 36 c6 6a 69 c7 ba 81 46 ef 6a 6a c6 ce 81 48 12 6a 6a b0 e3 81 4c 2e 6b 6b 94 ef 81 44 56 6b 6c b8 f9 81 40 68 6b 6c 07 0a 81 3e 6e 6b 6c 27 0f 81 38 77 69 69 60 18 81 32 6e 6e 6d 30 1e 81 3c 5a 5e 60 1b 3c 81 03 81 81 81 81 08 81 cd 81 81 81 81 fc 81 b2 81 83 83 81 c4 81 81 82 02 13 81 81 81 81 83 7f 7f 81 81 81 81 81 5a 5a 81 81 81 81 81 67 65 81 81 81 81 81 65 63 81 81 81 81 81 6a 64 81 81 81 81 81 6b 63 81 81 81 81 81 67 67 81 81 81 81 81 73 69 81 81 81 81 81 7f 6c 81 81 81 81 81 7f 7e 81 81 81 81 81 7f 78 81 81 81 81 81 7b 7b 81 81 81 81 81 58 7d 81 81 81 81 81 2d 79 81 81 81 81 81 0c 7f 81 81 81 81 81 f2 7f 81 81 81 81 81 18 7f 81 81 81 81 81 46 7f 81 81 81 81 81 78 7c 81 81 81 81 81 62 6f 81 81 81 81 81 6d 6a 81 81 81 81 81 74 52 81 81 81 81 82 75 46 81 81 81 81 83 71 4a 81 81 81 81 85 6c 1f 81 81 81 81 82 7f 22 81 81 81 81 81 20 c5 81 81 81 81 81 e4 d7 81 81 81 81 81 4e 58 81 81 81 81 81 4e 65 81 81 81 81 81 54 66 81 81 81 81 81 52 4e 81 81 81 81 81 38 3e 81 81 81 81 81 ea 26 81 81 81 81 81 c8 09 81 81 81 81 81 d6 0b 81 81 81 81 81 f0 14 81 81 81 81 81 e5 1d 81 81 81 81 81 e4 23 81 81 81 81 81 ea 24 81 81 81 81 81 f4 19 81 81 81 81 81 f6 20 81 81 81 81 81 fa 29 81 81 81 81 81 fe 2e 81 81 81 81 81 2c 48 81 81 81 81 81 75 5a 81 81 81 81 81 52 68 81 81 81 81 81 54 6c 81 81 81 81 81 50 69 81 81 81 81 81 48 6a 81 81 81 81 81 4a 68 81 81 81 81 81 46 65 81 81 81 81 81 44 58 81 81 81 81 81 40 60 81 81 81 81 81 e6 13 81 81 81 81 81 c4 d4 81 81 81 82 8e 23 2d 9f 81 81 82 0c 23 0c 2c 81 81 81 ed e5 0b fd 81 81 81 f2 d2 f0 05 81 81 81 e6 e2 f4 13 81 81 81 eb f0 f1 17 81 81 81 f1 eb d4 0d 87 81 98 e9 e8 d5 14 b4 81 ba e8 ee eb 1d d6 81 d7 05 ec f5 36 fc 81 f1 13 ec e8 28 2b 81 fd da ed ec f8 34 81 04 b0 eb e8 d2 42 81 09 96 e7 e7 ae 4e 81 0a 9a df e2 94 4c 81 0e 8d e1 df a0 4e 81 02 81 e6 e7 95 4c 81 ff 96 ed f0 b2 25 81 07 ca f0 f3 e2 30 81 0f d5 f1 e7 01 25 81 81 f8 e1 eb 38 81 81 81 0a eb e9 42 81 81 82 05 0d eb 28 81 81 81 f7 ee ec 22 82 81 81 15 d4 e9 29 83 81 81 ff 24 1d 23 81 81 81 81 e0 eb 81 81 81 81 81 36 3c 81 81 81 81 81 56 56 81 81 81 81 81 54 5a 81 81 81 81 81 52 54 b4 81 81 81 81 4e 52 ea 81 81 81 81 54 58 04 81 81 81 9a 52 5c fd 81 81 81 b2 4a 66 f5 81 81 81 d8 48 75 ee 81 81 81 00 58 7e e8 81 81 81 24 72 7f e5 81 81 81 32 77 7d e2 81 81 81 2d 60 6a eb 81 81 81 1b 18 52 ed 81 81 81 0e c7 32 09 81 81 81 08 9d 07 f8 81 81 81 db 85 bc fc 81 81 81 84 c7 95 0a 81 81 81 81 24 81 02 81 81 81 81 5a 81 0b 81 81 81 81 4a 81 0d 81 81 81 81 5a 81 fc 81 81 81 81 60 81 03 81 81 81 82 5a 81 05 81 81 81 84 52 81 17 81 81 81 82 4e 81 06 81 81 81 81 6e 81 1d 81 81 81 81 0a 81 be 81 81 81 82 81 ae 81 81 81 81 81 75 6f 81 81 81 81 81 7e 3c 82 81 81 81 81 36 a6 81 81 81 82 c9 81 81 9a 81 81 81 c7 b8 9e b4 81 81 81 d3 a0 b2 9a 81 81 81 04 95 b6 9c 81 81 81 1b 8d a2 a2 81 81 81 0a 8b 9e ae 81 81 81 13 8a a0 9e 81 81 81 2a 90 9e 9d 81 81 81 38 8e 99 a8 81 81 81 5e 91 9b ae 81 81 81 7f 8c 9b ca 81 81 89 7f 87 9a e6 81 81 8c 7f 93 9c 0b 81 81 8c 7e 8e 9a 32 81 81 91 7f 91 97 36 81 81 97 7e 9d 9c 4c 81 81 98 5a 99 9c 56 81 81 99 3e a2 9b 5a 81 81 99 1e 9f 98 63 81 81 a0 09 a8 9d 72 81 81 a4 d5 ba aa 5a 81 81 a4 81 81 81 65 81 81 c3 81 81 81 f8 81 81 b6 81 81 81 a4 81 81 81 83 df e3 81 81 81 81 81 7f 7b 82 81 81 81 81 b6 e0 81 81 81 81 04 be b0 be 81 81 81 f0 1b ff 02 81 81 81 a6 e2 dc 92 81 81 81 32 6a 4c fc 81 81 81 d4 05 03 fc 81 81 81 ba 00 fc 96 81 81 81 de 20 1e d5 81 81 81 eb 2c 32 f7 81 81 ae ef 32 1f f1 81 81 b8 c0 ea d6 50 81 81 8f 13 44 40 4e 81 81 b4 16 60 42 25 81 81 d9 c4 e4 d4 32 91 81 0c c0 23 04 14 a6 81 d3 ae 24 06 08 90 81 03 c8 42 1d e2 a0 81 4e 95 0c ed c7 d6 81 c3 a4 f4 d1 cd 96 81 e5 e8 75 52 e8 a6 81 f0 94 0e f3 81 ae 81 fd cf e5 e5 9a b6 81 d0 dc f3 1c a8 94 81 b2 0b f5 25 a8 83 81 85 ac e2 2f 81 82 81 81 81 9e d5 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 b6 17 81 81 81 82 84 52 4a b8 87 81 82 81 d9 18 65 81 81 81 81 81 81 4c d7 ef 9d ae cb 10 d9 13 07 91 fb 03 ba 81 8f 90 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 f4 81 81 81 81 82 a2 f1 81 de 81 81 81 fe f4 f6 48 81 81 be d3 08 5e 40 81 81 3e f0 01 e2 ea a6 fd e2 ec 2d 3a f1 0f 32 e9 3c 61 13 52 ba 38 28 4c d6 81 98 90 86 0f 81 81 9a 8d 81 c5 a2 a8 ba d7 ac 81 a4 b8 be ac bc ba 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 3e 3c 81 81 81 81 81 50 2e 81 81 81 81 1f 48 40 ff 81 81 84 17 6f 74 18 83 81 81 07 71 2e 01 81 81 81 13 32 07 05 81 81 81 1a 40 27 05 81 81 81 0a 58 44 2e 81 81 81 0d 50 2a 3c 81 81 81 34 44 1a 75 81 81 81 13 30 1f da 81 81 81 b8 3c 20 c8 81 81 81 c1 44 13 ea 8b 81 87 b6 28 1b de a2 81 aa 9e 27 2e e2 b0 81 ba 86 36 34 cd be 81 d1 8b 32 2f ca c8 81 e5 b4 3c 24 ca d0 81 ee ca 38 2c ca d6 81 ee f5 36 23 e2 e0 81 ec ea 4c 28 e4 e4 81 ee 81 ec 02 81 e2 81 ed 81 81 81 81 e4 81 e6 81 81 81 81 ea 81 fa 81 82 81 81 e5 81 fd 81 81 81 81 d8 81 fb 81 81 81 81 cc 81 9a 81 81 81 81 bc 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 9b 92 84 81 81 81 82 cb dc fa 81 81 81 81 81 e7 22 81 81 81 81 c8 25 2a 82 84 85 81 ce 19 01 81 84 81 e1 ba 2d 9f 82 81 85 aa ff 11 81 81 84 1d 81 e9 27 8d 81 81 19 aa 44 2c de 82 8f 32 a2 60 fc 38 81 90 62 f1 62 e7 c8 ba 28 52 32 62 0d 52 8c ec 04 19 c6 2a 1c 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 17 82 81 81 81 8a 81 01 81 81 81 81 81 81 fb 8e 82 81 8c 9e a2 3a 07 81 86 b8 f7 3c f3 f7 ca 81 c8 48 03 ed ed 07 c6 bc 07 ff f5 ef e9 ff 0b ff 0d 0d df d7 f7 2e 1b 11 1d 0d 01 1f 25 48 3c 38 2c 29 40 92 0f 23 23 2b 1b ed 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 b0 d0 81 81 81 81 81 5a 50 81 81 81 81 81 4c 46 81 81 81 81 81 5c 4e 81 81 81 81 81 63 56 81 81 81 81 81 60 5c 81 81 81 81 81 5c 4a 81 81 81 81 81 52 4a 81 81 81 81 81 4c 48 81 81 81 81 81 4a 46 81 81 81 81 81 4c 46 81 81 81 81 81 48 46 81 81 81 81 81 4c 48 81 81 81 81 81 50 4a 81 81 81 81 81 54 4e 81 81 81 81 81 5a 50 81 81 81 81 81 5e 52 81 81 81 81 81 62 56 81 81 81 81 81 64 56 81 81 81 81 81 66 54 81 81 81 81 81 67 52 81 81 81 81 81 67 4c 81 81 81 81 81 6a 4a 81 81 81 81 81 61 42 81 81 81 81 81 70 66 81 81 81 81 81 09 b2 81 81 81 81 81 e6 d2 81 81 81 82 86 78 7f 85 81 81 83 81 5e 69 81 81 81 81 cb 5e 65 83 81 81 83 7c 6a 64 67 81 81 83 5e 70 6e 68 82 81 81 62 6b 70 63 81 81 81 66 67 67 67 81 81 81 69 69 6d 66 81 81 81 6c 64 69 67 81 81 81 68 66 63 66 81 81 81 6a 68 66 66 81 81 81 6d 67 66 68 8f 81 81 6d 67 6a 6b b6 81 9c 6d 66 6e 70 d7 81 c3 6f 67 66 74 f0 81 e5 70 67 69 72 05 81 fb 72 67 68 70 17 81 1d 76 66 6a 5e 2c 81 32 73 69 6a 28 3e 81 3e 48 69 6a 28 42 81 4c 21 69 6a 16 44 81 4e 0f 69 6b 04 44 81 46 14 69 6b fe 36 81 42 1f 6b 6d f0 3a 81 36 1a 68 6a fe 26 81 81 3c 6d 67 2c 81 81 81 38 67 64 04 81 81 81 81 81 81 81 81 81 81 81 73 71 81 81 81 81 81 48 40 81 81 81 81 81 40 4a 81 81 81 81 81 40 44 81 81 81 81 81 2f 36 81 81 81 81 81 30 2f 81 81 81 81 81 29 3e 81 81 81 81 81 03 1d 81 81 81 81 81 fc f3 81 81 81 81 81 ea ec 81 81 81 81 81 e3 e6 81 81 81 81 81 ee e3 81 81 81 81 81 f3 ea 81 81 81 81 81 fc ef 81 81 81 81 81 04 ef 81 81 81 81 81 fc f2 81 81 81 81 81 fc ee 81 81 81 81 81 04 e2 81 81 81 81 81 23 04 81 81 81 81 81 2f 32 81 81 81 81 81 38 42 81 81 81 81 81 38 48 81 81 81 81 81 3a 4c 81 81 81 81 81 3a 4e 81 81 81 81 81 2f 4a 81 81 81 81 81 46 56 81 81 81 81 81 e6 04 81 81 81 81 81 e8 3c 81 81 81 81 b0 f5 44 dc 81 81 81 f8 24 1b 24 81 81 81 ec f5 ef fb 81 81 81 fe e8 dc f8 81 81 8a 05 d6 df f5 90 81 b2 02 d2 e2 f5 bc 81 d2 0e e2 cc e5 c9 81 d6 24 cf e2 df dc 81 dc 4c d6 df ef ef 81 f2 50 d9 c3 cf fb 81 05 18 d2 c6 c6 f8 81 08 14 cc c3 c6 f2 81 0b fb cf bc c6 f8 81 0e fb df cc d6 ef 81 0e fe e8 d2 dc e8 81 0b 14 e2 dc dc ef 81 08 30 e2 d9 e5 e2 81 05 3a e2 d9 e8 e2 81 02 3c e8 d9 ec e2 81 fb 2e fe ec f8 e2 81 fb 0e f2 dc f8 e5 81 f5 05 df c3 d9 e5 81 ef dc 81 81 81 e8 81 ec bc 90 90 d2 e5 81 f8 87 81 81 50 ef 81 fb 81 b8 d9 81 e8 81 05 81 a6 d6 81 f2 81 81 81 d1 df 81 81 81 81 81 62 7f 81 81 81 81 81 19 44 81 81 81 81 b8 a8 36 df 81 81 81 25 81 7f 7f 81 81 d0 38 97 17 db 94 81 e0 0b f2 00 96 e3 81 c7 26 34 7f 7f 06 81 ea 46 7f 5a 2d 02 81 27 52 4a 68 81 96 81 7f 76 d0 5c d9 81 81 7f 6c bc fe 32 ba 81 60 12 17 48 70 19 81 1f fa 22 6c 19 7f 81 1c 0d db 7f a8 6c 81 44 e5 cc 2b ac 40 81 46 d8 d8 ef 08 2a 81 7f e7 e2 a6 08 e3 81 7c ed 05 81 f5 a6 81 62 fe 3e 8f 17 d4 81 50 0d 3a b6 62 0d 81 46 3c 2c fe 58 29 81 5e 4a 10 15 62 3e 81 46 32 0a dd 6b 60 81 3a 2f 2d cc 40 5e 81 0e 2a 20 ee 7f 74 81 36 89 f8 0b a2 4a 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 82 81 85 c2 81 81 81 81 81 81 29 32 34 2b 13 81 81 28 3a 3e 42 3e 81 a0 2c 30 36 3e 3a 81 c1 34 34 36 38 3a 81 a0 3a 38 32 38 34 81 81 32 34 30 3a 32 81 81 34 34 30 38 34 81 86 38 34 38 38 32 82 db 3c 34 38 30 34 81 b2 2d 26 30 2d 24 82 81 44 36 38 38 3c 81 81 32 3c 3a 38 3a 81 94 0e 38 36 36 34 81 7f 60 4c 32 30 32 81 a2 44 42 52 4e 48 b2 81 e6 ff 92 94 93 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 9c 10 81 81 81 81 3a 6d 4a d8 81 81 81 3e 48 3a 42 81 81 81 3c 40 40 32 81 81 b0 42 3c 42 42 81 81 42 3e 36 34 3c 81 81 5c 3e 52 63 3c 81 81 6b 3e 22 50 3a b0 81 73 65 22 30 36 f4 81 ec 54 5e 54 3a 81 81 81 3a 46 54 52 81 81 83 48 3e 54 44 81 81 83 46 42 64 44 81 81 82 46 44 4a 38 81 81 83 46 46 40 38 81 81 83 46 4a 46 38 81 81 83 48 4a 46 38 81 81 83 4a 4a 46 3a 81 81 83 4c 4c 46 40 81 81 83 4a 4a 4a 4a 81 81 84 48 4c 4a 4c 81 81 83 46 4a 4a 46 81 81 83 46 48 48 42 81 81 83 42 46 46 44 81 81 83 44 44 46 4c 81 81 83 44 46 46 48 81 81 84 4c 46 46 5e 81 81 83 34 4a 4e 15 81 81 81 99 4e 3a 81 81 81 81 72 54 0c 54 81 81 81 50 56 6a 54 81 81 06 4e 3a 61 5e 9e 81 56 52 44 60 48 3a 81 54 54 44 42 68 48 81 4e 54 4a 42 5c 52 81 3e 40 3e 3c 40 3e 81 30 40 3a 44 48 34 81 2e 4a 34 40 40 42 81 40 3c 48 4c 4e 27 81 34 4a 46 2e 4e 10 81 28 4c 48 30 44 19 81 32 32 22 30 40 1f 81 3a 2e 32 30 44 1e 81 34 32 25 24 54 1a 81 46 28 36 28 48 12 81 2d 1b 36 29 3c 10 81 23 28 34 2c 4c 07 81 30 24 11 1d 24 0c 81 28 0f 08 0a 20 fc 81 24 1a 14 1a 1d ff 81 1b 0d 0c 1f 29 0b 81 16 25 1d 1d 42 0a 81 10 20 0b 1d 36 12 81 10 1f 1b 0d 44 0b 81 22 38 28 36 54 12 81 0a 23 11 1a 28 03 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 89 81 81 81 81 81 de ca 81 81 81 81 81 46 26 81 16 82 83 81 18 90 f0 21 81 81 ba f0 e8 3e fd 81 94 60 07 46 d3 11 82 36 1a 3a 24 5e 2f ba 29 06 3a 1b 12 64 d3 1e 2c 1e 15 aa f0 89 25 02 d8 48 f4 c7 81 5c 78 30 7b 16 36 82 81 16 ea a2 d9 24 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 82 82 81 82 83 81 81 81 83 3a 84 81 81 81 81 81 40 81 d2 81 81 81 5a 4a 81 2c 83 82 81 52 40 48 2a 84 82 23 4e 5c 3c 58 81 81 56 4e 5c 5e 1d 81 28 2b 48 6b 61 60 81 3a 16 32 70 66 68 be 4e 30 30 48 40 40 ee 44 46 44 46 4a 4a 81 77 75 6f 68 6c 64 81 b8 d0 b2 9c 99 82 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 32 84 ce 81 81 81 81 30 48 4e 81 81 81 81 52 50 5a 81 81 81 1e 9b 30 cd 81 81 82 67 81 81 81 81 88 81 5c 85 81 76 81 81 a2 73 81 b6 30 81 c3 3e 44 81 6e 60 81 0a d4 3e 79 6d 52 81 1b fa 52 4e 50 54 f1 52 4e 60 5c 4e 56 ac 4e 50 52 25 58 50 81 2a 78 78 81 6e 7c 81 81 b2 81 81 e0 aa 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 30 2d 81 81 81 81 81 21 3a 81 81 81 81 81 1a 38 81 81 81 81 81 19 2b 81 81 81 81 81 21 2d 81 81 81 81 81 28 28 81 81 81 81 81 2e 1d 81 81 81 81 81 56 20 81 81 81 81 81 75 1c 81 81 81 81 81 71 19 81 81 81 81 81 7b 26 81 81 81 81 81 7c 29 81 81 81 81 81 7f 2c 81 81 81 81 81 77 30 81 81 81 81 81 71 2f 81 81 81 81 81 62 30 81 81 81 81 81 4a 32 81 81 81 81 81 32 38 81 81 81 81 81 20 3c 81 81 81 81 81 17 3c 81 81 81 81 81 1f 3e 81 81 81 81 81 14 3e 81 81 81 81 81 0b 3e 81 81 81 81 81 fb 3a 81 81 81 81 81 e5 3c 81 81 81 81 81 cb 40 81 81 81 81 81 be 4a 81 81 81 81 81 9b 17 81 81 81 81 81 81 81 81 81 81 81 ac 34 34 a0 81 81 81 ba 54 56 ca 81 81 81 a4 82 89 a4 81 81 81 ac b6 b8 a8 81 81 81 b2 b6 b4 aa 81 81 81 b2 a8 b8 ae 81 81 88 b6 ae a6 ae 81 81 94 b4 b4 b0 b6 81 81 a2 be b0 b4 dc 81 81 b4 be a4 b6 03 81 81 be ae ae be 16 81 81 c3 9e b2 be 1d 81 81 c7 8f b2 c7 22 82 81 ca 84 b4 d3 28 8b 81 bc 86 ba df 16 8d 81 a6 89 ba ec ee 88 81 a8 99 a6 ff b4 8f 81 be a6 aa 14 b4 96 81 ba 90 b2 ff b4 a2 81 b0 9d b4 14 a2 aa 81 b6 be b4 1d 92 ae 81 ac ba c9 24 84 b4 81 c0 ef c2 1d d7 b8 81 c9 c9 2d c9 b0 c2 81 a4 81 c9 81 81 c7 81 97 81 9b 81 81 90 81 81 81 81 81 81 81 81 81 81 eb d9 82 81 81 81 81 7f 7f 81 81 81 82 81 46 42 81 81 81 81 42 5c 5a 3c 81 81 82 44 52 58 44 82 81 81 3c 36 38 38 81 81 81 42 40 44 3e 81 81 81 46 3e 3e 46 81 81 81 4c 34 32 4a 81 81 81 4a 38 36 6c 81 81 81 6c 3a 3a 7f 81 81 81 68 38 3e 56 81 81 81 38 3a 40 06 81 81 81 df 42 40 be 93 81 81 81 42 44 81 d8 81 81 81 3c 3c 81 15 81 8f 81 40 36 81 2d 81 94 81 42 40 81 30 81 ac 81 3c 3c d2 34 81 c3 b6 3e 3c 28 17 81 c3 11 46 42 46 f9 81 c5 32 44 3e 4c 18 81 d3 3c 3e 3e 46 19 81 b4 3c 40 3e 3a fd 81 81 52 3c 3a 4e e2 81 81 14 4e 4c 40 dd 81 81 81 d0 de 81 e8 81 81 81 81 81 81 81 81 81 81 8a e4 81 81 81 81 7f 7f 72 81 81 81 81 61 69 6a 81 81 81 81 58 6c 6c 81 81 81 81 7f 69 65 81 81 81 81 7f 6a 69 81 81 81 81 7f 6a 69 81 81 81 81 7f 68 69 99 81 81 81 78 67 67 ac 81 81 81 77 67 68 c4 81 81 81 74 69 67 cc 81 81 81 7f 6b 65 b8 81 81 81 7f 6c 65 83 81 81 81 7f 6d 65 81 81 81 81 7f 6c 64 81 81 81 81 7f 6d 65 83 81 81 81 7f 6e 66 95 81 81 81 7f 6f 65 a0 81 81 81 7f 70 66 be 81 81 81 7f 71 67 d8 81 81 81 7f 72 67 e9 81 81 81 7f 72 6a f6 81 81 81 7f 72 6f 01 81 81 81 7f 71 71 13 81 81 81 7f 71 74 28 81 81 81 7b 6b 6b 4e 81 81 81 7f 7f 7f ec 81 81 81 c2 1a 1d 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 9d 81 81 81 81 81 de 4e a6 81 81 81 81 5a 05 5e 81 81 81 81 08 c8 f7 81 81 81 81 36 07 dc 81 81 81 81 25 fc fb 82 81 81 81 38 27 3a 82 82 84 38 2f 29 40 82 85 81 0c f8 1e 2b 81 81 81 1c 06 22 1c 81 f4 2f 2f 36 1f 34 81 0a 17 02 2b 12 23 a8 d6 16 02 21 17 22 1a 3a 05 25 1a 25 3c c8 36 e1 2c 32 4c 48 81 44 19 21 46 3e 3a 81 48 44 3c 52 4a 4e 81 81 5e 6f 81 29 d4 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 82 b4 a8 81 81 81 81 83 60 46 81 81 81 81 81 4c 40 81 81 81 81 ba 46 48 85 81 81 81 36 42 44 e5 81 81 81 40 44 40 2b 81 81 81 46 44 3e 48 81 81 81 48 46 42 4c 81 81 81 48 44 3e 4c 81 81 81 46 44 40 50 81 81 81 46 40 3e 50 81 81 81 46 40 3e 4c 81 81 81 46 40 3e 48 81 81 81 48 40 3e 48 81 81 81 48 44 3e 4e 81 81 81 48 46 3e 4c 81 81 81 46 46 46 4c 81 81 81 48 46 46 4e 81 81 81 4e 46 46 50 81 81 81 46 44 46 5a 81 81 81 f5 42 46 e3 81 81 81 3c 40 46 e2 81 81 81 58 3e 40 44 81 81 81 52 40 40 58 81 81 81 52 3c 3e 50 81 81 81 54 3c 4a 4e 81 81 81 5a 5a 52 52 81 81 81 96 fe 96 94 81 81 81 81 81 81 81 81 81 81 81 81 da 82 81 81 81 81 81 34 83 81 81 81 81 11 81 81 81 81 81 81 48 81 81 81 81 81 81 d7 81 b4 81 81 81 81 81 81 dc 81 81 86 84 81 83 10 82 81 81 81 81 81 1c 81 81 b0 81 81 81 58 81 81 5c 3e 12 3c 2f 1b 81 3e 2f 40 38 46 52 81 2a 38 36 3e 06 4c 81 44 34 36 3e e7 42 81 63 3e 30 4a 20 44 81 6e 54 4a 56 fe 56 81 7a 5c 46 4a 38 52 81 7f 58 48 4e ff 5e 81 7f 58 4c 58 34 62 81 7f 58 54 4c 62 54 81 7f 58 5c 48 50 5c 81 7f 5c 58 52 56 5e 81 6c 5a 5c 5e 5e 60 81 64 5c 62 63 64 67 81 77 61 5a 5c 5e 62 81 71 63 6c 67 65 69 81 73 7f 56 58 52 38 81 b8 d9 81 81 81 81 81 81 81 81 be 81 81 81 81 81 83 2e 81 81 81 81 81 ea 87 83 81 81 81 81 d8 81 87 81 81 81 81 99 81 81 81 81 81 82 81 88 81 81 81 81 85 81 83 81 81 81 81 81 81 81 c3 81 81 81 81 84 81 08 81 81 81 81 83 81 22 81 81 81 81 81 81 01 81 81 81 b0 81 81 c7 81 81 81 f4 81 81 91 81 81 81 ff 81 81 81 81 81 81 10 83 84 81 81 81 81 ba 81 81 81 81 81 81 81 81 81 83 81 81 81 34 34 38 3a 81 81 81 5a 48 60 48 81 81 81 56 5a ae 50 81 81 81 5a 76 81 54 81 81 81 67 6f a8 58 81 81 81 62 61 7f 60 81 81 81 56 54 5a 5c 81 81 81 60 58 5a 58 81 81 81 3c 54 5c 56 81 81 81 58 72 7d 46 81 81 81 02 11 81 81 81\n",
            "=======\n",
            "byte1: 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 a6 81 81 81 82 d5 81 f8 81 81 81 82 10 81 eb 81 81 81 85 f9 27 0d 81 81 81 81 01 28 11 81 81 82 81 0a 26 1f 81 81 81 da 1a 2a 2a 81 81 81 09 23 20 2a 81 83 81 e4 1d 1d 1d 81 81 dd f4 1b 18 17 81 cd fc 00 09 22 22 c5 f3 00 ff 10 23 23 2a e5 e7 f9 28 46 3e ff 38 f9 3a 7f 7c 5c 81 eb 52 3e 81 50 1f 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 a6 81 81 81 81 52 7f 6e 81 81 81 81 73 74 68 42 81 81 e7 63 66 68 7c 81 81 69 7f 63 66 65 81 81 78 16 7f 68 6a 81 81 7f 90 40 7f 6a 81 81 7f 32 81 c2 6c 81 81 7f 4c 81 81 6c 81 81 7f 67 81 b6 6e 81 81 7f 7f 1e df 6d 81 81 7f 73 7f 66 70 81 81 7f 69 68 7b 73 81 81 7f 73 6a 64 7f 81 81 7f 7f 6c 68 7f 81 81 7e 7f 6b 6b 7f 81 81 77 7f 6a 6a 7f 81 81 76 7f 6b 6d 7f 81 81 73 7f 6c 6f 63 81 81 70 7a 6c 6d 4c 81 81 73 70 6c 6b 2c 81 81 7b 69 6c 6b fe 81 81 7c 68 69 6a 01 81 81 73 71 6d 70 b4 81 81 70 7f 5e 5e a0 81 81 75 81 81 81 a2 81 81 7f 81 81 81 a8 81 81 4e 85 83 83 84 81 81 81 81 1a 0e 81 81 81 81 81 7f 75 81 81 81 81 81 64 5c 81 81 81 81 81 69 5e 81 81 81 81 98 69 5e 81 81 81 81 c4 67 60 81 81 81 81 f3 6e 61 81 81 81 81 28 7a 60 81 81 81 81 50 61 62 81 81 81 81 60 22 60 81 81 81 81 75 c9 5a 81 81 81 81 7f 88 5c 81 81 81 81 7f 81 5e 81 81 81 81 7f 81 5c 81 81 81 81 7f 81 5e 81 81 81 81 7f 81 63 81 81 81 81 63 81 66 81 81 81 81 4c 81 63 81 81 81 81 18 81 6a 81 81 81 81 da 81 6d 81 81 81 81 a0 81 6e 81 81 81 81 81 a2 6e 81 81 81 81 81 c5 71 81 81 81 81 81 01 71 81 81 81 81 81 54 70 81 81 81 81 81 52 77 81 81 81 81 81 77 7f 81 81 81 81 81 c8 30 81 81 81 81 96 e4 dd 81 81 81 81 eb 6f 50 81 81 81 81 00 56 4a 81 81 81 81 13 64 56 81 81 81 81 f4 5a 60 81 81 81 81 f3 5a 4e 81 81 81 81 f1 3e 0c 81 81 81 81 c8 14 ed 81 81 81 81 d2 14 e5 81 81 81 81 c7 18 eb 81 81 81 81 be 0c e2 81 81 81 81 ba 00 d7 81 81 81 81 a6 f8 cf 81 81 81 81 8e fd c1 81 81 81 81 84 0f ba 81 81 81 81 81 fa be 81 81 81 81 81 ed cd 81 81 81 81 81 c5 b2 81 81 81 81 81 89 1d 81 81 81 81 82 81 54 81 81 81 81 81 81 62 81 81 81 81 81 81 67 81 81 81 81 81 81 69 81 81 81 81 81 81 6b 81 81 81 81 81 81 6f 81 81 81 81 81 81 6d 81 81 81 81 81 81 78 81 81 81 81 81 81 13 81 81 81 82 81 ca be 81 81 81 82 d0 22 36 81 81 81 81 0f 1b 02 22 81 81 81 e8 34 d6 1b 81 81 9e ed 13 13 12 82 81 c2 ed cb 17 19 81 81 ed e3 c9 f4 21 81 81 08 d4 f4 ee 42 81 81 08 cf ed f3 52 81 81 fd e1 f0 f2 44 81 81 f5 e7 e3 f1 3a 81 81 f3 e5 e1 f9 3c 81 81 f7 e6 e8 00 44 81 81 f4 ed f8 fc 4e 81 81 f7 ee 02 f7 58 8d 81 f6 f2 f9 f4 56 a4 81 ee fd f6 f0 40 ba 81 e7 f9 f5 f3 13 c7 81 f0 05 eb f5 f1 d5 81 07 fc e7 ee e3 08 81 2a ec ee e1 b4 f0 81 8d e7 f5 eb 9b 81 81 81 e6 07 f0 cb 81 81 84 e6 ed f8 08 81 81 81 ec e2 00 20 81 81 84 f1 fe f4 32 81 81 83 38 2c 2f be 81 81 81 81 ee e6 81 81 81 81 81 3e 30 81 81 81 81 8f 60 4c 81 81 81 81 97 5a 4c 81 81 81 81 ea 5c 50 81 81 81 81 4c 58 48 81 81 81 81 74 5a 42 81 81 81 81 77 54 48 81 81 81 81 6c 5c 4e 81 81 81 81 68 75 48 81 81 81 81 5e 61 46 81 81 81 81 4e 13 4a 81 81 81 81 46 a2 4c 81 81 81 81 3a 81 4c 81 81 81 81 32 81 4a 81 81 81 81 2c 81 4c 81 81 81 81 34 81 52 81 81 81 81 3e 81 74 81 81 81 81 3c 81 58 81 81 81 81 36 81 6e 81 81 81 81 42 81 76 81 81 81 81 08 81 58 81 81 81 81 9c a2 4a 81 81 81 81 81 d9 44 81 81 81 81 81 28 38 81 81 81 81 81 44 2a 81 81 81 81 81 5c 1c 81 81 81 81 81 6a 29 81 81 81 81 81 05 d2 81 81 81 81 81 a4 81 81 81 81 81 82 7e 0b 81 81 81 81 d9 0b a0 81 81 81 81 d5 52 81 81 81 81 81 dc 70 a8 83 81 81 81 b6 c1 9d 95 81 81 81 b2 d5 c0 9e 81 81 8d a6 db be a8 81 81 9d ba cd 94 ac 81 81 ac c2 d5 9d 9e 81 81 b6 d6 d5 99 9e 81 81 be e7 d1 9b 9c 81 81 c4 cf cc 9d 8e 81 81 cb c7 cc 91 88 81 81 ca ba cb 87 81 81 81 cc c4 d0 81 81 81 81 cc ba cd 85 81 81 81 cb b2 ca 86 81 81 81 cc a4 c4 8f 81 81 81 cf 96 cb 99 81 81 81 ce 95 c7 97 81 81 81 cc 96 c9 a0 84 81 81 d2 93 c8 9b 8e 81 81 cf b4 cc a2 91 81 81 c7 b4 c1 a8 ae 81 81 c6 81 81 81 f0 81 81 d5 81 81 81 cf 81 81 c8 81 81 81 9f 81 81 81 84 18 81 81 81 81 81 81 46 84 81 81 81 81 a8 38 c2 81 81 81 81 1d 11 b6 95 81 81 81 dc e8 b8 f6 81 81 ae a2 81 81 c2 81 81 e1 1e f0 c6 d3 81 81 23 c8 ae b2 d3 81 81 30 c3 89 be e9 81 81 21 e7 a8 99 23 81 81 ee fd b8 b4 ef 81 81 46 ee be a6 a6 81 81 5e 9a 86 81 1a 81 81 d8 04 c8 c5 d0 81 81 fe 07 f3 ca b8 81 81 f6 99 8a 81 ea 81 81 fa db b2 96 1b 81 81 9b ec b6 9a 22 81 81 ae 08 d2 b0 0d 81 81 04 c6 a6 82 6f 81 81 8a cb 8c 81 0c 81 81 ba 3a 05 eb 21 81 81 d0 c3 ac 91 13 81 81 ec d2 ac 81 06 81 81 98 d7 f1 a0 c8 81 81 db f1 f3 ac c1 81 81 1f e5 05 aa d7 81 81 cd 81 e7 81 a4 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 c0 ba 81 81 81 82 81 5c d9 81 81 81 84 b2 a6 3c 44 81 81 81 7e 81 81 52 e9 f0 c3 0f d3 28 b4 05 09 cb e3 fe 9a 81 8b 91 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 be 81 81 81 81 81 81 36 81 f6 81 81 81 6c 24 81 4c 81 82 87 f7 fb a6 48 81 81 3e ef 09 56 08 81 a4 c2 f4 09 09 db fe 02 f8 f3 36 14 2b 3c 24 ec 4c 61 48 52 fd 3c 48 3e e9 81 8d 9c 8e c8 81 81 98 98 9e b4 81 a8 b6 a8 b6 81 ae ca bc ae aa ae 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 e2 cd 83 81 81 81 c1 73 23 81 81 81 81 44 60 2b 97 81 81 81 0e 65 12 30 81 81 81 03 7f 0f 1a 81 81 92 16 48 12 02 81 81 b2 17 30 1a 0e 81 81 ce 18 36 1c 17 81 81 e9 05 30 14 23 81 81 f1 14 40 0f 4a 81 81 ff 1e 44 18 5e 81 81 1e 30 56 12 54 81 81 38 0b 48 03 61 81 81 3c 16 3c 0e 50 81 81 36 13 50 1b 42 81 81 30 2e 50 1c 40 81 81 34 36 38 0b 3a 81 81 26 42 44 02 40 81 81 1f 34 50 1a 44 81 81 24 32 3e 13 22 81 81 1f 0a 48 22 27 81 81 1b a2 16 fd f3 81 81 1b 81 81 81 de 81 81 1a 84 81 81 d1 81 81 1e 84 81 81 c4 81 81 1a 84 81 82 ba 81 81 26 86 81 81 b6 81 81 cc 82 81 81 9e 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 87 81 81 81 81 81 cd 36 94 81 81 81 81 d3 1a 90 81 81 81 81 32 24 dc 82 81 8a fa 9a 06 30 81 82 81 1a 81 f1 b4 82 81 ec 9f 81 22 81 81 81 2a a2 81 2a 81 82 81 b4 95 81 4a 81 85 b2 3c 82 c3 42 84 81 01 8f 81 40 42 84 22 24 a8 f1 52 32 20 be f6 2c 22 ae 19 11 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 8a 84 81 23 81 81 81 2c 81 81 07 81 82 81 48 8c 03 eb e5 81 84 48 f1 42 e1 0b 96 81 5a 36 dd eb ed ff b0 7f 0f 0b fb f5 e9 f5 65 e9 11 09 df dd 0f 44 19 13 17 09 0d 27 7b 52 3e 34 27 36 44 07 09 27 2c 25 17 c6 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 ae 81 81 81 81 81 81 c8 81 81 81 81 81 81 3e 81 81 81 81 81 2c 25 81 81 81 81 81 54 10 81 81 81 81 81 4e 05 81 81 81 81 81 56 ea 81 81 81 81 82 56 eb 81 81 81 81 81 58 0a 81 81 81 81 81 4c 32 81 81 81 81 81 4c 4a 81 81 81 81 81 50 64 81 81 81 81 81 50 4c 81 81 81 81 81 54 50 81 81 81 81 81 56 54 81 81 81 81 81 56 52 81 81 81 81 84 56 4e 81 81 81 81 a2 54 48 81 81 81 81 cb 54 44 81 81 81 81 e6 54 44 81 81 81 81 f3 56 42 81 81 81 81 0d 56 44 81 81 81 81 1c 54 42 81 81 81 81 28 54 42 81 81 81 81 30 56 46 81 81 81 81 6a 4c 44 81 81 81 81 03 7a 5a 81 81 81 81 81 e3 da 81 81 81 81 81 f6 81 81 81 81 81 81 76 38 81 81 81 81 81 5a 67 84 81 81 86 3e 3e 66 81 81 81 81 71 56 66 d5 81 81 81 63 76 66 72 81 81 81 65 6b 65 70 81 81 82 65 64 67 62 81 81 d9 68 6a 65 63 81 81 13 67 68 69 67 81 81 44 65 67 63 68 81 81 66 65 64 66 6b 81 81 7d 6a 68 69 6b 81 81 7f 6c 6a 66 6c 81 81 7f 6c 6b 68 6a 81 81 7f 6d 68 69 6a 81 81 7f 6d 68 6a 69 81 81 7f 6c 69 68 6d 81 81 7f 6c 6b 69 72 81 81 7b 6d 69 67 72 81 81 75 7d 69 69 61 81 81 6c 7f 6a 68 3c 81 81 68 7f 69 68 03 81 81 6b 7f 6b 69 c0 81 81 6b 7d 6b 6a b8 81 81 77 77 67 68 c7 81 81 95 77 6e 6b 81 81 81 81 6f 68 66 81 81 81 81 81 81 82 81 81 81 81 f7 66 63 81 81 81 81 f3 56 0a 81 81 81 81 04 5a 14 81 81 81 81 03 4c 36 81 81 81 81 0a 48 36 81 81 81 81 ff 3a 2e 81 81 81 81 ec 32 3a 81 81 81 81 e8 36 28 81 81 81 81 ce 2d f0 81 81 81 81 be 3c e2 81 81 81 81 b8 3e e7 81 81 81 81 b2 38 ec 81 81 81 81 9f 32 ea 81 81 81 81 9a 22 e5 81 81 81 81 8b 14 de 81 81 81 81 88 0d e1 81 81 81 81 86 0a e6 81 81 81 81 81 09 e0 81 81 81 81 81 09 fb 81 81 81 81 81 08 2b 81 81 81 81 81 0c 3e 81 81 81 81 81 0e 44 81 81 81 81 81 19 42 81 81 81 81 81 15 44 81 81 81 81 81 18 3e 81 81 81 81 81 30 4a 81 81 81 81 81 87 06 81 81 81 81 90 ec 30 81 81 81 81 4a 34 40 84 81 81 81 14 f8 27 1b 81 81 d6 0b f8 ec 02 81 81 11 11 df e5 ec 81 81 0b fb c6 e5 f5 81 81 11 ec cc e5 05 81 81 f8 f2 d9 c9 08 81 81 fb f5 d2 cf 2e 81 81 f8 ef d6 d9 21 81 81 e5 e8 cf be fb 81 81 cf 18 c6 cf f2 81 81 c3 21 be d2 e8 81 81 c6 21 c9 d6 cc 93 81 c3 2b d6 d9 b8 a2 81 bc 14 df d6 b8 a6 81 bc 14 df d9 ac a6 81 be 11 df d9 9d b0 81 c9 05 dc d9 97 b6 81 c6 02 e2 d9 b0 bc 81 c3 05 02 e5 be c3 81 cc f8 f2 dc b2 c6 81 d2 ec dc be ac c9 81 d6 ac 9d 81 84 cc 81 dc be c6 97 a0 cc 81 ef 1e b6 81 81 cf 81 f2 b2 d9 f8 81 d6 81 e2 81 a2 d9 81 d2 81 81 81 9b d8 81 81 81 82 81 5e 36 86 81 81 81 8c 54 ee 81 81 81 81 12 f9 5a b0 81 81 11 12 f8 66 72 81 81 32 fa 9d e6 1a 81 81 44 1b 81 90 0c 81 81 44 3a 86 ee 7f 81 81 4c 62 81 6a f9 81 81 4e 6c 81 7e f7 81 81 30 56 ae 14 26 81 81 fb 2e ea 11 58 81 81 ba 42 de 3a 65 81 81 8c 3c a0 17 50 a4 81 81 e7 91 14 44 ec 81 81 dd 81 fb f3 fd 81 b4 ef 81 c9 9e ce 81 eb 40 c1 c9 81 ae 81 4c 64 08 c1 81 93 81 7d 67 58 cc 81 86 81 58 7b 78 f2 81 92 81 3c 58 68 ea 81 96 81 ff 1d 30 c5 81 c0 81 ea fc 06 df 81 d5 81 fc e3 ea 38 81 01 81 fc 2c d5 5a 81 d7 81 30 06 14 4a 81 c8 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 be 81 81 81 81 81 83 1d 32 34 38 16 81 24 2b 3a 3e 44 36 82 ff 34 32 38 3e 2f 83 e8 32 38 36 36 34 85 00 36 36 36 34 24 86 05 36 32 32 3a 23 85 09 36 34 34 36 2c 85 f3 30 34 38 36 28 83 e6 36 32 34 32 29 81 58 2d 25 2f 2d 1b 81 0c 38 36 36 38 38 81 f5 4c 36 3a 38 34 84 f1 15 3a 38 34 34 81 25 30 3e 30 30 32 9a 2c 4a 56 50 4e 2e e9 cc 07 93 93 94 98 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 b4 82 34 81 81 81 81 58 5c 40 81 81 81 b2 3a 3c 3c 52 81 81 48 3e 48 40 3e 81 81 42 3e 40 3e 38 81 81 64 40 3c 36 3c 81 81 6e 34 60 4e 44 81 81 61 5e 2a 42 44 81 81 5a 34 2e f8 40 81 81 61 2f 64 17 58 81 81 81 62 3e 60 f4 81 81 81 42 40 67 81 81 81 81 44 42 74 81 81 81 81 44 46 68 81 81 81 81 46 48 42 81 81 81 81 46 4a 42 81 81 81 81 46 4a 46 81 81 81 81 48 4a 46 81 81 81 81 48 4a 46 81 81 81 81 46 4c 46 81 81 81 81 46 4c 48 81 81 81 81 46 4c 48 81 81 81 81 4a 4a 48 81 81 81 81 4c 46 46 81 81 81 81 4a 44 46 81 81 81 81 42 44 44 81 81 81 81 4e 42 4a 81 81 81 81 29 42 44 81 81 81 81 2e 34 69 81 81 81 81 58 f1 64 1f 81 81 10 46 6a 60 6d 81 81 58 3a 34 6e 5c 81 84 3a 4a 2e 32 58 81 88 3a 56 60 52 5a 88 81 36 4c 52 44 63 fa 81 32 44 3e 3e 3c 36 81 38 3e 48 44 44 3a 81 46 3c 36 42 44 52 81 34 3a 3e 36 4a 38 81 4e 48 4c 34 48 46 81 32 4c 40 3e 36 3e 81 14 12 1e 1b 02 46 86 25 17 1e 27 0c 3c 9a 0f 29 27 1d 0d 2b a4 0f 1f 30 20 11 3e a6 fa 27 2d 25 0d 2b 9e f1 30 32 28 17 23 99 f0 1a 0f 0b 0b 1b 9a ee 0d 10 0b 04 25 81 06 19 19 15 27 20 81 ff 16 0b 16 06 24 81 ff 06 19 10 02 20 81 0c 0c 1a 15 ec 22 81 f9 19 15 0f ba 20 81 04 1e 2e 22 9f 24 81 d3 29 0b 07 88 ff 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 1b 81 81 82 81 81 81 5e f9 81 23 85 84 81 23 46 e3 22 81 81 fb 19 23 54 08 ae cb 01 17 38 fe 25 2f 2d 0d 26 3e 54 f8 36 32 56 f2 5c e0 99 11 3e 7f a2 0e a6 ed 48 15 d1 db 34 e8 e6 81 54 5c 77 61 4a 5c 81 a2 1f fd ac 0c f7 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 83 81 c4 82 81 81 81 81 81 3c 81 f3 81 81 82 b8 2b 81 71 81 81 81 5a 28 8f 46 81 83 81 48 4e 6a 40 83 81 40 44 56 09 4e 81 df 4e 5c 60 75 4a 91 6a 3e 58 54 5a 64 1f 30 30 5e 6a 64 5c 26 56 1f 52 46 3e 48 52 44 40 42 48 48 4a fb 6e 74 6c 6a 6c 68 81 c0 c9 a4 9b 9b 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 84 81 dc 81 f4 81 81 82 81 4e 52 6b 81 81 81 2d 60 67 70 81 81 81 ba c8 28 0d 81 81 81 81 81 81 ec 81 86 81 81 85 81 66 81 81 2a 76 81 62 54 81 b2 24 6a 81 67 52 dc 2e a8 46 fe 58 4a 29 10 fa 62 4c 50 4e 50 56 5a 5a 5c 50 44 21 50 56 58 f5 50 40 81 54 73 20 81 71 4e 81 81 b2 81 81 a8 a4 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 50 2b 81 81 81 81 90 2d 71 81 81 81 81 ae 1c 5c 81 81 81 81 c1 23 5e 81 81 81 81 c2 21 4a 81 81 81 81 d1 1f 46 81 81 81 81 d9 50 4c 81 81 81 81 d6 22 4c 81 81 81 81 d3 e4 50 81 81 81 81 d1 d9 52 81 81 81 81 cb be 56 81 81 81 81 cc 91 56 81 81 81 81 c8 81 40 81 81 81 81 cc 81 40 81 81 81 81 d3 81 40 81 81 81 81 d1 81 40 81 81 81 81 d2 81 40 81 81 81 81 d9 81 40 81 81 81 81 de 81 44 81 81 81 81 de 81 44 81 81 81 81 dd 81 44 81 81 81 81 df 81 44 81 81 81 81 e7 81 44 81 81 81 81 e4 81 44 81 81 81 81 e3 81 40 81 81 81 81 d8 81 48 81 81 81 81 da 81 50 81 81 81 81 bc 81 2f 81 81 81 81 81 81 81 81 81 81 81 ae ff 77 81 81 81 81 b8 62 f5 b0 81 81 81 ac ae 8b c5 81 81 90 ae 9e be b6 81 81 a8 b4 a4 b2 b2 81 81 be b2 be b0 b6 81 81 c9 b2 a8 a6 c3 81 81 d8 b6 9e b2 c5 81 81 de b4 b4 b6 ce 81 81 d3 b6 ec c0 d7 81 81 c3 ba c0 c2 e7 81 81 a6 c2 b6 c3 01 81 81 99 c7 da c3 12 81 81 a6 c5 c5 c7 22 81 81 ca c3 b4 c2 2b 81 81 f8 b6 aa b4 36 81 81 e5 b6 ef b4 46 81 81 aa b4 c3 d5 d8 81 81 90 ae b4 a4 c9 81 81 8f ba de a4 d5 81 81 8f bc fd a2 f5 81 81 8d c7 a6 96 08 81 81 c0 16 e8 ce dc 81 81 ec c5 fd c7 8f 81 81 f1 81 81 81 81 81 81 b4 81 84 81 82 81 81 81 81 81 81 81 81 81 81 82 0c 81 81 81 81 81 81 6c a6 81 81 81 81 c6 68 6e 81 81 81 83 56 77 44 d9 81 81 81 3a 46 48 52 81 81 81 42 3e 3e 46 81 81 81 3e 48 44 46 81 81 81 44 42 46 44 81 81 81 40 3a 32 4a 81 81 a0 46 44 36 4e 81 81 be 4a 44 42 52 81 81 ef 48 46 40 50 81 81 15 40 4a 3c 63 81 81 38 38 4e 3e 70 81 81 5e 30 52 3c 52 81 81 48 25 4a 4a 0a 81 81 52 3a 46 44 ce 81 81 52 5a 4e 36 b6 81 81 52 74 4e 42 b6 81 81 56 6d 50 3a b6 81 81 74 58 4c 3a f5 81 81 75 4a 4c 3c 0a 81 81 75 44 4a 3a 21 81 81 79 40 4a 3e 42 81 81 48 44 40 3a 50 81 81 2e 70 50 4c f9 81 81 52 81 d1 cb aa 81 81 94 81 81 81 81 81 81 81 cb 81 2b 81 81 81 81 73 7f 6d 81 81 81 81 68 56 5e 81 81 81 81 6d 66 62 81 81 81 81 6e 6d 66 81 81 81 81 6f 69 66 81 81 81 81 6c 6b 66 81 81 81 81 6c 69 65 81 81 81 81 6c 66 62 81 81 81 81 6e 67 64 81 81 81 81 6c 68 66 81 81 81 81 6a 69 64 81 81 81 81 6f 69 65 81 81 81 81 72 68 66 81 81 81 81 71 68 68 81 81 81 81 71 69 69 81 81 81 81 70 69 69 81 81 81 81 71 69 69 81 81 81 81 70 6a 6a 81 81 81 81 70 6b 6b 81 81 81 81 71 6b 6a 81 81 81 81 71 6b 68 81 81 81 81 6c 6b 68 81 81 81 81 6c 6b 68 81 81 81 81 70 6d 69 81 81 81 81 6f 67 68 81 81 81 81 7b 7f 7b 81 81 81 81 e5 25 04 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 78 07 8e 81 81 81 83 2f 64 32 81 81 81 84 13 cc fb 81 81 81 81 1d f9 0a 81 81 81 81 32 ea 42 81 81 81 fe 27 29 60 81 81 85 23 12 30 54 81 83 81 05 03 24 48 81 81 cc 2c 28 29 4c 81 e5 34 1f 27 1e 48 3e 27 03 25 30 04 46 63 ca 11 23 2b 06 4c 56 0d f9 1b 1e 30 46 5a 1f d9 25 38 46 48 fa 42 06 2f 4c 42 3c 81 52 38 46 3a 4e 54 81 ba 3c 38 81 e8 ae 83 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 85 15 81 82 81 81 81 81 5c 81 82 81 81 81 c6 4c 4e 83 81 81 81 50 3c 46 81 81 81 81 48 4c 3e 81 81 81 81 4a 4a 46 81 81 81 81 50 46 48 81 81 81 81 4e 46 40 81 81 81 81 4e 46 3a 8e 81 81 81 46 42 3c 9e 81 81 81 32 44 3c ae 81 81 81 2d 44 3e bc 81 81 81 1b 46 3e d1 81 81 81 f4 46 40 dd 81 81 81 f1 46 44 ed 81 81 81 0f 44 46 f7 81 81 81 38 46 44 fa 81 81 81 50 46 46 fb 81 81 81 48 48 4a f8 81 81 81 48 4a 4e 1e 81 81 81 52 4e 52 8d 81 81 81 50 58 58 81 81 81 81 52 5e 60 81 81 81 81 58 68 66 8e 81 81 81 5c 70 6b c9 81 81 81 5a 6a 6e 17 81 81 81 60 7f 7a 40 81 81 81 b8 d7 81 81 81 81 81 81 87 81 81 81 81 81 81 81 81 82 81 81 81 81 11 52 81 81 81 81 81 38 ae 85 81 81 81 84 81 81 86 81 81 81 8c 81 81 81 81 81 81 81 81 83 81 81 81 85 81 81 88 81 82 81 81 81 81 81 81 81 82 82 81 81 81 81 81 81 4c 1c 42 4a ff 13 81 52 3c 3e 3c 1b 3c 81 54 3c 3a 32 3c 3c 81 5c 2b 3c 38 4e 46 d9 61 21 36 44 54 52 10 5e 46 4c 5a 14 5c 36 5a 56 4c 5a 15 5c 3c 58 52 54 56 fb 5c 3c 54 58 50 58 5c 5e 3a 50 56 4e 60 58 52 3a 50 58 54 4c 54 56 29 4a 5a 5a 4c 56 5c c6 48 58 5a 60 5e 5c 81 4c 5e 62 63 65 61 81 67 65 5e 5a 5e 60 81 62 62 68 67 64 66 81 67 7f 56 5a 54 2d 81 cf ca 81 81 81 81 81 81 81 81 81 81 81 81 81 81 3e c7 81 81 81 81 81 b6 29 81 81 81 81 84 81 e9 81 81 81 81 84 81 81 83 81 81 81 81 84 81 87 81 81 81 81 83 81 81 81 81 81 81 81 87 81 81 81 81 a0 81 88 81 81 81 81 ce 81 83 a0 81 81 81 e8 81 81 e5 81 81 81 c5 81 81 29 81 81 82 b4 81 81 2f 81 81 81 81 81 81 03 81 81 86 81 84 83 ba 81 81 89 81 81 81 81 81 81 83 81 81 81 84 81 81 81 3e 3c 32 3c 81 81 81 4a 56 50 48 81 81 81 4e 19 36 4c 81 81 b8 4e f1 1b 4e 81 81 b8 4e 1e 3c 5a 81 81 81 52 76 73 62 81 81 81 50 52 58 5e 81 81 81 4e 58 5a 61 81 81 84 5a 58 5c 74 81 81 84 6c 66 7a 25 81 81 83 11 10 81 81 81\n",
            "=======\n",
            "byte2: 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 83 8c 81 81 81 81 81 81 ef 81 81 81 81 81 81 14 08 81 81 81 81 8c 21 32 81 81 82 81 f4 29 28 8c 81 81 84 0c 16 2d b0 81 83 81 ef 08 28 f8 83 81 9b f0 07 21 32 81 81 f6 02 26 1b 26 98 d6 f0 fe 21 11 3e df f0 08 00 15 11 44 02 df ed 02 3e 46 38 2c 2c ff 44 52 7b 4e 81 25 54 17 81 3c 18 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 8e 81 81 81 81 81 81 62 7f 6b 81 81 81 0a 6a 76 6f 81 81 81 7f 64 65 67 34 81 81 71 7f 6e 63 71 81 81 71 b0 72 7f 7a 81 81 70 81 81 8e 7c 81 81 6e 81 03 ac 79 81 81 6c 81 a6 9a 79 81 81 6c 83 5e 75 75 81 81 6d 81 81 95 6f 81 81 6b 06 4a 88 6e 81 81 69 7f 73 7f 6e 81 81 69 63 66 6b 6c 81 81 75 69 6a 72 6c 81 81 7f 64 6a 71 6b 81 81 7f 60 6a 70 6c 81 81 7f 60 6b 69 6f 81 81 7f 63 6b 65 76 81 81 7f 65 6b 62 7b 81 81 7f 68 6a 65 7c 81 81 7f 6c 6b 68 7f 81 81 7f 6a 68 69 7f 81 81 7f 6e 6c 6d 7f 81 81 7a 5c 60 5a 7f 81 81 72 81 81 81 72 81 81 79 81 81 81 79 81 81 46 82 83 83 2f 81 81 81 c4 f6 30 81 81 81 81 44 71 7f 81 81 81 81 73 67 7f 81 81 81 81 7f 62 7f 81 81 81 81 7f 65 71 81 81 81 81 7f 62 6a 81 81 81 81 79 75 71 81 81 81 81 77 48 7b 81 81 81 81 72 81 7f 81 81 81 81 6e 81 7f 81 81 81 81 6b 81 7f 81 81 81 81 69 81 7f 81 81 81 81 69 81 7f 81 81 81 81 68 81 7f 81 81 81 81 64 81 7f 81 81 81 81 66 81 7f 81 81 81 81 6d 81 7f 81 81 81 81 6f 81 7f 81 81 81 81 75 81 7f 81 81 81 81 78 81 7f 81 81 81 81 70 81 7f 81 81 81 81 62 81 7f 81 81 81 81 69 81 6d 81 81 81 81 19 81 6e 81 81 81 81 ca 81 6d 81 81 81 81 81 81 6e 81 81 81 81 81 ba 7c 81 81 81 81 81 81 25 81 81 81 81 fc d5 c7 81 81 81 81 78 54 0c 81 81 81 81 58 56 26 81 81 81 81 44 58 25 81 81 81 81 42 52 26 81 81 81 81 15 62 04 81 81 81 81 f8 50 e9 81 81 81 81 0b de d8 81 81 81 81 00 e2 d4 81 81 81 81 0a b2 d7 81 81 81 81 08 81 d0 81 81 81 81 03 81 cc 81 81 81 81 02 81 b2 81 81 81 81 08 81 b4 81 81 81 81 fe 81 a0 81 81 81 81 f3 81 a8 81 81 81 81 f7 81 b6 81 81 81 81 0a 81 b4 81 81 81 81 48 81 ef 81 81 81 81 4c 81 22 81 81 81 81 52 81 26 81 81 81 81 4c 81 0e 81 81 81 81 42 81 09 81 81 81 81 5a 81 00 81 81 81 81 44 81 ea 81 81 81 81 fb 81 cb 81 81 81 81 f3 81 ae 81 81 81 81 95 81 82 81 81 81 82 81 cd 81 81 81 81 81 01 2e 38 81 81 81 81 e8 26 17 9b 81 81 eb eb 1d 1e 1e 81 81 07 e2 38 04 2a 81 81 04 e5 4e ed 23 81 81 fc e5 09 ee 23 81 81 fb de dc fe 21 81 81 05 e1 ed 16 21 81 81 04 e6 ed 1d 28 81 81 ff e1 de 16 23 81 81 f1 e5 e5 0e 14 81 81 e6 e5 ed 0c 12 81 81 e2 e1 e7 0d 13 81 81 e3 e1 e5 0e 15 81 81 e6 dd ea 0f 15 81 81 f6 db f2 14 13 81 81 14 db eb 13 20 81 81 23 da e7 0e 2a 81 81 3a d8 eb 07 21 81 81 46 e2 f1 04 7e 81 81 ae ee fb 02 95 81 81 81 f3 08 fc 81 81 81 81 e9 ed f2 81 81 81 81 e9 fc f9 81 81 81 81 ea fc e5 88 81 81 81 48 17 46 81 81 81 81 9f f0 c8 81 81 81 81 40 1e 34 81 81 81 81 6b 61 54 81 81 81 81 6a 48 34 81 81 81 81 7c 42 42 81 81 81 81 64 5e 3e 81 81 81 81 40 52 30 81 81 81 81 2b 6f 34 81 81 81 81 2b 3c 36 81 81 81 81 20 81 30 81 81 81 81 2b 81 38 81 81 81 81 30 81 38 81 81 81 81 30 81 34 81 81 81 81 2f 81 23 81 81 81 81 2f 81 0e 81 81 81 81 30 83 fa 81 81 81 81 40 86 ec 81 81 81 81 46 84 f7 81 81 81 81 44 85 f5 81 81 81 81 48 81 14 81 81 81 81 50 81 46 81 81 81 81 61 81 58 81 81 81 81 5c 81 58 81 81 81 81 4c 81 5c 81 81 81 81 06 81 5e 81 81 81 81 bc 81 64 81 81 81 81 81 b0 6d 81 81 81 81 81 f5 76 81 81 81 81 81 b6 12 81 81 81 81 81 b8 81 81 81 81 81 7a 6e 81 81 81 81 81 fd 3c 85 81 81 81 81 e3 73 81 81 81 81 87 06 5a ae 81 81 81 b0 ac 90 ba 81 81 81 c2 ba c6 ae 81 81 81 cf ba cf a4 81 81 81 d6 b0 c8 96 88 81 81 d0 aa c4 93 96 81 81 ca ac c0 8f 8e 81 81 c7 9d bc 81 8f 81 81 bc ac be 81 96 81 81 b2 a6 c2 81 9a 81 81 a4 ac c0 82 9c 81 81 9e ae c0 9c 9e 81 81 90 a8 c2 81 9d 81 81 86 b0 c2 81 9f 81 81 85 b0 c6 81 9d 81 81 81 bc c9 81 99 81 81 81 ba ca 81 95 81 81 81 c1 c9 81 92 81 81 81 ba ce 81 8e 81 81 81 d3 d1 81 8d 81 81 84 cc c3 89 87 81 81 9e 81 81 81 81 81 81 ae 81 81 81 99 81 81 a0 82 81 81 9c 81 81 81 81 1c 81 81 81 81 81 81 44 81 81 81 81 81 c0 46 fe 81 81 81 81 e3 27 f0 81 81 81 0a b0 eb c7 a6 81 81 58 81 a2 8b 18 81 81 a0 f6 10 ec cd 81 81 c0 9c d1 dd e9 81 81 dd 8c bc cc 0d 81 81 ee aa e5 b2 19 81 81 8f c4 f2 da df 81 81 95 b8 f7 d6 be 81 81 f5 83 bc 90 48 81 81 92 e8 eb e2 d9 81 81 d5 f1 1b 00 de 81 81 da 89 ba 91 f4 81 81 ed b4 e1 cf 00 81 81 c7 ba d7 d4 d3 81 81 f7 d4 f8 f2 b6 81 81 72 94 d4 c3 34 81 81 10 8c a8 a6 d0 81 81 13 fd 22 1b e7 81 81 28 87 d8 b6 f3 81 81 4c 8b ce a0 11 81 81 13 9a fc be f2 81 81 30 a4 01 c8 09 81 81 65 a0 00 ce 36 81 81 06 81 cc 8b d5 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 de a0 83 82 81 81 c3 56 26 81 81 81 82 32 96 30 cf 81 81 81 93 81 a2 46 ea f5 b8 9a d8 1a 98 01 19 e1 fd f3 81 81 8f 91 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 82 81 81 81 8c 81 81 81 13 9e 85 4a 81 81 81 14 30 81 5a 81 81 9f c9 3e a0 2b 81 81 24 ff f4 4a 3e 81 b4 cd f7 fb 2c 5e e8 f0 f6 09 3c f0 4c 36 17 0d 56 5a 7f 4e 1a 2f 54 44 3a 8e 87 83 b0 9a 81 9c 95 a6 c6 89 87 b0 9c ac c3 81 ae d1 b0 b4 ae a4 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 ee 81 81 81 81 81 2b 70 1b 81 81 81 81 16 73 1c 81 81 81 ea 03 5c 01 98 81 81 17 14 f3 09 f2 81 81 1e 0a 48 0f 0d 81 81 1f fe 0e 03 16 81 81 27 27 1f 20 17 81 81 20 36 09 1c 0f 81 81 2c 24 13 11 05 81 81 36 01 e9 0d 0e 81 81 30 1a ff 12 1b 81 81 24 0f 1f 22 13 81 81 22 26 2b 03 27 81 81 26 2b fd 05 1a 81 81 2c 23 e5 13 23 81 81 27 18 27 13 22 81 81 2c 1e 27 0f 1b 81 81 30 13 0e 0a 1e 81 81 34 11 14 06 1f 81 81 28 22 16 14 1e 81 81 27 d5 05 16 20 81 81 2a 81 83 81 1e 81 81 2a 81 81 81 1c 81 81 27 81 81 81 23 81 81 23 81 81 81 28 81 81 36 81 81 81 2b 81 81 dd 81 81 81 12 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 8c 81 81 81 81 81 a2 5c eb 81 81 81 81 81 19 2a 81 81 81 81 c3 0a 42 81 81 81 87 1c 64 60 81 81 82 81 ef 81 1c dc 82 81 1d f9 81 14 e9 81 d1 cb 0d 81 2c cb 82 01 84 3e 81 25 9b 85 20 94 7f 81 ce a8 81 46 a2 c0 81 e6 d9 2d 3a e0 d9 4a 3c 3e d3 fe 2d 12 bc 1a 17 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 84 cc 9e 84 81 81 c0 81 36 f5 81 82 81 0d 82 1f fb a0 81 81 19 eb 05 e5 1d 81 81 15 3c db d9 ed f5 88 f9 ff 0b 03 03 f1 2c 13 ed 11 f3 eb e1 2b e7 0f 19 1d 09 1d 50 4a 44 3e 32 1b 3e 58 f5 13 25 2b 17 07 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 84 81 82 81 81 81 81 89 82 81 81 81 81 81 81 81 81 81 81 81 81 86 cb 81 81 81 81 81 81 60 81 81 81 81 81 81 50 81 81 81 81 81 81 56 81 81 81 81 81 81 56 81 81 81 81 81 81 5c 81 81 81 81 81 81 5a 81 81 81 81 81 a6 4a 81 81 81 81 81 d8 4a 81 81 81 81 81 0e 48 a4 81 81 81 81 3a 48 b8 81 81 81 81 5a 44 dd 81 81 81 81 76 42 0a 81 81 81 81 7f 44 22 81 81 81 81 7f 46 40 81 81 81 81 7f 44 5a 81 81 81 81 7e 46 66 81 81 81 81 7b 48 6b 81 81 81 81 75 48 72 81 81 81 81 6f 4a 72 81 81 81 81 6a 4a 76 81 81 81 81 60 4e 56 81 81 81 81 5c 46 5e 81 81 81 81 7b 68 68 81 81 81 81 d6 b2 81 81 81 81 81 81 fa 81 81 81 81 81 84 77 81 81 81 81 83 18 61 81 81 81 81 81 61 58 66 81 81 81 81 67 58 6d 81 81 81 c2 67 4c 65 a4 81 81 29 68 67 67 34 81 81 64 69 65 68 71 81 81 75 5a 60 65 72 81 81 73 63 50 67 6e 81 81 71 6b 68 69 68 81 81 6d 66 62 67 67 81 81 6a 68 6a 64 66 81 81 67 69 56 65 67 81 81 65 69 58 66 68 81 81 65 69 6b 6a 6a 81 81 65 67 64 69 6b 81 81 65 67 65 6b 69 81 81 64 67 4e 66 69 81 81 69 67 68 63 6c 81 81 73 63 67 61 74 81 81 7f 64 6b 60 7f 81 81 7f 62 5c 60 7f 81 81 7f 67 5e 66 7b 81 81 73 69 6b 65 7f 81 81 7f 66 69 62 7f 81 81 9e 67 6b 63 81 81 81 81 62 60 65 81 81 81 81 81 93 86 81 81 81 81 6c 6e 68 81 81 81 81 28 5e 2b 81 81 81 81 19 3e fe 81 81 81 81 2c 09 27 81 81 81 81 3a 30 28 81 81 81 81 46 3a 38 81 81 81 81 4e 27 46 81 81 81 81 32 5a 38 81 81 81 81 1c 0f 12 81 81 81 81 13 d2 05 81 81 81 81 0e b8 05 81 81 81 81 10 98 08 81 81 81 81 18 81 05 81 81 81 81 22 81 fe 81 81 81 81 23 81 00 81 81 81 81 27 81 08 81 81 81 81 14 81 01 81 81 81 81 10 81 06 81 81 81 81 0a 81 15 81 81 81 81 20 81 1a 81 81 81 81 29 81 10 81 81 81 81 29 81 15 81 81 81 81 1e 81 10 81 81 81 81 1b 81 0c 81 81 81 81 11 81 15 81 81 81 81 3c 81 36 81 81 81 81 a6 81 b4 81 81 81 81 e5 f2 27 81 81 81 81 65 7f 21 81 81 81 cf 36 f2 0e ef 81 81 08 02 f8 0b 11 81 81 fb 05 d9 ec f2 81 81 fe e8 c6 df ef 81 81 fb d9 d6 e5 f2 81 81 ef d9 d6 dc f5 81 81 cc df df cc ef 81 81 b2 ec df d9 e5 81 81 c9 f5 be c9 e8 81 81 e5 e8 c6 c6 ef 81 81 e5 e8 cc c6 f5 81 81 e5 e2 cf c3 f5 81 81 ec e5 df c9 02 81 81 e5 e5 dc d2 05 81 81 e2 e2 d9 d6 fe 81 81 dc e5 d9 d6 fe 81 81 d6 e5 d9 d6 e2 81 81 cf ef dc df dc 81 81 d2 ec ec e5 d9 81 81 cf ec e5 df b8 81 81 cc cf d2 bc a2 81 81 bc 81 81 81 9a 81 81 ac 81 93 87 84 81 81 b0 9d 90 81 9a 81 81 9a 21 c6 0e a0 81 81 81 81 c6 b0 90 81 81 81 81 d1 81 81 81 81 84 44 5e 32 83 81 81 81 79 6e 2a 81 81 81 9a d8 7f 9c 81 81 81 17 d9 50 a8 32 81 81 c5 e7 70 85 1e 81 81 3c 26 58 9b 68 81 81 5a 7e 29 f1 40 81 81 52 60 1a 7f 9b 81 81 08 61 20 3e 18 81 81 a2 60 56 a2 2f 81 81 81 69 63 c8 18 81 81 b6 4a 4e 07 16 81 81 21 fb 2c 2b f6 81 81 7f c4 27 40 1f 81 81 7f d6 32 4e 40 81 81 4e 15 27 30 16 81 81 56 46 17 01 32 81 81 6e 60 26 d9 36 81 81 58 6f 1e be 4e 81 81 1d 60 48 cc 3e 81 81 ba 32 69 e0 0d 81 81 85 f1 54 28 e6 81 81 82 c9 52 50 b6 81 81 81 c2 54 5e 9b 81 81 9e 13 5e 56 81 81 81 9b 38 71 07 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 c2 9a 81 81 81 81 81 20 34 34 32 3a e4 81 36 2f 3a 3c 30 30 82 34 32 36 36 3a 30 81 44 36 3a 34 3c 38 81 44 32 36 38 32 52 81 40 30 34 32 36 58 81 40 34 36 32 38 60 81 46 30 32 38 38 52 81 46 34 30 30 30 4e 84 36 28 25 2d 2d 46 81 42 38 34 38 3e 60 81 4e 38 36 3a 38 5c 81 4a 42 3a 3a 34 3c 81 34 1f 3a 32 30 3a e2 4a 44 58 4e 4c 63 a0 e9 2f 8a 94 95 a2 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 40 82 a0 81 81 81 86 3e 5a 5e 81 81 81 30 3a 38 38 90 81 81 42 3e 46 3c 32 81 81 3e 3e 40 3c 3e 81 81 44 32 3a 3c 40 81 81 4e 40 67 38 3a 81 81 4a 56 40 6f 38 81 81 46 2c 30 34 3e 81 81 7f fc 70 5c 52 81 81 e4 6b 3a 66 81 81 81 81 4c 44 63 81 81 81 81 44 46 63 81 81 81 81 48 44 63 81 81 81 81 48 44 44 81 81 81 81 48 46 3a 81 81 81 81 46 46 3e 81 81 81 81 48 48 40 81 81 81 81 4a 48 42 81 81 81 81 4c 4c 44 81 81 81 81 4e 4a 44 81 81 81 81 4c 4a 44 81 81 81 81 4a 4a 44 81 81 81 8c 4a 48 48 81 81 81 8c 44 46 46 81 81 81 8b 42 44 42 81 81 81 8c 4a 40 4c 81 81 81 81 42 44 3c 81 81 81 81 5e 6b 69 81 81 81 97 7c 81 78 92 81 82 66 72 3a 6b 5c 81 81 5c 58 48 36 50 82 81 50 42 3a 48 36 81 81 56 52 48 5e 3a 81 81 4a 52 44 40 34 81 b0 6b 38 3c 38 30 81 03 4e 34 3e 48 40 81 1f 2d 4e 36 36 42 8e 1e 3a 44 3c 48 32 b4 44 3a 40 48 44 4a c9 52 44 4e 36 48 1f d8 46 f3 1d 2b 17 ec f9 40 d2 2d 27 2c db f0 32 c1 34 23 32 d6 02 36 d7 1b 25 32 e0 0d 2e c9 22 2b 30 c2 fc 2e c1 36 27 38 ac f8 25 bc 17 12 0b a4 fd 36 b8 10 12 22 a8 02 22 a8 12 0d 19 a0 ef 2e a0 0c 1b 23 90 f5 27 81 20 16 17 91 f6 0a 81 17 0d 1b 81 c5 c1 81 1d 15 0f 81 9b 94 81 1e 23 1b 81 8b 83 81 17 0d 1d 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 82 81 81 81 81 81 30 81 81 81 81 81 81 2a 8f 81 81 85 81 b6 3a 40 32 c2 81 81 7f 30 0e 19 0e b6 df fb 19 38 21 01 34 d6 16 24 10 32 81 4c 1a 04 46 52 44 9d 2a 09 0d 2c f6 cc 0a 32 1b c6 ff fd 01 28 e1 77 32 7f 7f 7f 5a 81 04 28 a4 cd 05 90 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 83 8a 83 81 81 81 82 81 04 82 86 81 81 82 5e 2c 81 dd 81 81 81 56 52 c4 3a 81 82 ef 54 46 71 71 84 81 7b 3c 50 26 75 81 4a 3e 4a 60 64 7b d8 5c 4a 5a 64 3a 7f 40 00 44 61 5e 5c 7b 1d 4e 36 52 40 46 6a 38 4e 4a 40 48 4a 67 48 6c 70 6b 6a 6c 52 81 c8 be a0 98 9c 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 ac 81 81 81 81 81 63 50 4c c0 81 81 84 13 58 64 cf 81 81 81 81 f4 20 fc 81 81 81 81 81 81 46 84 81 02 81 82 c4 56 81 81 42 90 81 5e 52 92 ef 10 7f 81 56 67 50 32 f0 54 87 60 62 4e d6 2f 63 50 50 6c 40 4c 65 50 60 4c 60 46 4e 56 75 9b 50 54 a2 66 70 94 81 7e 7f 81 81 a2 81 81 a0 ac 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 10 3e 81 81 81 81 81 2b 46 8c 81 81 81 81 42 2b b4 81 81 81 81 38 1d ef 81 81 81 81 2b 20 f7 81 81 81 81 2c 3e 02 81 81 81 81 27 69 02 81 81 81 81 29 22 ff 81 81 81 81 36 e6 01 81 81 81 81 36 aa f3 81 81 81 81 36 81 e9 81 81 81 81 3e 81 df 81 81 81 81 3e 81 dd 81 81 81 81 38 81 de 81 81 81 81 40 81 dd 81 81 81 81 30 81 df 81 81 81 81 2e 81 de 81 81 81 81 2f 81 df 81 81 81 81 2d 81 de 81 81 81 81 2d 81 da 81 81 81 81 2d 81 de 81 81 81 81 2c 81 d8 81 81 81 81 2f 81 cb 81 81 81 81 32 81 cc 81 81 81 81 34 81 c7 81 81 81 81 3a 81 b8 81 81 81 81 44 81 c2 81 81 81 81 1f 81 9e 81 81 81 81 d1 81 89 81 81 81 81 f5 ff ff 81 81 81 90 86 38 86 81 81 81 be b6 f8 b2 8d 81 81 ce b2 ac b2 a0 81 81 c7 b2 a4 ae b6 81 81 c9 b0 dc b0 be 81 81 d7 aa ba ac ba 81 81 ec b4 b4 b2 ba 81 81 f5 be bc ae be 81 81 0b c0 fc a2 be 81 81 29 c3 d3 a0 b6 81 81 38 c7 01 a8 a0 81 81 40 d3 1b a8 97 81 81 34 e1 42 ae 8f 81 81 16 e5 29 b0 8b 81 81 21 e5 d5 b4 88 81 81 38 08 d5 b4 b0 81 81 66 32 d0 be e5 81 81 74 fd c7 b6 0b 81 81 4a 18 bc c5 2d 81 81 52 06 aa d8 21 81 81 26 f5 d1 dc 2b 81 81 4e ff e8 ff 1f 81 81 88 ba 4c d7 12 81 81 86 81 99 81 28 81 81 89 81 81 81 b6 81 81 81 81 a2 81 81 81 81 81 81 f5 81 81 81 81 81 81 65 81 81 81 81 81 44 72 23 81 81 81 81 4e 5c 52 81 81 81 a2 36 48 38 ac 81 81 10 3e 3c 42 27 81 81 5c 3e 4c 42 46 81 81 61 42 38 46 44 81 81 42 38 38 38 4e 81 81 54 38 3e 34 56 81 81 5a 4c 32 46 5a 81 81 5c 52 3e 4e 5a 81 81 58 52 46 48 5a 81 81 54 56 38 3e 58 81 81 52 5a 36 40 62 81 81 58 56 42 44 6e 81 81 64 52 4c 46 7f 81 81 69 4a 32 34 7f 81 81 61 3e 3e 30 7f 81 81 5c 34 4c 36 7f 81 81 58 38 42 38 7f 81 81 5a 3e 3a 3a 76 81 81 56 3e 40 3e 66 81 81 58 42 3e 3e 66 81 81 5a 3c 42 3a 62 81 81 5a 4c 4c 4a 64 81 81 6b aa d7 a0 6a 81 81 ae 81 81 81 88 81 81 81 10 8c d8 81 81 81 81 77 77 70 81 81 81 81 67 e5 62 81 81 81 81 69 4e 65 81 81 81 81 6b 72 63 81 81 81 81 6b 67 60 81 81 81 81 6c 6c 60 81 81 81 81 6b 6a 60 81 81 81 81 68 68 5c 81 81 81 81 6c 68 5c 81 81 81 81 6f 68 5e 81 81 81 81 71 68 5c 81 81 81 81 6e 68 5e 81 81 81 81 6d 68 61 81 81 81 81 6c 67 63 81 81 81 81 6c 67 67 81 81 81 81 6d 67 67 81 81 81 81 6e 67 65 81 81 81 81 6e 66 63 81 81 81 81 6d 65 63 81 81 81 81 6e 66 64 81 81 81 81 6e 66 66 81 81 81 81 6e 67 67 81 81 81 81 70 68 65 81 81 81 81 75 6a 67 81 81 81 81 6f 61 64 81 81 81 81 7f 7f 76 81 81 81 81 02 23 ea 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 b6 81 81 81 81 81 84 dd ea 81 81 81 81 81 02 7f c5 81 81 81 81 11 db ce 81 81 81 81 f1 ee c9 81 81 82 e9 17 df b2 81 81 81 38 1c 2f ba 81 81 81 fd 21 28 df 87 85 c7 32 1f 36 13 81 81 36 2b 1e 12 3c c1 e6 2f 04 27 ff 62 56 32 22 29 29 0d 5c 4c f1 26 24 28 24 50 50 0a f0 21 26 30 5c 40 f8 e9 2c 32 42 5e 58 30 12 36 52 3a 64 8d 58 38 54 44 48 4e 81 0a 48 17 81 17 81 83 81 9b 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 82 82 ec 83 81 81 81 81 81 5e 81 81 81 81 81 3c 6e 06 81 81 81 85 48 30 48 81 81 81 81 40 2c 3a 81 81 81 81 46 34 3e 81 81 81 81 48 2b 3a 81 81 81 81 50 34 3e 81 81 81 81 56 40 4a 81 81 81 81 4e 40 3c 81 81 81 81 2d 40 21 81 81 81 81 27 40 1a 81 81 81 81 1c 42 ed 81 81 81 81 13 44 d7 81 81 81 81 23 46 c5 81 81 81 81 3e 46 e9 81 81 81 81 48 48 26 81 81 81 81 46 4c 3a 81 81 81 81 44 4c 3a 81 81 81 81 40 4e 3c 81 81 81 81 3e 50 3a 81 81 81 81 3c 4c 3a 81 81 81 81 3e 4c 40 81 81 81 81 3c 46 48 81 81 81 81 3a 46 50 81 81 81 81 44 3e 4e 81 81 81 94 58 4e 60 81 81 81 81 b4 f7 d2 81 81 81 81 81 81 89 81 81 81 81 81 9a 81 81 81 81 81 82 56 d4 81 81 81 81 88 81 4e 81 81 81 81 81 81 c1 81 81 81 81 81 83 81 85 81 81 81 81 81 81 8a 81 81 85 81 82 81 84 81 81 81 81 81 81 81 81 81 85 a0 81 81 81 81 81 3e 2d 3e 1f 44 36 8d 42 52 36 3a 4a 08 f3 40 32 34 4a 46 f1 74 4a 36 4a 38 3c 2a 1e 56 40 20 4a 3c 3a aa 58 38 4e 68 5c 54 81 58 4e 4e 42 3a 67 81 5a 54 48 60 56 72 81 5a 56 52 63 60 7f 81 5a 56 4e 56 54 7f 81 58 5a 48 4a 58 7f 81 5c 58 5a 50 5e 7f 00 5c 58 5a 5e 60 7f ee 56 60 64 65 64 7f 81 5e 65 5e 5c 60 6b 81 67 62 67 65 66 75 81 7f 7f 58 54 48 3a 81 d9 be 81 81 81 81 81 81 81 ef 83 81 81 81 81 83 bc 81 81 81 81 81 83 81 81 81 81 81 81 81 88 e9 81 81 81 81 81 82 1c 81 81 81 81 91 81 e5 81 81 81 81 cc 81 81 83 81 81 81 d9 81 81 86 81 81 81 c0 81 81 87 81 81 81 97 81 81 81 81 81 81 81 81 87 81 81 81 85 81 81 87 81 81 81 88 81 81 83 ae 81 81 81 81 81 81 db 81 81 81 89 84 83 0a 81 81 81 81 81 81 a4 81 81 81 81 81 81 98 81 81 81 3a 3c 34 2c 81 81 81 4a 5e 4a 4e 81 81 81 4e b0 56 4a 81 81 cb 54 81 69 5e 81 81 02 56 be 69 5c 81 81 d8 58 7f 64 60 81 81 c0 4e 56 5a 52 81 81 81 50 58 5c 32 81 81 81 4e 5c 5a 03 81 81 81 60 7f 54 8a 81 81 81 0a a2 81 81 81\n",
            "=======\n",
            "byte3: 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 84 88 81 81 81 81 81 81 81 81 81 81 81 81 81 97 81 81 81 81 b6 30 1b 81 81 81 81 0a 30 16 81 81 81 84 f3 1a 10 81 81 81 81 db 04 10 81 81 85 81 ee 11 11 81 83 81 ed f6 1b 0e 81 81 96 f0 07 2b 10 ac b6 f7 f2 0c 0d 1c be db f3 09 18 fe 0b ba e9 e2 eb 16 3e 3c a4 3c 1a 00 52 32 7b b2 8d 3a 52 d3 81 30 8c 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 c4 81 81 81 81 81 89 77 7f 2d 81 81 81 6f 65 70 78 81 81 81 67 69 64 63 81 81 81 65 6e 76 6a 95 81 81 67 7c 58 64 b6 81 81 68 7f 81 fc f3 81 81 6f 7f f5 a6 23 81 81 75 7f 9d 8e 48 81 81 7a 7f 7f 46 60 81 81 7a 81 81 ff 7a 81 81 7d 0b 56 2f 7f 81 81 7f 7f 73 7f 7f 81 81 79 60 66 5e 7f 81 81 5e 69 6a 67 7f 81 81 48 68 6a 6d 76 81 81 3c 69 6a 7d 78 81 81 16 6b 6b 7f 79 81 81 f0 6b 6b 7f 79 81 81 ee 6b 6d 7f 75 81 81 f3 6b 6d 7f 74 81 81 1b 6a 6e 7f 73 81 81 2c 6a 6a 70 72 81 81 ba 6e 6d 7e 6f 81 81 be 5e 60 7f 6c 81 81 99 81 81 81 74 81 81 97 81 81 81 7f 81 81 8c 83 83 84 3e 81 81 81 32 02 81 81 81 81 81 7f 7b cd 81 81 81 81 6d 5e f5 81 81 81 81 6b 61 12 81 81 81 81 66 61 28 81 81 81 81 61 63 3c 81 81 81 81 5a 63 30 81 81 81 81 63 78 14 81 81 81 81 61 7f 02 81 81 81 81 60 7f 08 81 81 81 81 5e 78 12 81 81 81 81 62 40 ff 81 81 81 81 67 20 f0 81 81 81 81 6c 04 f0 81 81 81 81 73 ba f0 81 81 81 81 74 8b e5 81 81 81 81 72 87 da 81 81 81 81 75 81 e4 81 81 81 81 6e 81 dd 81 81 81 81 69 81 db 81 81 81 81 65 81 dd 81 81 81 81 69 81 e0 81 81 81 81 6c 81 e3 81 81 81 81 72 81 d2 81 81 81 81 76 81 cb 81 81 81 81 65 81 e4 81 81 81 81 48 81 f8 81 81 81 81 e3 81 ba 81 81 81 81 ed d4 87 81 81 81 81 66 2f de 81 81 81 81 56 42 e4 81 81 81 81 65 52 b6 81 81 81 81 63 54 8f 81 81 81 81 36 64 8b 81 81 81 81 eb 7b 91 81 81 81 81 cf 76 88 81 81 81 81 e7 7d 90 81 81 81 81 e5 7c 8b 81 81 81 81 d9 7c 86 81 81 81 81 d8 74 83 81 81 81 81 da 67 81 81 81 81 81 db 6b 81 81 81 81 81 cf 60 81 81 81 81 81 d1 3c 81 81 81 81 81 e3 12 81 81 81 81 81 d2 e0 81 81 81 81 81 2d b4 81 81 81 81 81 52 b0 81 81 81 81 81 5a b6 81 81 81 81 81 60 b0 81 81 81 81 81 67 aa 81 81 81 81 81 6a 9f 81 81 81 81 81 70 8e 81 81 81 81 81 77 81 81 81 81 81 81 7f 81 81 81 81 81 81 2f 81 81 81 81 83 81 ba cd 81 81 81 82 81 4a 40 ed 81 81 81 e7 f4 1a 0b 81 81 82 fd de 14 f3 81 81 83 e6 f5 25 fb de 81 81 ea e9 2f f8 0e 81 81 f1 e6 05 0f 44 81 81 f8 e2 ee 26 30 81 81 16 e2 f4 1f 32 81 81 21 ee f3 24 2f 81 81 21 e9 fc 21 23 81 81 28 e6 ff 1f 15 81 81 46 e1 fb 17 0f 81 81 46 e1 f9 17 08 81 85 42 eb f8 1a 0c 81 99 3c f1 00 17 04 81 a8 1f f5 09 24 07 81 a8 f8 f8 00 34 02 81 ba e6 fc ff 32 0b 81 ed d5 fb 01 2f 14 81 e2 a6 fb ff 2d 29 81 81 83 fc 05 18 89 81 81 8e e5 02 18 81 81 81 ca e7 04 0f 82 81 81 f1 0c 0b 09 81 81 81 0f e6 10 ff 81 81 81 8a 28 28 36 81 81 81 81 c9 f0 8d 81 81 81 81 3c 26 36 81 81 81 81 56 5a 3e 81 81 81 81 5a 4c 2b 81 81 81 81 4e 44 4c 81 81 81 81 38 54 63 81 81 81 81 42 58 61 81 81 81 81 40 67 5a 81 81 81 81 42 67 56 81 81 81 81 42 50 52 81 81 81 81 3e 18 52 81 81 81 81 3a b6 4e 81 81 81 81 3e 81 48 81 81 81 81 48 81 48 81 81 81 81 54 81 34 81 81 81 81 76 81 12 81 81 81 81 78 81 0f 81 81 81 81 54 81 26 81 81 81 81 61 81 28 81 81 81 81 5e 81 34 81 81 81 81 56 81 4c 81 81 81 81 4e 81 5e 81 81 81 81 4c 81 60 81 81 81 81 56 81 66 81 81 81 81 5a 81 68 81 81 81 81 5a 81 56 81 81 81 81 40 81 60 81 81 81 81 22 81 6d 81 81 81 81 a6 81 02 81 81 81 81 92 b4 81 81 81 81 84 7f 74 81 81 81 81 81 2b 7f 81 81 81 81 81 81 7f 81 81 81 81 b8 ac 81 95 81 81 81 ee c8 95 ba 81 81 81 ca b4 9a 9c 81 81 81 b6 b4 95 92 81 81 81 9e ac 96 94 81 81 81 8e aa 8e aa 81 81 81 8b aa 91 a2 81 81 81 83 b0 8b ce 81 81 81 84 ae 8a 22 81 81 81 85 ae 88 72 81 81 81 8c b6 85 5a 81 81 81 9a b2 89 74 81 81 81 b6 b2 87 5c 84 81 81 e8 ae 83 52 88 81 81 fa b4 83 3e 89 81 81 03 ba 82 30 8b 81 81 1c b6 83 07 8d 81 81 3a bc 85 fb 91 81 81 42 b8 85 f0 94 81 81 62 ca 89 e7 94 81 81 6a cc 94 b4 92 81 81 70 81 81 81 92 81 81 f4 81 81 81 9b 81 81 b4 81 81 81 9c 81 81 81 81 0b 82 82 81 81 81 ae 40 81 81 81 81 81 aa 36 87 81 81 81 b4 d0 1d fd 81 81 81 c7 d1 f2 ff 81 81 81 81 91 ac ac 81 81 81 e3 1d 26 0f 81 81 81 b2 ba d6 f8 95 81 81 a8 ac b2 d5 a8 81 81 f3 cd d3 e3 ae 81 81 c9 de e8 ed 9d 81 81 cb cf e8 eb de 81 81 3e 88 a6 a0 16 81 81 e0 e6 04 ef ae 81 81 f6 ee 22 12 dd 81 81 4c 8b b2 a2 ef 81 81 72 c0 f1 c9 14 81 81 36 c2 f6 c9 e0 81 81 1c e1 14 df d6 81 81 2c b0 e9 b2 4e 81 81 ed a0 c3 ae d2 81 81 c6 17 4a 2d ed 81 81 92 b6 f0 c9 fe 81 81 88 ce c3 ce 1d 81 81 83 06 db ee e4 81 81 81 27 e4 0b d7 81 81 81 32 ee fa e9 81 81 81 d1 ac 81 b8 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 94 b2 92 81 81 81 81 2f 34 69 81 81 81 82 0b e0 52 81 81 81 81 81 81 1c f0 ec b2 b0 ba db f6 e8 03 c0 fd fd dc 81 81 8f 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 83 81 81 81 81 81 81 81 30 81 81 8d 81 83 81 ff 81 81 b4 82 81 6c e9 6e dc 9a 81 be d1 ff 30 5e a8 81 16 e5 fa db 2d a2 f0 d6 e8 21 46 df cd 36 ff 22 5e 52 7c a8 2b 36 50 16 81 98 93 83 c6 87 81 c9 8c b0 ca ba 9b ba c2 aa b0 81 ca c3 a8 ac ba 82 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 12 ea 81 81 81 81 81 24 65 93 81 81 81 a8 40 3a 23 81 81 81 22 48 3c 0f 81 81 81 0a fa 70 05 81 81 81 02 0e 50 0d 84 81 81 0a 1c 26 02 93 81 81 22 36 58 23 ba 81 81 2b 46 2f fa e6 81 81 4e 32 3c 09 0a 81 81 5c fa 1e e8 1a 81 81 58 18 4c f5 1c 81 81 68 36 67 05 1e 81 81 5e 18 36 11 0f 81 81 6c 0e 23 0d 22 81 81 40 1b 22 16 17 81 81 28 1e 50 0d 1c 81 81 0b 06 46 07 1c 81 81 f7 16 38 14 1b 81 81 fb 26 34 1a 17 81 81 24 24 36 14 0e 81 81 12 c0 1a b8 0e 81 81 d6 81 8a 81 0f 81 81 d1 82 81 82 11 81 81 cd 81 81 84 0e 81 81 b4 81 82 86 13 81 81 b6 81 81 86 0d 81 81 84 81 81 84 0a 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 82 fe 81 81 81 81 81 32 b4 04 82 81 81 81 81 e0 22 82 81 81 81 e6 30 07 85 82 81 87 14 5a 1c 81 81 81 81 fa 17 0d 81 82 81 0a 24 82 d3 81 81 ec 0a 2c 81 32 9f 84 09 c0 40 81 fe c8 81 f3 ce 4a 81 81 d0 81 28 e3 3e 90 81 aa 2a 3c 2c 4c 52 75 ae e4 06 20 db 38 25 b2 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 eb 81 81 81 81 81 84 05 81 84 81 81 81 81 01 df 84 82 81 ca 84 ed 29 81 84 81 25 0f 1f e1 f5 81 81 34 2e d9 eb fb e5 81 f5 f7 ff fd ef fb d0 21 07 0f ed d4 e9 42 13 11 1f 17 ff 2b 60 42 30 3c 2c 1f 44 df 09 25 21 25 19 ff 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 a4 84 81 81 81 81 81 c1 81 81 81 81 81 81 25 81 81 81 81 81 81 61 48 81 81 81 81 81 4a 58 81 81 81 81 81 40 48 81 81 81 81 81 16 4a 82 81 81 81 81 0c 34 82 81 81 81 81 30 40 81 81 81 81 81 70 40 81 81 81 81 81 5c 40 81 81 81 81 81 61 48 81 81 81 81 81 5e 48 81 81 81 81 81 5c 4c 81 81 81 81 81 56 4c 81 81 81 81 81 50 4a 81 81 81 81 81 4e 48 81 81 81 81 81 44 4a 81 81 81 81 81 42 4a 81 81 81 81 81 42 4a 81 81 81 81 81 46 4a 81 81 81 81 81 4a 48 86 81 81 81 81 4a 46 98 81 81 81 81 4a 44 a8 81 81 81 81 4c 44 b0 81 81 81 81 4c 3e d7 81 81 81 81 63 6c c6 81 81 81 81 00 bc 81 81 81 81 81 81 ee 81 81 81 81 82 7f 75 81 81 81 81 81 78 67 81 81 81 81 81 65 64 f3 81 81 81 28 65 6c 76 85 81 81 77 65 60 63 81 81 81 74 69 60 67 81 81 81 6a 6d 6b 68 ae 81 81 68 64 68 66 21 81 81 6c 69 60 68 5c 81 81 6d 63 66 63 54 81 81 6e 66 67 66 5e 81 81 6f 67 69 69 7f 81 81 70 66 60 69 7f 81 81 71 66 64 69 7f 81 81 73 66 68 68 7f 81 81 6f 68 67 65 7f 81 81 6d 68 68 62 7e 81 81 6b 68 62 68 7b 81 81 6c 69 6a 72 75 81 81 54 6a 6a 7d 72 81 81 25 69 6b 7f 6b 81 81 e4 69 67 7f 69 81 81 95 6b 6c 7f 68 81 81 81 6c 6b 7f 6a 81 81 81 6b 68 76 63 81 81 81 6d 6a 77 81 81 81 81 62 63 6a 81 81 81 81 81 89 81 81 81 81 81 54 7f 29 81 81 81 81 44 5c f7 81 81 81 81 36 4c ec 81 81 81 81 38 1e 01 81 81 81 81 3a 24 06 81 81 81 81 38 24 f0 81 81 81 81 28 42 d4 81 81 81 81 02 46 c4 81 81 81 81 fa 4c ac 81 81 81 81 e8 50 99 81 81 81 81 e1 50 90 81 81 81 81 d8 4e 8d 81 81 81 81 cf 4a 8c 81 81 81 81 c6 3c 81 81 81 81 81 cf 36 81 81 81 81 81 d1 36 81 81 81 81 81 c9 38 81 81 81 81 81 c1 34 81 81 81 81 81 d6 32 81 81 81 81 81 24 36 81 81 81 81 81 34 2f 81 81 81 81 81 36 30 81 81 81 81 81 3c 2a 81 81 81 81 81 38 1f 81 81 81 81 81 32 23 81 81 81 81 81 46 36 81 81 81 81 81 ed ac 81 81 81 81 81 05 18 b2 81 81 81 81 50 1e 40 81 81 81 0e 40 e5 08 81 81 81 f8 ec fb 1b c6 81 81 f2 fb d6 fe 0b 81 81 08 d9 d6 df 0b 81 81 14 d6 dc d6 08 81 81 27 d9 d2 d6 f2 81 81 24 cc d9 d9 f8 81 81 18 d9 df cf ef 81 81 0b e2 cc e5 e5 81 81 cc e5 cf e8 e5 81 81 a2 e5 bc e2 e2 81 81 97 e2 b2 d9 ef 81 81 8d ec d2 d9 f5 81 8d 81 ef df d9 f8 81 a0 81 ec d9 d6 f8 81 a0 81 ec d9 d6 05 81 a0 81 ec d9 d6 0e 81 a8 81 f2 d6 dc 0e 81 ac 81 f5 e8 e5 0e 81 b6 81 ef dc d9 08 81 c3 81 d9 c9 b2 fe 81 d9 81 81 81 81 05 81 d9 81 93 8d 81 08 81 ef 81 81 81 fe 1e 81 e8 81 bc be 0b fe 81 cc 81 9d c9 81 fb 81 81 81 81 d7 81 81 81 81 83 26 75 b0 81 81 81 81 3c 4a d0 81 81 83 c4 be 46 ba 81 81 81 dc a6 38 c3 91 81 81 50 81 65 a0 46 81 81 36 a4 56 bc 7b 81 81 2b d4 1d 46 1d 81 81 48 19 00 7f 50 81 81 5a 6a 75 d5 7f 81 81 5a 58 7f b4 52 81 81 70 04 36 fb 11 81 81 7c e0 6c 66 69 81 8d 67 f2 70 78 46 81 b2 26 e8 36 6f da 81 c8 d5 e7 08 5e db 81 aa 88 09 e6 32 e1 81 be 81 3e 96 f5 ec 81 ba 81 4e 8b a8 38 81 b4 81 32 8c a0 40 81 bc 81 2b 91 fd 52 81 ba 81 10 ae 4a 5c 81 a6 81 d3 f3 4c 70 81 98 81 c3 1f 54 71 81 ba 81 03 fd 69 65 81 e1 81 30 cb 7e 5c 81 f3 81 18 e7 08 58 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 eb 81 81 81 81 81 81 fc 88 81 81 81 81 83 1f 3e 34 2f 1e 81 81 27 34 3c 3c 3a 81 81 23 30 36 36 2e be 8e 2d 34 38 32 32 cb c4 30 32 34 34 30 cf dd 32 2f 32 32 34 d1 dd 30 32 32 32 34 ce cc 2c 32 36 38 30 c7 8e 2d 34 34 32 2b c3 81 30 26 2a 2d 23 c0 81 3a 36 36 38 38 bc 81 11 34 38 3a 38 c9 81 44 44 38 36 36 aa 99 46 3e 36 30 32 a4 e8 40 32 56 4e 4c ae 81 f7 1a 93 94 96 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 f4 a0 81 81 81 81 f2 65 72 28 81 81 81 42 3c 42 3c 81 81 81 36 3c 44 38 81 81 81 3e 3c 3e 3a aa 81 81 3e 32 38 40 ff 81 81 3e 5c 5c 3e 3e 81 c3 3c 3e 30 40 32 81 04 3c 26 1f 6f 44 81 81 3c 60 5a 56 c8 81 81 5c 62 44 38 81 81 82 5c 38 3c 5a 84 81 81 5e 46 38 58 81 81 81 5a 46 42 52 82 81 81 5a 46 4a 46 81 81 81 58 48 4a 46 82 81 81 54 4a 48 48 82 81 81 56 4a 4a 46 82 81 81 58 4a 4a 44 82 81 81 5a 4a 4a 44 82 81 81 5a 4c 4a 44 82 81 81 5e 4a 48 44 82 81 81 60 48 48 44 82 81 81 40 48 46 46 82 81 81 42 44 46 46 82 81 81 40 42 46 46 82 81 81 46 46 44 4e 82 81 81 30 4a 4a 2e 82 81 81 81 60 30 16 81 81 82 0c 65 b4 4a 81 81 81 65 60 7f 48 b0 81 81 4e 4a 40 46 42 81 9b 4e 4e 36 44 50 81 ff 58 46 54 63 40 81 38 3e 56 40 3e 32 81 40 44 3c 3c 36 3a 81 36 3a 3c 3e 44 2e 81 3e 48 42 2e 40 36 81 3a 3a 4a 3c 3a 3a 81 2e 40 3e 40 4e 24 81 2b 58 4e 3e 44 32 81 2c 58 29 25 23 3e 81 27 52 23 30 28 3a 81 20 4c 1f 32 25 52 81 25 58 24 20 23 48 81 1a 58 24 2c 29 25 81 11 5c 28 2c 36 2c 81 0c 48 0a 14 0a 3a 81 0b 32 12 17 19 4a 81 10 3a 1b 06 0c 29 81 0b 42 0b 08 19 38 81 12 4c 1b 28 02 48 81 24 34 14 1b 0f 44 81 23 1a 24 11 16 28 81 20 eb 19 32 1e 20 81 f8 ac 15 19 19 ec 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 c5 81 84 81 81 81 81 6a 81 81 81 81 81 81 d8 81 9e 81 82 81 1f df 32 30 81 81 81 48 4c f2 0a 81 81 f6 0e 26 25 07 81 23 14 1a 2b 2d 36 81 15 2e 30 ff 60 34 94 17 ec 40 0b cf ed ba 36 2c d4 48 ec d7 ed 4a 79 05 7d 7f 40 b0 81 0a df 9a f6 0b 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 82 81 81 81 83 c2 81 83 81 81 81 81 4e 81 81 81 81 81 cb 48 e2 05 81 82 81 7d 58 46 42 99 84 b0 44 60 52 38 c4 81 48 3c 60 46 34 e1 e6 32 2c 54 66 2f d1 15 f8 38 68 5a 6b ae 30 3a 30 4a 42 40 91 38 48 46 44 48 4a 83 66 6f 73 6b 6a 68 81 8a d1 ba 9e 99 90 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 2b 8d 9e 81 81 81 84 52 50 52 81 81 81 81 09 5c 62 81 81 81 81 81 21 13 81 81 81 0f 81 81 81 81 87 81 36 84 81 20 93 81 81 28 81 81 1a ba bc 15 2f 19 ac 6c d3 16 11 34 69 62 58 99 38 eb 46 58 5c 4e b2 4a 4c 5e 56 52 54 ba 4c 52 52 54 34 50 9f f4 6b 6d 81 4c 7f c0 81 95 95 81 cc be 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 1d 22 81 81 81 81 81 1d 32 81 81 81 81 81 21 30 81 81 81 81 81 0e 2e 81 81 81 81 81 10 2f 81 81 81 81 81 15 36 81 81 81 81 81 15 26 81 81 81 81 81 1c 2e 81 81 81 81 81 2d 4c 81 81 81 81 81 28 58 81 81 81 81 81 23 5a 81 81 81 81 81 27 50 81 81 81 81 81 29 42 81 81 81 81 81 29 3c 81 81 81 81 81 34 38 81 81 81 81 81 38 2b 81 81 81 81 81 3e 13 81 81 81 81 81 44 03 81 81 81 81 81 44 fe 81 81 81 81 81 42 fc 81 81 81 81 81 44 fc 81 81 81 81 81 46 fb 81 81 81 81 81 48 f1 81 81 81 81 81 4c ea 81 81 81 81 81 4c ed 81 81 81 81 81 4c e4 81 81 81 81 81 4a dd 81 81 81 81 81 30 a2 81 81 81 81 81 94 81 81 82 81 81 82 7f 01 b8 81 81 81 c5 df 58 b8 81 81 81 ac 92 b8 a8 81 81 82 ae ba b4 ae 81 81 81 ac b4 be ac 81 81 81 b0 b4 a4 ae 82 81 81 bc a8 bc a8 99 81 81 c2 ac ba aa a2 81 81 b6 b2 ac b8 aa 81 81 c9 b2 a4 c3 b4 81 81 c2 b0 a8 c7 be 81 88 da ae a2 a6 c2 81 90 0b aa 99 94 cc 81 94 22 a8 99 88 d0 81 a0 52 a6 9b 86 de 81 a6 ff b2 a4 90 ee 81 9b d3 b6 a8 99 ec 81 9b f3 c9 b4 c3 dc 81 99 e1 ca be a8 ce 81 a2 c5 d1 d1 ac b4 81 aa b8 ee e1 c7 a2 81 a4 92 ea e7 cc a0 81 c3 f1 d1 ef ea b2 81 c7 d3 08 06 d5 b8 81 c2 81 9b 94 81 bc 81 96 81 90 9e 82 9d 81 81 81 84 aa 82 81 81 81 81 81 21 83 81 81 81 81 c2 67 81 81 81 81 81 73 64 ba 81 81 81 e4 40 6f 54 81 81 81 52 4c 56 3a 81 81 81 4e 3a 36 42 81 81 81 4a 42 40 42 81 81 81 4c 42 3a 46 8d 81 81 52 32 34 40 a0 81 81 54 32 32 58 bc 81 81 5c 40 3c 5c fb 81 81 60 3a 4a 58 2e 81 81 66 38 34 65 56 81 81 71 38 42 6e 6d 81 81 7f 36 3e 6d 52 81 81 71 3a 3a 67 4e 81 81 58 3e 46 72 4e 81 81 4c 3a 3e 7d 4c 81 81 4c 42 3e 6d 52 81 81 40 3c 42 52 5a 81 81 40 3c 44 40 6a 81 81 42 3e 42 40 66 81 81 4c 3e 44 40 63 81 81 54 42 44 40 6a 81 81 50 3e 42 3e 60 81 81 36 4c 4e 67 5c 81 81 40 c7 d7 81 5e 81 81 8e 81 81 81 98 81 81 81 d3 a6 81 81 81 81 83 76 7f 7f 81 81 81 81 66 4a 54 81 81 81 81 6a 61 4c 81 81 81 81 6b 6b 72 81 81 81 81 6b 67 7b 81 81 81 81 6a 6b 7f 81 81 81 9e 68 6a 7f 81 81 81 b8 67 6b 7f 81 81 81 d2 68 69 7f 81 81 81 c7 69 67 7f 81 81 81 99 6b 66 7f 81 81 81 81 6b 65 7f 81 81 81 81 6a 66 7e 81 81 81 81 6a 65 7a 81 81 81 8d 6c 67 7f 81 81 81 9e 6d 69 7f 81 81 81 ac 6e 68 7f 81 81 81 be 6e 68 7f 81 81 81 cc 6f 69 7f 81 81 81 d8 70 6b 7f 81 81 81 e6 71 6d 7f 81 81 81 f1 72 6d 7f 81 81 81 f9 74 6c 7f 81 81 81 0d 75 6e 6d 81 81 81 38 69 69 6c 81 81 81 25 7f 7f 7f 81 81 81 81 0b 21 90 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 2f 81 81 81 81 81 81 27 c4 81 81 81 81 81 f0 6f 81 81 81 81 84 dd dd 81 81 81 81 25 ed e7 81 81 81 82 36 f7 f0 81 81 81 81 17 2c 36 81 81 81 b8 2d 29 32 81 86 81 56 3a 19 36 81 81 81 1d 11 1c fa 81 fd 0c 36 13 1f 2d 81 0c 23 17 36 1e 27 81 16 19 05 1b 28 21 81 42 0e 11 1f 21 30 ea 3e e4 10 2f 30 44 ee 50 2e 29 42 48 3a 12 19 4c 3c 4a 44 44 9d 81 3e 42 81 9d da 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 82 81 25 85 81 81 81 82 95 6a 81 81 81 81 83 56 4e 97 81 81 81 81 46 44 3a 81 81 81 81 40 3c 48 81 81 81 81 48 40 46 81 81 81 9d 48 44 48 81 81 81 be 44 44 4e 81 81 81 de 44 44 52 81 81 81 f9 46 42 50 81 81 81 07 4c 42 56 81 81 81 15 4c 42 62 81 81 81 22 4c 40 54 81 81 81 29 4e 40 44 81 81 81 2f 4e 3e 21 81 81 81 36 4c 3e 14 81 81 81 3a 4c 3e 22 81 81 81 30 50 3e 5a 81 81 81 38 50 3e 50 81 81 81 1a 54 3a 44 81 81 81 81 5e 3a 4e 81 81 81 81 63 3e 52 81 81 81 88 6a 40 48 81 81 81 c8 70 44 46 81 81 81 09 70 46 48 81 81 81 3a 78 3e 48 81 81 81 5a 72 52 54 81 81 81 81 87 21 a6 81 81 81 81 81 81 81 81 81 81 81 83 e0 83 81 81 81 81 81 2f 81 81 81 81 81 81 81 be 81 81 81 81 c2 81 2e 81 81 81 81 0d 81 21 81 81 81 81 24 81 f5 81 81 82 84 25 83 ed 81 81 81 81 76 81 f8 81 81 81 81 7f 81 12 81 81 c6 4e 48 3a 28 32 be d3 3a 52 32 32 46 95 8d 3e 34 32 40 44 81 88 44 3c 4a 52 44 8b 81 4e 46 21 60 42 8d 81 5a 3c 54 f7 52 99 81 5c 42 64 fd 61 9e 81 5a 4c 54 13 5c b4 9d 5a 50 68 5a 5a cf ca 5a 56 5c 50 56 e5 ec 5a 5c 48 50 5c 00 fe 58 5a 56 54 61 1b 02 5a 5c 5c 5e 61 1c 6e 5a 62 63 65 67 26 38 5e 60 5e 5c 62 1f 25 67 68 67 65 69 4c 6a 7f 79 58 52 3a e7 85 df 81 81 81 81 81 81 81 84 0b 81 81 81 81 81 81 b8 86 81 81 81 81 81 81 81 81 81 81 81 aa 8d 81 81 81 81 81 d2 83 81 81 81 81 81 ee 81 ed 81 81 81 81 a4 81 17 81 81 81 81 81 81 02 81 81 81 83 81 81 c6 81 81 81 85 81 81 81 84 81 81 81 81 81 81 87 81 81 81 86 81 81 81 81 81 81 85 81 81 81 81 81 81 82 81 84 81 81 81 c3 83 84 88 81 81 81 d3 81 81 81 81 81 81 95 81 81 81 97 81 81 e5 36 3a 38 d1 81 81 4a 48 5e 4a 07 81 81 36 4c da 4e d9 81 81 2c 48 93 4e c1 81 81 d6 52 ec 54 81 81 81 e1 5c 7f 64 81 81 81 f5 4e 58 5c 81 81 81 eb 54 5a 5a 81 81 81 81 4c 5c 58 81 81 81 81 63 7b 52 81 81 81 81 0e 81 81 85 81\n",
            "=======\n",
            "===\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'Q_SELayer' object has no attribute 'weights'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[22], line 92\u001b[0m\n\u001b[0;32m     90\u001b[0m input_or_weight_gen(q_input_activation[\u001b[39m\"\u001b[39m\u001b[39mConv.1\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     91\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m===\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 92\u001b[0m input_or_weight_gen(quantized_model\u001b[39m.\u001b[39;49mConv[\u001b[39m4\u001b[39;49m]\u001b[39m.\u001b[39;49mweights)\n\u001b[0;32m     94\u001b[0m \u001b[39mprint\u001b[39m(quantized_model\u001b[39m.\u001b[39mConv[\u001b[39m4\u001b[39m]\u001b[39m.\u001b[39minput_zero_point)\n\u001b[0;32m     96\u001b[0m DeS \u001b[39m=\u001b[39m quantized_model\u001b[39m.\u001b[39mConv[\u001b[39m3\u001b[39m]\u001b[39m.\u001b[39mstore_scale\n",
            "File \u001b[1;32mc:\\Users\\胡家豪\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1693\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m   1694\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1695\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'Q_SELayer' object has no attribute 'weights'"
          ]
        }
      ],
      "source": [
        "def signed_dec2hex_matrix(input):\n",
        "    '''Convert a matrix which data is signed decimal to 8 bits hex with 2's complement'''\n",
        "    temp = []\n",
        "    bin8 = lambda x : ''.join(reversed( [str((x >> i) & 1) for i in range(8)] ) )\n",
        "    for i in input:\n",
        "        test =bin8(i)\n",
        "        test = int(test,base=2)\n",
        "        hex_test = hex(test)[2:].zfill(2)\n",
        "        temp.append(hex_test)\n",
        "\n",
        "    return temp\n",
        "\n",
        "def signed_dec2hex(input):\n",
        "    '''Convert a number which data is signed decimal to 8 bits hex with 2's complement'''\n",
        "    bin8 = lambda x : ''.join(reversed( [str((x >> i) & 1) for i in range(8)] ) )\n",
        "    test =bin8(input)\n",
        "    test = int(test,base=2)\n",
        "    hex_test = hex(test)[2:].zfill(2)\n",
        "\n",
        "    return hex_test\n",
        "\n",
        "\n",
        "def golden_gen(golden_layer_decimal):\n",
        "    '''Convert a layer output which is signed decimal in GPU to 8 bits hex with 2's complement in CPU and\n",
        "     make it 4 element in a line, example of use : golden_gen(q_output_activation[\"Conv.3\"]) '''\n",
        "    golden = []\n",
        "    i=0\n",
        "    golden_in_numpy = golden_layer_decimal.cpu().numpy()\n",
        "    test = golden_in_numpy.flatten()\n",
        "    test =test.astype('int32')\n",
        "    golden.append([])\n",
        "    for j, data in enumerate(test):\n",
        "        if(j%4==0 ):\n",
        "            golden.append([])\n",
        "            i = i+1\n",
        "            golden[i].append(signed_dec2hex(data))\n",
        "        if(j%4!=0):\n",
        "            golden[i].append(signed_dec2hex(data))\n",
        "    golden.pop(0)\n",
        "    for indice,data in enumerate(golden):\n",
        "        print(*data,sep='')\n",
        "\n",
        "def input_or_weight_gen(layer_decimal):\n",
        "    '''Convert a layer output which is signed decimal in GPU to 8 bits hex with 2's complement in CPU and\n",
        "     make each byte display in different place, example of use : input_or_weight_gen(quantized_model.Conv[1].weights)'''\n",
        "    byte0 = []\n",
        "    byte1 = []\n",
        "    byte2 = []\n",
        "    byte3 = []\n",
        "\n",
        "    data_in_numpy = layer_decimal.cpu().numpy()\n",
        "    data_test = data_in_numpy.flatten()\n",
        "    data_test = data_test.astype('int32')\n",
        "    data_test = signed_dec2hex_matrix(data_test)\n",
        "    for indice,data in enumerate(data_test):\n",
        "        if(indice%4 == 0):\n",
        "            byte0.append(data)\n",
        "        elif(indice%4 == 1):\n",
        "            byte1.append(data)\n",
        "        elif(indice%4 == 2):\n",
        "            byte2.append(data)\n",
        "        else:\n",
        "            byte3.append(data)\n",
        "    print(\"byte0:\",*byte0)\n",
        "    print(\"=======\")\n",
        "    print(\"byte1:\",*byte1)\n",
        "    print(\"=======\")\n",
        "    print(\"byte2:\",*byte2)\n",
        "    print(\"=======\")\n",
        "    print(\"byte3:\",*byte3)\n",
        "    print(\"=======\")\n",
        "    return byte0,byte1,byte2,byte3\n",
        "\n",
        "def DecToBin_machine(num,accuracy):\n",
        "    integer = int(num)\n",
        "    flo = num - integer\n",
        "    integercom = '{:1b}'.format(integer)\n",
        "    tem = flo\n",
        "    flo_list = []\n",
        "    for i in range(accuracy):\n",
        "        tem *= 2\n",
        "        flo_list += str(int(tem))\n",
        "        tem -= int(tem)\n",
        "    flocom = flo_list\n",
        "    binary_value =  ''.join(flocom)\n",
        "    return binary_value\n",
        "\n",
        "#golden_gen(q_output_activation[\"Conv.3\"])\n",
        "print(signed_dec2hex(quantized_model.Conv[1].input_zero_point))\n",
        "input_or_weight_gen(q_input_activation[\"Conv.1\"])\n",
        "print(\"===\")\n",
        "input_or_weight_gen(quantized_model.Conv[4].weights)\n",
        "\n",
        "print(quantized_model.Conv[4].input_zero_point)\n",
        "\n",
        "DeS = quantized_model.Conv[3].store_scale\n",
        "print(DeS)\n",
        "#print(DeS *8192) # 2**13\n",
        "#print(\"deq_scale (shift 13):\",DecToBin_machine(quantized_model.Conv[1].,8))\n",
        "print(\"req_scale (shift 6):\",)\n",
        "print(\"output zero\",)\n",
        "#binary_value = integercom + '.' + ''.join(flocom)\n",
        "result = DecToBin_machine(DeS,8)\n",
        "print(result)\n",
        "# 0.1100111101011100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMccqTL6URaZ"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRMXzNeCgDuq",
        "outputId": "0fa65b9f-3a60-41e0-a935-a601a8db0484"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Error: \n",
            " Accuracy: 86.9%, Avg loss: 0.000380 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_loop(test_loader, FP32_model, loss_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knTzO1mbheBe",
        "outputId": "411fc256-b7ea-4757-9f75-6acaae605324"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Error: \n",
            " Accuracy: 86.9%, Avg loss: 0.000064 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_loop(test_loader, quantized_model, loss_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['Conv.0', 'Conv.1', 'Conv.2.avg_pool', 'Conv.2.fc.0', 'Conv.2.fc.1', 'Conv.2.fc.2', 'Conv.2.fc.3', 'Conv.3', 'Conv.4', 'backbone.0', 'backbone.1', 'backbone.2', 'backbone.3', 'backbone.4'])\n",
            "dict_keys(['Conv.0', 'Conv.1', 'Conv.2', 'Conv.3', 'Conv.4.avg_pool', 'Conv.4.fc.0', 'Conv.4.fc.1', 'Conv.4', 'Conv.5', 'Conv.6', 'Conv.7', 'backbone.0', 'backbone.1', 'backbone.2'])\n"
          ]
        }
      ],
      "source": [
        "print(output_activation.keys())\n",
        "print(q_output_activation.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(125440,)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(array([1.3000e+01, 1.4200e+02, 2.2200e+02, 3.0300e+02, 4.8000e+02,\n",
              "        5.2100e+02, 8.8600e+02, 6.4759e+04, 1.0730e+03, 1.3310e+03,\n",
              "        1.2910e+03, 8.2400e+02, 8.0600e+02, 7.4600e+02, 7.7600e+02,\n",
              "        7.6000e+02, 8.2800e+02, 8.4200e+02, 1.0100e+03, 8.7100e+02,\n",
              "        1.2100e+03, 7.9400e+02, 1.4660e+03, 1.0810e+03, 5.4900e+02,\n",
              "        8.5100e+02, 1.5600e+02, 1.6000e+02, 1.2580e+03, 2.5940e+03,\n",
              "        2.9940e+03, 1.5100e+03, 1.8490e+03, 8.6400e+02, 9.7900e+02,\n",
              "        1.7120e+03, 6.8500e+02, 6.1800e+02, 7.1900e+02, 7.0800e+02,\n",
              "        6.6500e+02, 6.2400e+02, 5.2500e+02, 6.1700e+02, 6.0300e+02,\n",
              "        5.3600e+02, 5.5300e+02, 3.8800e+02, 3.7500e+02, 4.4600e+02,\n",
              "        4.5200e+02, 4.2000e+02, 4.3700e+02, 3.7600e+02, 3.4000e+02,\n",
              "        3.7400e+02, 3.5200e+02, 2.6900e+02, 2.5300e+02, 4.8400e+02,\n",
              "        1.4100e+02, 1.3200e+02, 1.5200e+02, 1.1000e+02, 1.0700e+02,\n",
              "        4.0600e+02, 4.3600e+02, 4.4700e+02, 4.1500e+02, 4.2100e+02,\n",
              "        3.3100e+02, 4.5100e+02, 4.0000e+01, 4.0000e+01, 6.0000e+01,\n",
              "        3.0700e+02, 9.4100e+02, 9.1200e+02, 1.5560e+03, 1.7460e+03,\n",
              "        1.0110e+03, 1.5000e+01, 5.1100e+02, 7.0400e+02, 5.2000e+02,\n",
              "        7.8000e+02, 9.0000e+00, 1.8000e+01, 5.1700e+02, 1.8000e+01,\n",
              "        5.9200e+02, 2.5000e+01, 1.2390e+03]),\n",
              " array([-0.26296028, -0.22821784, -0.1934754 , -0.15873295, -0.1239905 ,\n",
              "        -0.08924805, -0.05450561, -0.01976316,  0.01497928,  0.04972173,\n",
              "         0.08446418,  0.11920662,  0.15394907,  0.18869151,  0.22343396,\n",
              "         0.25817642,  0.29291886,  0.32766131,  0.36240375,  0.3971462 ,\n",
              "         0.43188864,  0.46663108,  0.50137353,  0.53611594,  0.57085842,\n",
              "         0.60560089,  0.64034331,  0.67508578,  0.7098282 ,  0.74457067,\n",
              "         0.77931309,  0.81405556,  0.84879798,  0.88354045,  0.91828287,\n",
              "         0.95302534,  0.98776776,  1.02251017,  1.05725265,  1.09199512,\n",
              "         1.12673759,  1.16147995,  1.19622242,  1.2309649 ,  1.26570737,\n",
              "         1.30044973,  1.3351922 ,  1.36993468,  1.40467715,  1.43941963,\n",
              "         1.47416198,  1.50890446,  1.54364693,  1.57838941,  1.61313176,\n",
              "         1.64787424,  1.68261671,  1.71735919,  1.75210154,  1.78684402,\n",
              "         1.82158649,  1.85632896,  1.89107132,  1.92581379,  1.96055627,\n",
              "         1.99529874,  2.03004122,  2.06478357,  2.09952593,  2.13426852,\n",
              "         2.16901088,  2.20375347,  2.23849583,  2.27323818,  2.30798078,\n",
              "         2.34272313,  2.37746572,  2.41220808,  2.44695044,  2.48169303,\n",
              "         2.51643538,  2.55117774,  2.58592033,  2.62066269,  2.65540528,\n",
              "         2.69014764,  2.72488999,  2.75963259,  2.79437494,  2.8291173 ,\n",
              "         2.86385989,  2.89860225,  2.93334484,  2.9680872 ]),\n",
              " <BarContainer object of 93 artists>)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#y = torch.flatten(FP32_model.Conv[0].weight)\n",
        "y = torch.flatten(input_activation['Conv.3'])\n",
        "y = y.cpu()\n",
        "y = torch.flatten(y)\n",
        "y = y.detach()\n",
        "y = y.numpy()\n",
        "print(y.shape)\n",
        "\n",
        "plt.hist(y, bins='auto',density=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(125440,)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(array([1.5000e+01, 1.0900e+02, 2.5300e+02, 2.2500e+02, 4.4200e+02,\n",
              "        5.2900e+02, 4.7900e+02, 6.4546e+04, 5.6800e+02, 1.0860e+03,\n",
              "        1.2960e+03, 7.8700e+02, 1.2320e+03, 1.0400e+03, 7.2900e+02,\n",
              "        1.0390e+03, 1.0300e+03, 8.4100e+02, 1.2760e+03, 1.5700e+03,\n",
              "        6.7700e+02, 1.0950e+03, 1.4000e+03, 1.0130e+03, 7.3900e+02,\n",
              "        5.7500e+02, 9.3400e+02, 1.3690e+03, 6.0200e+02, 6.7900e+02,\n",
              "        1.6940e+03, 2.2300e+02, 3.2610e+03, 2.5540e+03, 1.2020e+03,\n",
              "        1.5730e+03, 7.6100e+02, 1.2880e+03, 8.3900e+02, 8.0000e+02,\n",
              "        6.9300e+02, 8.3000e+02, 5.7100e+02, 3.2200e+02, 4.3500e+02,\n",
              "        4.8700e+02, 4.2000e+02, 4.2900e+02, 4.5500e+02, 3.1400e+02,\n",
              "        3.4200e+02, 3.2700e+02, 1.5200e+02, 2.8500e+02, 2.9700e+02,\n",
              "        1.9100e+02, 3.0900e+02, 2.8100e+02, 3.1800e+02, 3.6200e+02,\n",
              "        2.5500e+02, 1.9700e+02, 1.9600e+02, 3.8100e+02, 1.3900e+02,\n",
              "        1.2200e+02, 3.6500e+02, 6.6600e+02, 1.1500e+02, 3.4100e+02,\n",
              "        3.2800e+02, 5.7000e+01, 1.0150e+03, 7.2000e+01, 8.1500e+02,\n",
              "        2.6300e+02, 4.7000e+01, 5.1000e+01, 7.3600e+02, 3.6000e+01,\n",
              "        5.3200e+02, 5.5800e+02, 8.3000e+01, 1.3550e+03, 5.6700e+02,\n",
              "        1.5800e+03, 1.6290e+03, 1.7000e+01, 9.3500e+02, 2.8000e+01,\n",
              "        1.0840e+03, 0.0000e+00, 1.0000e+00, 0.0000e+00, 3.0000e+00,\n",
              "        6.8100e+02]),\n",
              " array([-128.     , -125.34375, -122.6875 , -120.03125, -117.375  ,\n",
              "        -114.71875, -112.0625 , -109.40625, -106.75   , -104.09375,\n",
              "        -101.4375 ,  -98.78125,  -96.125  ,  -93.46875,  -90.8125 ,\n",
              "         -88.15625,  -85.5    ,  -82.84375,  -80.1875 ,  -77.53125,\n",
              "         -74.875  ,  -72.21875,  -69.5625 ,  -66.90625,  -64.25   ,\n",
              "         -61.59375,  -58.9375 ,  -56.28125,  -53.625  ,  -50.96875,\n",
              "         -48.3125 ,  -45.65625,  -43.     ,  -40.34375,  -37.6875 ,\n",
              "         -35.03125,  -32.375  ,  -29.71875,  -27.0625 ,  -24.40625,\n",
              "         -21.75   ,  -19.09375,  -16.4375 ,  -13.78125,  -11.125  ,\n",
              "          -8.46875,   -5.8125 ,   -3.15625,   -0.5    ,    2.15625,\n",
              "           4.8125 ,    7.46875,   10.125  ,   12.78125,   15.4375 ,\n",
              "          18.09375,   20.75   ,   23.40625,   26.0625 ,   28.71875,\n",
              "          31.375  ,   34.03125,   36.6875 ,   39.34375,   42.     ,\n",
              "          44.65625,   47.3125 ,   49.96875,   52.625  ,   55.28125,\n",
              "          57.9375 ,   60.59375,   63.25   ,   65.90625,   68.5625 ,\n",
              "          71.21875,   73.875  ,   76.53125,   79.1875 ,   81.84375,\n",
              "          84.5    ,   87.15625,   89.8125 ,   92.46875,   95.125  ,\n",
              "          97.78125,  100.4375 ,  103.09375,  105.75   ,  108.40625,\n",
              "         111.0625 ,  113.71875,  116.375  ,  119.03125,  121.6875 ,\n",
              "         124.34375,  127.     ]),\n",
              " <BarContainer object of 96 artists>)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#x = torch.flatten(quantized_weights12)\n",
        "#x = torch.flatten(quantized_model.Conv[1].weights)\n",
        "#print(q_output_activation['Conv.3'])\n",
        "x = torch.flatten(q_input_activation['Conv.5'])\n",
        "x = x.cpu()\n",
        "x = torch.flatten(x)\n",
        "x = x.detach()\n",
        "x = x.numpy()\n",
        "print(x.shape)\n",
        "\n",
        "plt.hist(x, bins='auto',density=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
