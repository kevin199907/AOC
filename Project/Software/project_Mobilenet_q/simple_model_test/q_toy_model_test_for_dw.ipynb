{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin199907/.conda/envs/ldm/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import math\n",
    "import random\n",
    "from collections import OrderedDict, defaultdict\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.datasets import *\n",
    "from torchvision.transforms import *\n",
    "\n",
    "\n",
    "no_cuda = False\n",
    "use_gpu = not no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n",
    "\n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    \"\"\"\n",
    "    This function is taken from the original tf repo.\n",
    "    It ensures that all layers have a channel number that is divisible by 8\n",
    "    It can be seen here:\n",
    "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    :param v:\n",
    "    :param divisor:\n",
    "    :param min_value:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "class h_sigmoid(nn.Module):\n",
    "    def __init__(self, inplace=True):\n",
    "        super(h_sigmoid, self).__init__()\n",
    "        self.relu = nn.ReLU6(inplace=inplace)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(x + 3) / 6\n",
    "\n",
    "\n",
    "class h_swish(nn.Module):\n",
    "    def __init__(self, inplace=True):\n",
    "        super(h_swish, self).__init__()\n",
    "        self.sigmoid = h_sigmoid(inplace=inplace)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.sigmoid(x)\n",
    "    \n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=4):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "                nn.Linear(channel, _make_divisible(channel // reduction, 8),bias=False),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(_make_divisible(channel // reduction, 8), channel,bias=False),\n",
    "                nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y\n",
    "\n",
    "class ToyModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.Conv = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=1, out_channels=8, kernel_size=1, stride=1,padding= 0, bias=True),\n",
    "      h_swish(inplace=True),\n",
    "      nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3, stride=3,padding= 1, bias=True,groups=8),\n",
    "      h_swish(inplace=True),\n",
    "      SELayer(8),\n",
    "      nn.Conv2d(in_channels=8, out_channels=1, kernel_size=1, stride=1,padding= 0, bias=True),\n",
    "      h_swish(inplace=True)\n",
    "    )  \n",
    "    self.backbone = nn.Sequential(\n",
    "      nn.Linear(10*10, 120, bias=False),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(120, 84, bias=False),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(84, 10, bias=False)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x=self.Conv(x)\n",
    "    x = x.view(-1, 10*10) #transform 28*28 figure to 784 vector\n",
    "    x = self.backbone(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "class Q_SELayer(nn.Module):\n",
    "  def __init__(self,weights1,input_scale1,weight_scale1,output_scale1, input_zero_point1, weight_zero_point1, output_zero_point1,\n",
    "               weights2, input_scale2, weight_scale2, output_scale2, input_zero_point2, weight_zero_point2, output_zero_point2,\n",
    "               input_SE_scale,in_SE_zero_point,\n",
    "               output_SE_scale,output_SE_zero_point,\n",
    "               out_pool_scale,out_pool_zero_point):\n",
    "    super().__init__()\n",
    "    self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "    self.fc = nn.Sequential(\n",
    "        QuantizedLinear(weights1,input_scale1,weight_scale1,output_scale1, input_zero_point1, weight_zero_point1, output_zero_point1),\n",
    "        QuantizedLinear(weights2, input_scale2, weight_scale2, output_scale2, input_zero_point2, weight_zero_point2, output_zero_point2)\n",
    "    )   \n",
    "    self.input_SE_scale, self.in_SE_zero_point = input_SE_scale,in_SE_zero_point\n",
    "    self.output_SE_scale, self.output_SE_zero_point = output_SE_scale, output_SE_zero_point,\n",
    "    self.out_pool_scale, self.out_pool_zero_point = out_pool_scale,out_pool_zero_point\n",
    "    self.linear_out_scale, self.linear_out_zero_point = output_scale2, output_zero_point2\n",
    "\n",
    "\n",
    "  def forward(self,x):\n",
    "    b, c, _, _ = x.size()\n",
    "    y = self.avg_pool(x).view(b, c)\n",
    "    y = (y- self.in_SE_zero_point) \n",
    "    y = do_fake_quant(y, self.input_SE_scale, self.out_pool_scale, self.out_pool_zero_point,bitwidth=8)\n",
    "    y = self.fc(y).view(b, c, 1, 1)\n",
    "    z = (x-self.in_SE_zero_point)*(y-self.linear_out_zero_point)\n",
    "    return do_fake_quant(z, deq_scale=(self.input_SE_scale *self.linear_out_scale), \n",
    "                         q_scale=self.output_SE_scale, q_zero_point=self.output_SE_zero_point,bitwidth=8)\n",
    "  \n",
    "  def __repr__(self):\n",
    "    return f\"Quantized_SE(in_channels={self.fc[0].weights.size(1)}, out_channels={self.fc[1].weights.size(0)})\"\n",
    "    \n",
    "\n",
    "\n",
    "class QuantizedConv(nn.Module):\n",
    "  def __init__(self,bias ,weights,stride,padding,groups ,input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point, bitwidth=8, activation_bitwidth=8):\n",
    "    super().__init__()\n",
    "    self.stride, self.padding, self.groups = stride, padding,groups\n",
    "    self.weights = weights\n",
    "    self.input_scale, self.input_zero_point = input_scale, input_zero_point\n",
    "    self.weight_scale, self.weight_zero_point = weight_scale, weight_zero_point\n",
    "    self.output_scale, self.output_zero_point = output_scale, output_zero_point\n",
    "    self.bias = bias\n",
    "    self.bitwidth = bitwidth\n",
    "    self.activation_bitwidth = activation_bitwidth\n",
    "    self.q_bias = torch.round(bias / (input_scale*weight_scale))\n",
    "    self.q_weight = weights - weight_zero_point\n",
    "    self.DeQ_scale = input_scale*weight_scale*8192\n",
    "  def forward(self, x):\n",
    "    return quantized_conv(x, self.bias, self.weights, self.stride, self.padding, self.groups, self.input_scale, self.weight_scale, self.output_scale, self.input_zero_point, self.weight_zero_point, self.output_zero_point, device)\n",
    "  def __repr__(self):\n",
    "    return f\"QuantizedConv(in_channels={self.weights.size(1)}, out_channels={self.weights.size(0)})\"\n",
    "\n",
    "class QuantizedLinear(nn.Module):\n",
    "  def __init__(self, weights, input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point, bitwidth=8, activation_bitwidth=8):\n",
    "    super().__init__()\n",
    "    self.weights = weights\n",
    "    self.input_scale, self.input_zero_point = input_scale, input_zero_point\n",
    "    self.weight_scale, self.weight_zero_point = weight_scale, weight_zero_point\n",
    "    self.output_scale, self.output_zero_point = output_scale, output_zero_point\n",
    "\n",
    "    self.bitwidth = bitwidth\n",
    "    self.activation_bitwidth = activation_bitwidth\n",
    "\n",
    "  def forward(self, x):\n",
    "    return quantized_linear(x, self.weights, self.input_scale, self.weight_scale, self.output_scale, self.input_zero_point, self.weight_zero_point, self.output_zero_point, device)\n",
    "  def __repr__(self):\n",
    "    return f\"QuantizedLinear(in_channels={self.weights.size(1)}, out_channels={self.weights.size(0)})\"\n",
    "\n",
    "#Transform input data to correct integer range\n",
    "class Preprocess(nn.Module):\n",
    "  def __init__(self, input_scale, input_zero_point, activation_bitwidth=8):\n",
    "    super().__init__()\n",
    "    self.input_scale, self.input_zero_point = input_scale, input_zero_point\n",
    "    self.activation_bitwidth = activation_bitwidth\n",
    "  def forward(self, x):\n",
    "    x = x / self.input_scale + self.input_zero_point\n",
    "    x = x.round() \n",
    "    return x\n",
    "  \n",
    "class Quantizer(nn.Module):\n",
    "  def __init__(self,scale,zero_point,bitwidth=8):\n",
    "    super().__init__()\n",
    "    self.scale = scale\n",
    "    self.zero = zero_point\n",
    "    self.store_scale = scale *64\n",
    "\n",
    "  def forward(self,x):\n",
    "    return do_requant(x,self.scale,self.zero)\n",
    "    \n",
    "    \n",
    "\n",
    "def quantized_linear(input, weights, input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point, device, bitwidth=8, activation_bitwidth=8):\n",
    "  input, weights = input.to(device), weights.to(device)\n",
    "\n",
    "  #####################################################\n",
    "\n",
    "  M = input_scale * weight_scale / output_scale\n",
    "  output = torch.nn.functional.linear((input - input_zero_point ), (weights - weight_zero_point))\n",
    "  output *= M\n",
    "  output += output_zero_point\n",
    "\n",
    "  #####################################################\n",
    "\n",
    "  #clamp and round\n",
    "  output = output.round().clamp(-(2**(activation_bitwidth-1)), 2**(activation_bitwidth-1)-1)\n",
    "\n",
    "  return output\n",
    "\n",
    "def quantized_conv(input, bias,weights,stride, padding,groups,input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point, device, bitwidth=8, activation_bitwidth=16):\n",
    "  input, weights = input.to(device), weights.to(device)\n",
    "\n",
    "  #####################################################\n",
    "\n",
    "  M = input_scale * weight_scale \n",
    "  conv_bias = bias /M\n",
    "  conv_bias = conv_bias.round()\n",
    "  output_only_conv = torch.nn.functional.conv2d((input - input_zero_point ), (weights - weight_zero_point),bias = conv_bias ,stride=stride,padding=padding,groups=groups)\n",
    "  output = M * output_only_conv\n",
    "  #output += output_zero_point\n",
    "  #####################################################\n",
    "\n",
    "  #clamp and round\n",
    "  output = output.clamp(-(2**(activation_bitwidth-1)), 2**(activation_bitwidth-1)-1)\n",
    "  return output\n",
    "\n",
    "def do_requant(input, scale,zero_point,bitwidth=8):\n",
    "    output = input / scale\n",
    "    output = output.round()\n",
    "    output += zero_point\n",
    "    output = output.round().clamp(-(2**(bitwidth-1)), 2**(bitwidth-1)-1)\n",
    "    return output\n",
    "\n",
    "def do_fake_quant(input, deq_scale, q_scale, q_zero_point,bitwidth=8):\n",
    "    M = deq_scale/q_scale\n",
    "    N = q_zero_point\n",
    "    output = input * M\n",
    "    output += N\n",
    "    output = output.round().clamp(-(2**(bitwidth-1)), 2**(bitwidth-1)-1)\n",
    "    return output\n",
    "\n",
    "def signed_dec2hex_matrix_16b(input):\n",
    "    '''Convert a matrix which data is signed decimal to 8 bits hex with 2's complement'''\n",
    "    temp = []\n",
    "    bin8 = lambda x : ''.join(reversed( [str((x >> i) & 1) for i in range(16)] ) )\n",
    "    for i in input:\n",
    "        test =bin8(i)\n",
    "        test = int(test,base=2)\n",
    "        hex_test = hex(test)[2:].zfill(2)\n",
    "        temp.append(hex_test)\n",
    "\n",
    "    return temp\n",
    "\n",
    "def signed_dec2hex_16b(input):\n",
    "    '''Convert a number which data is signed decimal to 8 bits hex with 2's complement'''\n",
    "    bin8 = lambda x : ''.join(reversed( [str((x >> i) & 1) for i in range(16)] ) )\n",
    "    test =bin8(input)\n",
    "    test = int(test,base=2)\n",
    "    hex_test = hex(test)[2:].zfill(2)\n",
    "\n",
    "    return hex_test\n",
    "\n",
    "\n",
    "def signed_dec2hex_matrix(input):\n",
    "    '''Convert a matrix which data is signed decimal to 8 bits hex with 2's complement'''\n",
    "    temp = []\n",
    "    bin8 = lambda x : ''.join(reversed( [str((x >> i) & 1) for i in range(8)] ) )\n",
    "    for i in input:\n",
    "        test =bin8(i)\n",
    "        test = int(test,base=2)\n",
    "        hex_test = hex(test)[2:].zfill(2)\n",
    "        temp.append(hex_test)\n",
    "\n",
    "    return temp\n",
    "\n",
    "def signed_dec2hex(input):\n",
    "    '''Convert a number which data is signed decimal to 8 bits hex with 2's complement'''\n",
    "    bin8 = lambda x : ''.join(reversed( [str((x >> i) & 1) for i in range(8)] ) )\n",
    "    test =bin8(input)\n",
    "    test = int(test,base=2)\n",
    "    hex_test = hex(test)[2:].zfill(2)\n",
    "\n",
    "    return hex_test\n",
    "\n",
    "\n",
    "def golden_gen(golden_layer_decimal):\n",
    "    '''Convert a layer output which is signed decimal in GPU to 8 bits hex with 2's complement in CPU and\n",
    "     make it 4 element in a line, example of use : golden_gen(q_output_activation[\"Conv.3\"]) '''\n",
    "    golden = []\n",
    "    i=0\n",
    "    golden_in_numpy = golden_layer_decimal.cpu().numpy()\n",
    "    test = golden_in_numpy.flatten()\n",
    "    test =test.astype('int32')\n",
    "    golden.append([])\n",
    "    for j, data in enumerate(test):\n",
    "        if(j%4==0 ):\n",
    "            golden.append([])\n",
    "            i = i+1\n",
    "            golden[i].append(signed_dec2hex(data))\n",
    "        if(j%4!=0):\n",
    "            golden[i].append(signed_dec2hex(data))\n",
    "    golden.pop(0)\n",
    "    for indice,data in enumerate(golden):\n",
    "        print(*data,sep='')\n",
    "\n",
    "def input_or_weight_gen(layer_decimal):\n",
    "    '''Convert a layer output which is signed decimal in GPU to 8 bits hex with 2's complement in CPU and\n",
    "     make each byte display in different place, example of use : input_or_weight_gen(quantized_model.Conv[1].weights)'''\n",
    "    byte0 = []\n",
    "    byte1 = []\n",
    "    byte2 = []\n",
    "    byte3 = []\n",
    "\n",
    "    data_in_numpy = layer_decimal.cpu().numpy()\n",
    "    data_test = data_in_numpy.flatten()\n",
    "    data_test = data_test.astype('int32')\n",
    "    data_test = signed_dec2hex_matrix(data_test)\n",
    "    for indice,data in enumerate(data_test):\n",
    "        if(indice%4 == 0):\n",
    "            byte0.append(data)\n",
    "        elif(indice%4 == 1):\n",
    "            byte1.append(data)\n",
    "        elif(indice%4 == 2):\n",
    "            byte2.append(data)\n",
    "        else:\n",
    "            byte3.append(data)\n",
    "    print(\"byte0:\",*byte0)\n",
    "    print(\"=======\")\n",
    "    print(\"byte1:\",*byte1)\n",
    "    print(\"=======\")\n",
    "    print(\"byte2:\",*byte2)\n",
    "    print(\"=======\")\n",
    "    print(\"byte3:\",*byte3)\n",
    "    print(\"=======\")\n",
    "    return byte0,byte1,byte2,byte3\n",
    "\n",
    "\n",
    "def bias_gen(layer_decimal):\n",
    "    byte0 = []\n",
    "    byte1 = []\n",
    "    byte2 = []\n",
    "    byte3 = []\n",
    "    temp1 = []\n",
    "\n",
    "    data_in_numpy = layer_decimal.cpu().numpy()\n",
    "    data_test = data_in_numpy.flatten()\n",
    "    data_test = data_test.astype('int32')\n",
    "    data_test = signed_dec2hex_matrix_16b(data_test)\n",
    "    for indice,data in enumerate(data_test):\n",
    "        if(indice%2 == 0):\n",
    "            if(len(data)==1):\n",
    "                byte1.append('00')\n",
    "                byte0.append('0'+str(data))\n",
    "            elif(len(data)==2):\n",
    "                byte1.append('00')\n",
    "                byte0.append(data)\n",
    "            elif(len(data)==3):\n",
    "                temp = data[2]\n",
    "                byte1.append('0'+data[0])\n",
    "                byte0.append(data[1]+data[2])\n",
    "            elif(len(data)==4):\n",
    "                byte1.append(data[0:2])\n",
    "                byte0.append(data[2:4])\n",
    "        elif(indice%2 == 1):\n",
    "            if(len(data)==1):\n",
    "                byte3.append('00')\n",
    "                byte2.append('0'+str(data))\n",
    "            elif(len(data)==2):\n",
    "                byte3.append('00')\n",
    "                byte2.append(data)\n",
    "            elif(len(data)==3):\n",
    "                byte3.append('0'+data[0])\n",
    "                byte2.append(data[1]+data[2])\n",
    "            elif(len(data)==4):\n",
    "                byte3.append(data[0:2])\n",
    "                byte2.append(data[2:4])\n",
    "\n",
    "    print(\"byte0:\",*byte0)\n",
    "    print(\"=======\")\n",
    "    print(\"byte1:\",*byte1)\n",
    "    print(\"=======\")\n",
    "    print(\"byte2:\",*byte2)\n",
    "    print(\"=======\")\n",
    "    print(\"byte3:\",*byte3)\n",
    "    print(\"=======\")\n",
    "    return byte0,byte1,byte2,byte3\n",
    "\n",
    "def DecToBin_machine(num,accuracy):\n",
    "    integer = int(num)\n",
    "    flo = num - integer\n",
    "    integercom = '{:1b}'.format(integer)\n",
    "    tem = flo\n",
    "    flo_list = []\n",
    "    for i in range(accuracy):\n",
    "        tem *= 2\n",
    "        flo_list += str(int(tem))\n",
    "        tem -= int(tem)\n",
    "    flocom = flo_list\n",
    "    binary_value =  ''.join(flocom)\n",
    "    return binary_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToyModel(\n",
      "  (Conv): Sequential(\n",
      "    (0): Preprocess()\n",
      "    (1): QuantizedConv(in_channels=1, out_channels=8)\n",
      "    (2): h_swish(\n",
      "      (sigmoid): h_sigmoid(\n",
      "        (relu): ReLU6(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): Quantizer()\n",
      "    (4): QuantizedConv(in_channels=1, out_channels=8)\n",
      "    (5): h_swish(\n",
      "      (sigmoid): h_sigmoid(\n",
      "        (relu): ReLU6(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Quantizer()\n",
      "    (7): Quantized_SE(in_channels=8, out_channels=8)\n",
      "    (8): QuantizedConv(in_channels=8, out_channels=1)\n",
      "    (9): h_swish(\n",
      "      (sigmoid): h_sigmoid(\n",
      "        (relu): ReLU6(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (10): Quantizer()\n",
      "  )\n",
      "  (backbone): Sequential(\n",
      "    (0): QuantizedLinear(in_channels=100, out_channels=120)\n",
      "    (1): QuantizedLinear(in_channels=120, out_channels=84)\n",
      "    (2): QuantizedLinear(in_channels=84, out_channels=10)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "#Dataset\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "model = torch.load('dw_customize_Toymodel.pt',map_location=device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Conv.0', 'Conv.1', 'Conv.2', 'Conv.3', 'Conv.4', 'Conv.5', 'Conv.6', 'Conv.7.fc.0', 'Conv.7.fc.1', 'Conv.8', 'Conv.9', 'Conv.10', 'backbone.0', 'backbone.1', 'backbone.2'])\n"
     ]
    }
   ],
   "source": [
    "# add hook to record the min max value of the activation\n",
    "q_input_activation = {}\n",
    "q_output_activation = {}\n",
    "\n",
    "#Define a hook to record the feature map of each layer\n",
    "def add_range_recoder_hook(model):\n",
    "    import functools\n",
    "    def _record_range(self, x, y, module_name):\n",
    "        x = x[0]\n",
    "        q_input_activation[module_name] = x.detach()\n",
    "        q_output_activation[module_name] = y.detach()\n",
    "\n",
    "    all_hooks = []\n",
    "    for name, m in model.named_modules():\n",
    "        if isinstance(m, (QuantizedConv,  QuantizedLinear,h_swish,Quantizer,Preprocess)):\n",
    "            all_hooks.append(m.register_forward_hook(\n",
    "                functools.partial(_record_range, module_name=name)))\n",
    "\n",
    "\n",
    "    return all_hooks\n",
    "\n",
    "\n",
    "q_test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "hooks = add_range_recoder_hook(model)\n",
    "sample_data = iter(q_test_loader).__next__()[0].to(device) #Use a batch of training data to calibrate\n",
    "model(sample_data) #Forward to use hook\n",
    "#print(quantized_model.Conv[1].weights)\n",
    "print(q_output_activation.keys())\n",
    "# print(q_input_activation[\"Conv.2\"])\n",
    "#print(q_output_activation[\"Conv.4\"])\n",
    "# print(quantized_model.Conv[1].bias)\n",
    "# print(quantized_model.Conv[1].q_bias)\n",
    "# print(quantized_model.Conv[1].input_scale)\n",
    "# print(quantized_model.Conv[1].weight_scale)\n",
    "# remove hooks\n",
    "for h in hooks:\n",
    "    h.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.000000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "#Dataset\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "#Dataloader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() #define loss function\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "  #set model to evaluate mode\n",
    "  model.eval()\n",
    "  size = len(dataloader.dataset)\n",
    "  num_batches = len(dataloader)\n",
    "  test_loss, correct = 0, 0\n",
    "  with torch.no_grad():\n",
    "    for x, y in dataloader:\n",
    "      if use_gpu:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "      pred = model(x)\n",
    "      test_loss = loss_fn(pred, y).item()\n",
    "      correct += (pred.argmax(1) == y).type(torch.float).sum().item() #calculate accuracy\n",
    "  test_loss /= num_batches\n",
    "  correct /= size\n",
    "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "test_loop(test_loader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.707694528976893\n",
      "10110101\n",
      "53.57103390375497\n"
     ]
    }
   ],
   "source": [
    "print( model.Conv[4].input_scale *  model.Conv[4].weight_scale*16384 )\n",
    "print(DecToBin_machine( model.Conv[4].input_scale *  model.Conv[4].weight_scale*16384,8 ))\n",
    "print(1/ model.Conv[6].scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([221.,  11., 154.,  88., 119.,  60.,  46.,  18.,   6.,   6.,   8.,\n",
       "         25.,   1.,   2.,   1.,  34.]),\n",
       " array([-128.   , -112.125,  -96.25 ,  -80.375,  -64.5  ,  -48.625,\n",
       "         -32.75 ,  -16.875,   -1.   ,   14.875,   30.75 ,   46.625,\n",
       "          62.5  ,   78.375,   94.25 ,  110.125,  126.   ]),\n",
       " <BarContainer object of 16 artists>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.flatten(q_output_activation['Conv.6'])\n",
    "x = x.cpu()\n",
    "x = torch.flatten(x)\n",
    "x = x.detach()\n",
    "x = x.numpy()\n",
    "print(x.shape)\n",
    "\n",
    "plt.hist(x, bins='auto',density=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-22791., -22080.,  14448., -19011.,  -7044., -19033.,  11902., -20904.],\n",
      "       device='cuda:0')\n",
      "byte0: f9 70 7c 7e\n",
      "=======\n",
      "byte1: a6 38 e4 2e\n",
      "=======\n",
      "byte2: c0 bd a7 58\n",
      "=======\n",
      "byte3: a9 b5 b5 ae\n",
      "=======\n",
      "=========dividen=============\n",
      "byte0: f9 70 7c 7e\n",
      "=======\n",
      "byte1: a6 38 e4 2e\n",
      "=======\n",
      "byte2: c0 bd a7 58\n",
      "=======\n",
      "byte3: a9 b5 b5 ae\n",
      "=======\n",
      "deq_scale (shift 13): 01011010\n",
      "req_scale (shift 6): 00000001\n"
     ]
    }
   ],
   "source": [
    "#golden_gen(q_output_activation[\"Conv.3\"])\n",
    "#print(model.Conv[1].input_zero_point)\n",
    "#input_or_weight_gen(q_input_activation[\"Conv.1\"])\n",
    "#print(\"===\")\n",
    "\n",
    "#input_or_weight_gen(model.Conv[1].weights)\n",
    "print(model.Conv[4].q_bias)\n",
    "bias_gen(model.Conv[4].q_bias)\n",
    "print(\"=========dividen=============\")\n",
    "bias_gen(model.Conv[1].q_bias)\n",
    "#golden_gen(q_output_activation[\"Conv.3\"])\n",
    "#print(model.Conv[1].DeQ_scale)\n",
    "#print(model.Conv[3].scale)\n",
    "print(\"deq_scale (shift 13):\",DecToBin_machine(model.Conv[1].DeQ_scale*8192 ,8))\n",
    "print(\"req_scale (shift 6):\",DecToBin_machine(model.Conv[3].scale ,8))\n",
    "#print(\"output zero\",)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b2bababa\n",
      "babababa\n",
      "baafb9c4\n",
      "c4c4c4c4\n",
      "c4c4c4b6\n",
      "b9c4c4c4\n",
      "c4c4c5c4\n",
      "c7b6b9c4\n",
      "c4c4c5d3\n",
      "e3d5e6b6\n",
      "b9c4c4c5\n",
      "caedfafd\n",
      "fab8b9c5\n",
      "c6d2ebf3\n",
      "fbfbfac4\n",
      "c6e8edf2\n",
      "f4f8fafd\n",
      "fdcbbdd9\n",
      "e7e7e8de\n",
      "d4eae9c1\n",
      "b9c4c4c4\n",
      "c4c4c4c4\n",
      "c4b6b1b8\n",
      "b8b8b8b8\n",
      "b8b8b8af\n",
      "b4bababa\n",
      "babababa\n",
      "baabb8c1\n",
      "c1c1c1c1\n",
      "c1c1c1ac\n",
      "b8c1c1c1\n",
      "c1c1c1c1\n",
      "c1acb8c1\n",
      "c1c1c1c0\n",
      "bebfbdac\n",
      "b8c1c1c1\n",
      "c1bebcbb\n",
      "bcacb8c1\n",
      "c1c0bebd\n",
      "bcbcbcab\n",
      "b7bebebd\n",
      "bdbcbcbb\n",
      "bbabb8bf\n",
      "bebdbdbf\n",
      "c0bcbdac\n",
      "b8c1c1c1\n",
      "c1c1c1c1\n",
      "c1acaeaf\n",
      "afafafaf\n",
      "afafafa4\n",
      "f3383838\n",
      "38383838\n",
      "38ee397e\n",
      "7e7e7e7e\n",
      "7e7e7e2c\n",
      "397e7e7e\n",
      "7e7e7e7e\n",
      "782c397e\n",
      "7e7e7d5d\n",
      "37522f2c\n",
      "397e7e7d\n",
      "7113eade\n",
      "e720387e\n",
      "7a601c03\n",
      "e7e4e8eb\n",
      "0c2c1909\n",
      "04f2e6db\n",
      "dbd6243e\n",
      "1b1b132c\n",
      "41f902f9\n",
      "397e7e7e\n",
      "7e7e7e7e\n",
      "7e2c063b\n",
      "3b3b3b3b\n",
      "3b3b3bf8\n",
      "a8a9a9a9\n",
      "a9a9a9a9\n",
      "a9a6abad\n",
      "adadadad\n",
      "adadada9\n",
      "abadadad\n",
      "adadaead\n",
      "afa9abad\n",
      "adadaeb8\n",
      "c6bac8a9\n",
      "abadadae\n",
      "b0cfdadc\n",
      "daaaabad\n",
      "aeb7ced3\n",
      "d9dbd9b1\n",
      "b5c9ced2\n",
      "d4d8dadc\n",
      "dcb8afbd\n",
      "cbcbcdc4\n",
      "bacfcdb1\n",
      "abadadad\n",
      "adadadad\n",
      "ada9a7a9\n",
      "a9a9a9a9\n",
      "a9a9a9a6\n",
      "86868686\n",
      "86868686\n",
      "86868686\n",
      "86868686\n",
      "86868686\n",
      "86868686\n",
      "86868686\n",
      "86868686\n",
      "86868686\n",
      "88888786\n",
      "86868686\n",
      "86878787\n",
      "88878686\n",
      "86878787\n",
      "88888788\n",
      "87888787\n",
      "87878888\n",
      "88888686\n",
      "86878786\n",
      "86868687\n",
      "86868686\n",
      "86868686\n",
      "86868686\n",
      "86868686\n",
      "86868686\n",
      "87858585\n",
      "85858585\n",
      "85878582\n",
      "82828282\n",
      "82828285\n",
      "85828282\n",
      "82828282\n",
      "81858582\n",
      "82828280\n",
      "84808485\n",
      "85828282\n",
      "81858d90\n",
      "8e838582\n",
      "82808589\n",
      "8e8f8d80\n",
      "81838688\n",
      "898c8e90\n",
      "90808380\n",
      "84848482\n",
      "80858580\n",
      "85828282\n",
      "82828282\n",
      "82858885\n",
      "85858585\n",
      "85858587\n",
      "a2a9a9a9\n",
      "a9a9a9a9\n",
      "a9a8a2ab\n",
      "abababab\n",
      "abababaa\n",
      "a2ababab\n",
      "abababab\n",
      "abaaa2ab\n",
      "abababa7\n",
      "8a9c97aa\n",
      "a2ababab\n",
      "aa918683\n",
      "85a7a2ab\n",
      "aba4938b\n",
      "83848688\n",
      "9d928f8b\n",
      "89878582\n",
      "8383a29d\n",
      "8c85858c\n",
      "9683848a\n",
      "a2ababab\n",
      "abababab\n",
      "abaaa0a8\n",
      "a8a8a8a8\n",
      "a8a8a8a7\n",
      "bdc5c5c5\n",
      "c5c5c5c5\n",
      "c5bbc7dc\n",
      "dcdcdcdc\n",
      "dcdcdcc8\n",
      "c7dcdcdc\n",
      "dcdcdcdc\n",
      "dcc8c7dc\n",
      "dcdcdcde\n",
      "e1dfe1c8\n",
      "c7dcdcdc\n",
      "dde1e4e5\n",
      "e4c8c7dc\n",
      "dcdee1e3\n",
      "e4e4e4cb\n",
      "c8e0e1e2\n",
      "e2e3e4e5\n",
      "e5ccc7e0\n",
      "e2e2e2e1\n",
      "e0e3e3ca\n",
      "c7dcdcdc\n",
      "dcdcdcdc\n",
      "dcc8b9c7\n",
      "c7c7c7c7\n",
      "c7c7c7bb\n"
     ]
    }
   ],
   "source": [
    "golden_gen(q_output_activation[\"Conv.6\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
