{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHXk_L8g3fDh"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVH9mlCdXrkw"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import math\n",
        "import random\n",
        "from collections import OrderedDict, defaultdict\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import *\n",
        "from torch.optim.lr_scheduler import *\n",
        "import torchvision.models as models\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.datasets import *\n",
        "from torchvision.transforms import *\n",
        "\n",
        "\n",
        "no_cuda = False\n",
        "use_gpu = not no_cuda and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_gpu else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _make_divisible(v, divisor, min_value=None):\n",
        "    \"\"\"\n",
        "    This function is taken from the original tf repo.\n",
        "    It ensures that all layers have a channel number that is divisible by 8\n",
        "    It can be seen here:\n",
        "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
        "    :param v:\n",
        "    :param divisor:\n",
        "    :param min_value:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if min_value is None:\n",
        "        min_value = divisor\n",
        "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "    # Make sure that round down does not go down by more than 10%.\n",
        "    if new_v < 0.9 * v:\n",
        "        new_v += divisor\n",
        "    return new_v\n",
        "\n",
        "class h_sigmoid(nn.Module):\n",
        "    def __init__(self, inplace=True):\n",
        "        super(h_sigmoid, self).__init__()\n",
        "        self.relu = nn.ReLU6(inplace=inplace)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.relu(x + 3) / 6\n",
        "\n",
        "\n",
        "class h_swish(nn.Module):\n",
        "    def __init__(self, inplace=True):\n",
        "        super(h_swish, self).__init__()\n",
        "        self.sigmoid = h_sigmoid(inplace=inplace)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * self.sigmoid(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class SELayer(nn.Module):\n",
        "    def __init__(self, channel, reduction=4):\n",
        "        super(SELayer, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "                nn.Linear(channel, _make_divisible(channel // reduction, 8),bias=False),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(_make_divisible(channel // reduction, 8), channel,bias=False),\n",
        "                nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk1U6PcMXtDB",
        "outputId": "58b165e2-e66b-41c5-987d-4fcc1b6a26fa"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "#Dataset\n",
        "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "#Dataloader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzMtMm9n3hsZ"
      },
      "source": [
        "Create NN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-pKE7xJbOc7",
        "outputId": "fce122fd-5aa8-4d0c-fe2c-94bb60cc64ea"
      },
      "outputs": [],
      "source": [
        "class ToyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.Conv = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=1, out_channels=5, kernel_size=1, stride=1,padding= 0, bias=True),\n",
        "      h_swish(inplace=True),\n",
        "      SELayer(5),\n",
        "      nn.Conv2d(in_channels=5, out_channels=1, kernel_size=1, stride=1,padding= 0, bias=True),\n",
        "      h_swish(inplace=True)\n",
        "    )  \n",
        "    self.backbone = nn.Sequential(\n",
        "      nn.Linear(28*28, 120, bias=False),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(120, 84, bias=False),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(84, 10, bias=False)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x=self.Conv(x)\n",
        "    x = x.view(-1, 28 * 28) #transform 28*28 figure to 784 vector\n",
        "    x = self.backbone(x)\n",
        "    return x\n",
        "\n",
        "FP32_model = ToyModel()\n",
        "print(FP32_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOyeqSPDbvr5"
      },
      "outputs": [],
      "source": [
        "#train model\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  #Set the model to train mode\n",
        "  model.train()\n",
        "  for batch, (x, y) in enumerate(dataloader):\n",
        "    if use_gpu:\n",
        "      x, y = x.cuda(), y.cuda()\n",
        "    optimizer.zero_grad()\n",
        "    #forward\n",
        "    pred = model(x)\n",
        "\n",
        "    #loss\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    #backward\n",
        "    loss.backward()\n",
        "\n",
        "    #optimize\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), (batch + 1) * len(x)\n",
        "      print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "  #set model to evaluate mode\n",
        "  model.eval()\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for x, y in dataloader:\n",
        "      if use_gpu:\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "      pred = model(x)\n",
        "      test_loss = loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item() #calculate accuracy\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LsfzIw4b1AU",
        "outputId": "03aeb700-d0fe-4e88-a24e-d000b63c4184"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "epochs = 3\n",
        "loss_fn = nn.CrossEntropyLoss() #define loss function\n",
        "optimizer = torch.optim.Adam(FP32_model.parameters(), lr=learning_rate)  #define optimizer\n",
        "\n",
        "FP32_model.to(device) #let model on GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "LH6kt0eqb9tl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 0.605188  [16032/60000]\n",
            "loss: 0.421754  [19232/60000]\n",
            "loss: 0.624769  [22432/60000]\n",
            "loss: 0.629864  [25632/60000]\n",
            "loss: 0.310080  [28832/60000]\n",
            "loss: 0.612952  [32032/60000]\n",
            "loss: 0.396862  [35232/60000]\n",
            "loss: 0.431447  [38432/60000]\n",
            "loss: 0.557648  [41632/60000]\n",
            "loss: 0.559689  [44832/60000]\n",
            "loss: 0.265188  [48032/60000]\n",
            "loss: 0.728065  [51232/60000]\n",
            "loss: 0.551859  [54432/60000]\n",
            "loss: 0.174155  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.4%, Avg loss: 0.000908 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.187655  [   32/60000]\n",
            "loss: 0.264462  [ 3232/60000]\n",
            "loss: 0.344568  [ 6432/60000]\n",
            "loss: 0.388792  [ 9632/60000]\n",
            "loss: 0.465516  [12832/60000]\n",
            "loss: 0.222715  [16032/60000]\n",
            "loss: 0.306143  [19232/60000]\n",
            "loss: 0.681011  [22432/60000]\n",
            "loss: 0.362475  [25632/60000]\n",
            "loss: 0.335350  [28832/60000]\n",
            "loss: 0.378258  [32032/60000]\n",
            "loss: 0.502297  [35232/60000]\n",
            "loss: 0.453380  [38432/60000]\n",
            "loss: 0.406592  [41632/60000]\n",
            "loss: 0.154795  [44832/60000]\n",
            "loss: 0.325632  [48032/60000]\n",
            "loss: 0.203416  [51232/60000]\n",
            "loss: 0.242830  [54432/60000]\n",
            "loss: 0.502773  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.8%, Avg loss: 0.000552 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.274349  [   32/60000]\n",
            "loss: 0.432891  [ 3232/60000]\n",
            "loss: 0.257630  [ 6432/60000]\n",
            "loss: 0.388826  [ 9632/60000]\n",
            "loss: 0.364951  [12832/60000]\n",
            "loss: 0.363534  [16032/60000]\n",
            "loss: 0.262571  [19232/60000]\n",
            "loss: 0.360470  [22432/60000]\n",
            "loss: 0.334380  [25632/60000]\n",
            "loss: 0.209868  [28832/60000]\n",
            "loss: 0.361830  [32032/60000]\n",
            "loss: 0.337530  [35232/60000]\n",
            "loss: 0.157982  [38432/60000]\n",
            "loss: 0.230690  [41632/60000]\n",
            "loss: 0.422096  [44832/60000]\n",
            "loss: 0.359624  [48032/60000]\n",
            "loss: 0.238293  [51232/60000]\n",
            "loss: 0.305462  [54432/60000]\n",
            "loss: 0.160996  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.0%, Avg loss: 0.000476 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Training\n",
        "for i in range(epochs):\n",
        "  print(f\"Epoch {i+1}\\n-------------------------------\")\n",
        "  train_loop(train_loader, FP32_model, loss_fn, optimizer)\n",
        "  test_loop(test_loader, FP32_model, loss_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTAK3-fH3qGh"
      },
      "source": [
        "# Quantization definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lWzxrde4G5i"
      },
      "source": [
        "####Question 1.####\n",
        "\n",
        "Use\n",
        ">$S=(r_{\\mathrm{max}} - r_{\\mathrm{min}}) / (q_{\\mathrm{max}} - q_{\\mathrm{min}})$\n",
        "\n",
        ">$Z = q_{\\mathrm{min}} - r_{\\mathrm{min}} / S$\n",
        "\n",
        "to calculate scale factor and zero point of a tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "kJIr-5SpcgQr"
      },
      "outputs": [],
      "source": [
        "def get_scale_and_zero_point(fp32_tensor, bitwidth=8):\n",
        "  q_min, q_max = -(2**(bitwidth-1)-1), 2**(bitwidth-1) - 1\n",
        "  fp_min = fp32_tensor.min().item()\n",
        "  fp_max = fp32_tensor.max().item()\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "  scale = (fp_max-fp_min) / (q_max-q_min)\n",
        "  zero_point = q_min-fp_min /scale\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "\n",
        "  zero_point = round(zero_point)          #round\n",
        "  zero_point = max(q_min, min(zero_point, q_max)) #clip\n",
        "\n",
        "  return scale, int(zero_point)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4YA7ano5nS1"
      },
      "source": [
        "####Question 2.####\n",
        "\n",
        "Use $q=r/S + Z$ to quantize a tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "sBMKB5Le54wr"
      },
      "outputs": [],
      "source": [
        "def linear_quantize(fp32_tensor, bitwidth=8):\n",
        "  q_min, q_max = -(2**(bitwidth-1)-1), 2**(bitwidth-1) - 1\n",
        "\n",
        "  scale, zero_point = get_scale_and_zero_point(fp32_tensor)\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "  q_tensor = torch.round( fp32_tensor/scale ) +zero_point\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "  #clamp\n",
        "  q_tensor = torch.clamp(q_tensor, q_min, q_max)\n",
        "  return q_tensor, scale, zero_point  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0taJXSmz6KDS"
      },
      "source": [
        "####Question 3.####\n",
        "\n",
        "Use\n",
        "> $q_{\\mathrm{output}} = M * \\mathrm{Linear}[q_{\\mathrm{input}}, q_{\\mathrm{weight}}] + Z_{\\mathrm{output}}$\n",
        "\n",
        "> $M = S_{\\mathrm{input}} * S_{\\mathrm{weight}} / S_{\\mathrm{output}}$\n",
        "\n",
        "to compute quantized linear operation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "sbXY0vaCcn7l"
      },
      "outputs": [],
      "source": [
        "def quantized_linear(input, weights, input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point, device, bitwidth=8, activation_bitwidth=8):\n",
        "  input, weights = input.to(device), weights.to(device)\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "  M = input_scale * weight_scale / output_scale\n",
        "  output = torch.nn.functional.linear((input - input_zero_point ), (weights - weight_zero_point))\n",
        "  output *= M\n",
        "  output += output_zero_point\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "  #clamp and round\n",
        "  output = output.round().clamp(-(2**(activation_bitwidth-1)-1), 2**(activation_bitwidth-1)-1)\n",
        "\n",
        "  return output\n",
        "\n",
        "def quantized_conv(input, bias,weights,stride, padding,groups,input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point, device, bitwidth=8, activation_bitwidth=16):\n",
        "  input, weights = input.to(device), weights.to(device)\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "  M = input_scale * weight_scale \n",
        "  conv_bias = bias /M\n",
        "  conv_bias = conv_bias.round()\n",
        "  output_only_conv = torch.nn.functional.conv2d((input - input_zero_point ), (weights - weight_zero_point),bias = conv_bias ,stride=stride,padding=padding,groups=groups)\n",
        "  output = M * output_only_conv\n",
        "  #output += output_zero_point\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "  #clamp and round\n",
        "  output = output.round().clamp(-(2**(activation_bitwidth-1)-1), 2**(activation_bitwidth-1)-1)\n",
        "\n",
        "  return output\n",
        "\n",
        "def do_requant(input, scale,zero_point,bitwidth=8):\n",
        "    output = input / scale\n",
        "    output = output.round()\n",
        "    output += zero_point\n",
        "    output = output.clamp(-(2**(bitwidth-1)-1), 2**(bitwidth-1)-1)\n",
        "    return output\n",
        "\n",
        "def do_fake_quant(input, deq_scale, q_scale, q_zero_point,bitwidth=8):\n",
        "    M = deq_scale/q_scale\n",
        "    N = q_zero_point\n",
        "    output = input * M\n",
        "    output += N\n",
        "    output = output.round().clamp(-(2**(bitwidth-1)-1), 2**(bitwidth-1)-1)\n",
        "    return output\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vK10k10R7II7"
      },
      "source": [
        "# Design quantized linear layer and preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "IwrXNVKadKfG"
      },
      "outputs": [],
      "source": [
        "class Q_SELayer(nn.Module):\n",
        "  def __init__(self,weights1,input_scale1,weight_scale1,output_scale1, input_zero_point1, weight_zero_point1, output_zero_point1,\n",
        "               weights2, input_scale2, weight_scale2, output_scale2, input_zero_point2, weight_zero_point2, output_zero_point2,\n",
        "               in_pool_scale,in_pool_zero_point,\n",
        "               SE_req_q_scale,SE_req_q_output_zero_point,\n",
        "               SE_req_dq_scale , SE_req_dq_output_zero_point):\n",
        "    super().__init__()\n",
        "    self.weights1 = weights1\n",
        "    self.input_scale1 = input_scale1\n",
        "    self.weight_scale1 = weight_scale1\n",
        "    self.output_scale1 = output_scale1\n",
        "    self.input_zero_point1 = input_zero_point1\n",
        "    self.weight_zero_point1 = weight_zero_point1\n",
        "    self.output_zero_point1 = output_zero_point1\n",
        "\n",
        "    self.weights2 = weights2\n",
        "    self.input_scale2 = input_scale2\n",
        "    self.weight_scale2 = weight_scale2\n",
        "    self.output_scale2 = output_scale2\n",
        "    self.input_zero_point2 = input_zero_point2\n",
        "    self.weight_zero_point2 = weight_zero_point2\n",
        "    self.output_zero_point2 = output_zero_point2\n",
        "\n",
        "    self.SE_req_dq_scale , self.SE_req_dq_output_zero_point = SE_req_dq_scale , SE_req_dq_output_zero_point\n",
        "\n",
        "    self.SE_req_q_scale = SE_req_q_scale\n",
        "    self.SE_req_q_output_zero_point = SE_req_q_output_zero_point\n",
        "\n",
        "    self.in_pool_scale = in_pool_scale\n",
        "    self.in_pool_zero_point = in_pool_zero_point\n",
        "\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    b, c, _, _ = x.size()\n",
        "    y = self.avg_pool(x).view(b, c)\n",
        "    y = (y-self.in_pool_zero_point) \n",
        "    y = do_fake_quant(y, self.in_pool_scale, self.input_scale1,self.input_zero_point1,bitwidth=8)\n",
        "    y = quantized_linear(y, self.weights1, self.input_scale1, self.weight_scale1, self.output_scale1, self.input_zero_point1, self.weight_zero_point1, self.output_zero_point1, device)\n",
        "    y = quantized_linear(y, self.weights2, self.input_scale2, self.weight_scale2, self.output_scale2, self.input_zero_point2, self.weight_zero_point2, self.output_zero_point2, device).view(b,c,1,1)\n",
        "    z = (x-self.SE_req_dq_output_zero_point)*(y-self.output_zero_point2)\n",
        "    return do_fake_quant(z, deq_scale=(self.SE_req_dq_scale *self.output_scale2), \n",
        "                         q_scale=self.SE_req_q_scale, q_zero_point=self.SE_req_q_output_zero_point,bitwidth=8)\n",
        "  \n",
        "  def __repr__(self):\n",
        "    return f\"Quantized_SE(in_channels={self.weights1.size(1)}, out_channels={self.weights2.size(0)})\"\n",
        "    \n",
        "\n",
        "\n",
        "class QuantizedConv(nn.Module):\n",
        "  def __init__(self,bias ,weights,stride,padding,groups ,input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point, bitwidth=8, activation_bitwidth=8):\n",
        "    super().__init__()\n",
        "    self.stride, self.padding, self.groups = stride, padding,groups\n",
        "    self.weights = weights\n",
        "    self.input_scale, self.input_zero_point = input_scale, input_zero_point\n",
        "    self.weight_scale, self.weight_zero_point = weight_scale, weight_zero_point\n",
        "    self.output_scale, self.output_zero_point = output_scale, output_zero_point\n",
        "    self.bias = bias\n",
        "    self.bitwidth = bitwidth\n",
        "    self.activation_bitwidth = activation_bitwidth\n",
        "    self.q_bias = torch.round(bias / (input_scale*weight_scale))\n",
        "    self.q_weight = weights - weight_zero_point\n",
        "    self.DeQ_scale = input_scale*weight_scale*8192\n",
        "  def forward(self, x):\n",
        "    return quantized_conv(x, self.bias, self.weights, self.stride, self.padding, self.groups, self.input_scale, self.weight_scale, self.output_scale, self.input_zero_point, self.weight_zero_point, self.output_zero_point, device)\n",
        "  def __repr__(self):\n",
        "    return f\"QuantizedConv(in_channels={self.weights.size(1)}, out_channels={self.weights.size(0)})\"\n",
        "\n",
        "class QuantizedLinear(nn.Module):\n",
        "  def __init__(self, weights, input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point, bitwidth=8, activation_bitwidth=8):\n",
        "    super().__init__()\n",
        "    self.weights = weights\n",
        "    self.input_scale, self.input_zero_point = input_scale, input_zero_point\n",
        "    self.weight_scale, self.weight_zero_point = weight_scale, weight_zero_point\n",
        "    self.output_scale, self.output_zero_point = output_scale, output_zero_point\n",
        "\n",
        "    self.bitwidth = bitwidth\n",
        "    self.activation_bitwidth = activation_bitwidth\n",
        "\n",
        "  def forward(self, x):\n",
        "    return quantized_linear(x, self.weights, self.input_scale, self.weight_scale, self.output_scale, self.input_zero_point, self.weight_zero_point, self.output_zero_point, device)\n",
        "  def __repr__(self):\n",
        "    return f\"QuantizedLinear(in_channels={self.weights.size(1)}, out_channels={self.weights.size(0)})\"\n",
        "\n",
        "#Transform input data to correct integer range\n",
        "class Preprocess(nn.Module):\n",
        "  def __init__(self, input_scale, input_zero_point, activation_bitwidth=8):\n",
        "    super().__init__()\n",
        "    self.input_scale, self.input_zero_point = input_scale, input_zero_point\n",
        "    self.activation_bitwidth = activation_bitwidth\n",
        "  def forward(self, x):\n",
        "    x = x / self.input_scale + self.input_zero_point\n",
        "    x = x.round() \n",
        "    return x\n",
        "  \n",
        "class Quantizer(nn.Module):\n",
        "  def __init__(self,scale,zero_point,bitwidth=8):\n",
        "    super().__init__()\n",
        "    self.scale = scale\n",
        "    self.zero = zero_point\n",
        "    self.store_scale = scale *64\n",
        "\n",
        "  def forward(self,x):\n",
        "    return do_requant(x,self.scale,self.zero)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUpiPDiu7RCH"
      },
      "source": [
        "# Calibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "cBdXFnr5dZqT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['Conv.0', 'Conv.1', 'Conv.2.avg_pool', 'Conv.2.fc.0', 'Conv.2.fc.1', 'Conv.2.fc.2', 'Conv.2.fc.3', 'Conv.3', 'Conv.4', 'backbone.0', 'backbone.1', 'backbone.2', 'backbone.3', 'backbone.4'])\n"
          ]
        }
      ],
      "source": [
        "# add hook to record the min max value of the activation\n",
        "input_activation = {}\n",
        "output_activation = {}\n",
        "\n",
        "#Define a hook to record the feature map of each layer\n",
        "def add_range_recoder_hook(model):\n",
        "    import functools\n",
        "    def _record_range(self, x, y, module_name):\n",
        "        x = x[0]\n",
        "        input_activation[module_name] = x.detach()\n",
        "        output_activation[module_name] = y.detach()\n",
        "\n",
        "    all_hooks = []\n",
        "    for name, m in model.named_modules():\n",
        "        if isinstance(m, (nn.Linear, nn.ReLU,nn.Conv2d,h_swish,nn.AdaptiveAvgPool2d)):\n",
        "            all_hooks.append(m.register_forward_hook(\n",
        "                functools.partial(_record_range, module_name=name)))\n",
        "\n",
        "\n",
        "    return all_hooks\n",
        "\n",
        "hooks = add_range_recoder_hook(FP32_model)\n",
        "sample_data = iter(train_loader).__next__()[0].to(device) #Use a batch of training data to calibrate\n",
        "FP32_model(sample_data) #Forward to use hook\n",
        "# print(output_activation['Conv.1'])\n",
        "# print(\"==\")\n",
        "# print(input_activation['Conv.2.avg_pool'])\n",
        "print(output_activation.keys())\n",
        "# remove hooks\n",
        "for h in hooks:\n",
        "    h.remove()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVf8vpiVTsDa"
      },
      "source": [
        "# Quantize model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "SVh-SRj8eOrs"
      },
      "outputs": [],
      "source": [
        "#copy original model\n",
        "quantized_model = copy.deepcopy(FP32_model)\n",
        "\n",
        "#Record each layer in original model\n",
        "quantized_backbone = []\n",
        "quantized_Conv = []\n",
        "i = 0\n",
        "\n",
        "#Record input scale and zero point\n",
        "input_scale, input_zero_point = get_scale_and_zero_point(input_activation[\"Conv.0\"])\n",
        "preprocess = Preprocess(input_scale, input_zero_point)\n",
        "quantized_Conv.append(preprocess)\n",
        "\n",
        "input_scale, input_zero_point = get_scale_and_zero_point(input_activation['Conv.0'])\n",
        "output_scale, output_zero_point = get_scale_and_zero_point(output_activation['Conv.0'])\n",
        "quantized_weights, weight_scale, weight_zero_point = linear_quantize(FP32_model.Conv[0].weight.data)\n",
        "Conv_bias = FP32_model.Conv[0].bias.data\n",
        "quantizedConv1 = QuantizedConv(Conv_bias,quantized_weights, 1,0,1,input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point)\n",
        "h_swish1 = h_swish()\n",
        "#quantized_model.Conv[0] = quantizedConv1 \n",
        "\n",
        "req_scale , output_zero_point = get_scale_and_zero_point(output_activation['Conv.1'])\n",
        "req1 = Quantizer(req_scale,output_zero_point)\n",
        "\n",
        "quantized_Conv.append(quantizedConv1)\n",
        "quantized_Conv.append(h_swish1)\n",
        "quantized_Conv.append(req1)\n",
        "###############\n",
        "input_scale1, input_zero_point1 = get_scale_and_zero_point(input_activation['Conv.2.fc.0'])\n",
        "output_scale1, output_zero_point1 = get_scale_and_zero_point(output_activation['Conv.2.fc.1'])\n",
        "quantized_weights1, weight_scale1, weight_zero_point1 = linear_quantize(FP32_model.Conv[2].fc[0].weight.data)\n",
        "\n",
        "input_scale2, input_zero_point2 = get_scale_and_zero_point(input_activation['Conv.2.fc.2'])\n",
        "output_scale2, output_zero_point2 = get_scale_and_zero_point(output_activation['Conv.2.fc.3'])\n",
        "quantized_weights2, weight_scale2, weight_zero_point2 = linear_quantize(FP32_model.Conv[2].fc[2].weight.data)\n",
        "\n",
        "SE_in_pool_scale, SE_in_pool_zero_point = get_scale_and_zero_point(input_activation['Conv.2.avg_pool'])\n",
        "\n",
        "SE_req_q_scale , SE_req_q_output_zero_point = get_scale_and_zero_point(input_activation['Conv.3'])\n",
        "\n",
        "SE_req_dq_scale , SE_req_dq_output_zero_point = get_scale_and_zero_point(output_activation['Conv.1'])\n",
        "\n",
        "quantizedSE_linear1 =Q_SELayer(quantized_weights1,input_scale1,weight_scale1,output_scale1,input_zero_point1,weight_zero_point1,output_zero_point1, \n",
        "                               quantized_weights2,input_scale2,weight_scale2,output_scale2,input_zero_point2,weight_zero_point2,output_zero_point2,\n",
        "                               SE_in_pool_scale, SE_in_pool_zero_point,\n",
        "                               SE_req_q_scale,SE_req_q_output_zero_point,\n",
        "                               SE_req_dq_scale , SE_req_dq_output_zero_point)\n",
        "##################\n",
        "quantized_Conv.append(quantizedSE_linear1)\n",
        "\n",
        "\n",
        "input_scale, input_zero_point = get_scale_and_zero_point(input_activation['Conv.3'])\n",
        "output_scale, output_zero_point = get_scale_and_zero_point(output_activation['Conv.3'])\n",
        "quantized_weights, weight_scale, weight_zero_point = linear_quantize(FP32_model.Conv[3].weight.data)\n",
        "Conv_bias = FP32_model.Conv[3].bias.data\n",
        "quantizedConv2 = QuantizedConv(Conv_bias,quantized_weights, 1,0,1,input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point)\n",
        "#quantized_model.Conv[2] = quantizedConv2 \n",
        "\n",
        "h_swish2 = h_swish()\n",
        "#quantized_model.Conv[0] = quantizedConv1 \n",
        "\n",
        "req_scale , output_zero_point = get_scale_and_zero_point(output_activation['Conv.4'])\n",
        "req2 = Quantizer(req_scale,output_zero_point)\n",
        "\n",
        "quantized_Conv.append(quantizedConv2)\n",
        "quantized_Conv.append(h_swish2)\n",
        "quantized_Conv.append(req2)\n",
        "\n",
        "\n",
        "################# below is linear\n",
        "\n",
        "input_scale, input_zero_point = get_scale_and_zero_point(input_activation['backbone.0'])\n",
        "output_scale, output_zero_point = get_scale_and_zero_point(output_activation['backbone.1'])\n",
        "quantized_weights, weight_scale, weight_zero_point = linear_quantize(FP32_model.backbone[0].weight.data)\n",
        "quantizedLinear1 = QuantizedLinear(quantized_weights, input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point)\n",
        "quantized_backbone.append(quantizedLinear1)\n",
        "\n",
        "input_scale, input_zero_point = get_scale_and_zero_point(input_activation['backbone.2'])\n",
        "output_scale, output_zero_point = get_scale_and_zero_point(output_activation['backbone.3'])\n",
        "quantized_weights, weight_scale, weight_zero_point = linear_quantize(FP32_model.backbone[2].weight.data)\n",
        "quantizedLinear2 = QuantizedLinear(quantized_weights, input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point)\n",
        "quantized_backbone.append(quantizedLinear2)\n",
        "\n",
        "# #Record Linear + ReLU of the model (except the last Linear)\n",
        "# while i < len(quantized_model.backbone) - 1:\n",
        "#   if isinstance(quantized_model.backbone[i], nn.Linear) and isinstance(quantized_model.backbone[i+1], nn.ReLU):\n",
        "#     linear = quantized_model.backbone[i]\n",
        "#     linear_name = f\"backbone.{i}\"\n",
        "#     relu = quantized_model.backbone[i + 1]\n",
        "#     relu_name = f\"backbone.{i + 1}\"\n",
        "\n",
        "#     #Use the calibration data to calculate scale and zero point of each layer\n",
        "#     input_scale, input_zero_point = get_scale_and_zero_point(input_activation[linear_name])\n",
        "#     output_scale, output_zero_point = get_scale_and_zero_point(output_activation[relu_name])\n",
        "#     quantized_weights, weight_scale, weight_zero_point = linear_quantize(linear.weight.data)\n",
        "\n",
        "#     quantizedLinear = QuantizedLinear(quantized_weights, input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point)\n",
        "\n",
        "#     quantized_backbone.append(quantizedLinear)\n",
        "#     i += 2\n",
        "\n",
        "#Record the last Linear layer\n",
        "linear = quantized_model.backbone[4]\n",
        "linear_name = f\"backbone.4\"\n",
        "input_scale, input_zero_point = get_scale_and_zero_point(input_activation[linear_name])\n",
        "output_scale, output_zero_point = get_scale_and_zero_point(output_activation[linear_name])\n",
        "quantized_weights, weight_scale, weight_zero_point = linear_quantize(linear.weight.data)\n",
        "quantizedLinear3 = QuantizedLinear(quantized_weights, input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point)\n",
        "quantized_backbone.append(quantizedLinear3)\n",
        "\n",
        "quantized_model.Conv = nn.Sequential(*quantized_Conv)\n",
        "quantized_model.backbone = nn.Sequential(*quantized_backbone)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRB96PKbfNX4",
        "outputId": "58ce882a-3521-4b40-ff98-44dcea373546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ToyModel(\n",
            "  (Conv): Sequential(\n",
            "    (0): Preprocess()\n",
            "    (1): QuantizedConv(in_channels=1, out_channels=5)\n",
            "    (2): h_swish(\n",
            "      (sigmoid): h_sigmoid(\n",
            "        (relu): ReLU6(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (3): Quantizer()\n",
            "    (4): Quantized_SE(in_channels=5, out_channels=5)\n",
            "    (5): QuantizedConv(in_channels=5, out_channels=1)\n",
            "    (6): h_swish(\n",
            "      (sigmoid): h_sigmoid(\n",
            "        (relu): ReLU6(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (7): Quantizer()\n",
            "  )\n",
            "  (backbone): Sequential(\n",
            "    (0): QuantizedLinear(in_channels=784, out_channels=120)\n",
            "    (1): QuantizedLinear(in_channels=120, out_channels=84)\n",
            "    (2): QuantizedLinear(in_channels=84, out_channels=10)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(quantized_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['Conv.0', 'Conv.1', 'Conv.2', 'Conv.3', 'Conv.4', 'Conv.5', 'Conv.6', 'Conv.7', 'backbone.0', 'backbone.1', 'backbone.2'])\n",
            "tensor([[ -78.,   40.,  -74.,   43.,  -75.,  -61.,   36., -113.],\n",
            "        [  10.,   -3.,  -71., -127.,   85.,   12.,   -4.,  -69.],\n",
            "        [ 114.,  -19.,   53.,  102.,  127.,  -25.,  -69.,  105.],\n",
            "        [-103.,   51.,    0.,   51., -111., -113.,  -62.,  -70.],\n",
            "        [  70.,    9.,   16.,   42.,   51.,   59.,  -51.,  101.]],\n",
            "       device='cuda:0')\n",
            "tensor([[[[-81., -81., -81.,  ..., -81., -81., -81.],\n",
            "          [-81., -81., -81.,  ..., -81., -81., -81.],\n",
            "          [-81., -81., -81.,  ..., -81., -81., -81.],\n",
            "          ...,\n",
            "          [-81., -81., -81.,  ..., -81., -81., -81.],\n",
            "          [-81., -81., -81.,  ..., -81., -81., -81.],\n",
            "          [-81., -81., -81.,  ..., -81., -81., -81.]],\n",
            "\n",
            "         [[-98., -98., -98.,  ..., -98., -98., -98.],\n",
            "          [-98., -98., -98.,  ..., -98., -98., -98.],\n",
            "          [-98., -98., -98.,  ..., -98., -98., -98.],\n",
            "          ...,\n",
            "          [-98., -98., -98.,  ..., -98., -98., -98.],\n",
            "          [-98., -98., -98.,  ..., -98., -98., -98.],\n",
            "          [-98., -98., -98.,  ..., -98., -98., -98.]],\n",
            "\n",
            "         [[ 66.,  66.,  66.,  ...,  66.,  66.,  66.],\n",
            "          [ 66.,  66.,  66.,  ...,  66.,  66.,  66.],\n",
            "          [ 66.,  66.,  66.,  ...,  66.,  66.,  66.],\n",
            "          ...,\n",
            "          [ 66.,  66.,  66.,  ...,  66.,  66.,  66.],\n",
            "          [ 66.,  66.,  66.,  ...,  66.,  66.,  66.],\n",
            "          [ 66.,  66.,  66.,  ...,  66.,  66.,  66.]],\n",
            "\n",
            "         [[-81., -81., -81.,  ..., -81., -81., -81.],\n",
            "          [-81., -81., -81.,  ..., -81., -81., -81.],\n",
            "          [-81., -81., -81.,  ..., -81., -81., -81.],\n",
            "          ...,\n",
            "          [-81., -81., -81.,  ..., -81., -81., -81.],\n",
            "          [-81., -81., -81.,  ..., -81., -81., -81.],\n",
            "          [-81., -81., -81.,  ..., -81., -81., -81.]],\n",
            "\n",
            "         [[ 47.,  47.,  47.,  ...,  47.,  47.,  47.],\n",
            "          [ 47.,  47.,  47.,  ...,  47.,  47.,  47.],\n",
            "          [ 47.,  47.,  47.,  ...,  47.,  47.,  47.],\n",
            "          ...,\n",
            "          [ 47.,  47.,  47.,  ...,  47.,  47.,  47.],\n",
            "          [ 47.,  47.,  47.,  ...,  47.,  47.,  47.],\n",
            "          [ 47.,  47.,  47.,  ...,  47.,  47.,  47.]]]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# add hook to record the min max value of the activation\n",
        "q_input_activation = {}\n",
        "q_output_activation = {}\n",
        "\n",
        "#Define a hook to record the feature map of each layer\n",
        "def add_range_recoder_hook(model):\n",
        "    import functools\n",
        "    def _record_range(self, x, y, module_name):\n",
        "        x = x[0]\n",
        "        q_input_activation[module_name] = x.detach()\n",
        "        q_output_activation[module_name] = y.detach()\n",
        "\n",
        "    all_hooks = []\n",
        "    for name, m in model.named_modules():\n",
        "        if isinstance(m, (QuantizedConv,  QuantizedLinear,h_swish,Quantizer,Preprocess,Q_SELayer)):\n",
        "            all_hooks.append(m.register_forward_hook(\n",
        "                functools.partial(_record_range, module_name=name)))\n",
        "\n",
        "\n",
        "    return all_hooks\n",
        "\n",
        "\n",
        "q_test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
        "hooks = add_range_recoder_hook(quantized_model)\n",
        "sample_data = iter(q_test_loader).__next__()[0].to(device) #Use a batch of training data to calibrate\n",
        "quantized_model(sample_data) #Forward to use hook\n",
        "\n",
        "print(q_output_activation.keys())\n",
        "#print(q_intput_activation.keys())\n",
        "print(quantized_model.Conv[4].weights2)\n",
        "print(q_output_activation[\"Conv.4\"])\n",
        "# remove hooks\n",
        "for h in hooks:\n",
        "    h.remove()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1, 28, 28])\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n",
            "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# print(q_input_activation[\"Conv.0\"].shape)\n",
        "print(q_input_activation[\"Conv.1\"].shape)\n",
        "# print(q_input_activation[\"Conv.2\"].shape)\n",
        "\n",
        "for i in range(28):\n",
        "    print(q_output_activation[\"Conv.1\"][0][0][0])\n",
        "#print(q_input_activation[\"Conv.1\"][0][0][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "00\n",
            "byte0: 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 82 81 81 81 81 81 9c 81 81 81 81 81 81 d9 81 de 81 81 81 81 01 1d 28 81 81 81 83 02 1f 17 81 81 83 81 eb 1c 1d 81 82 81 81 df 17 1f 81 81 82 e3 ef 15 1e 81 82 81 f6 08 1a 13 84 81 b6 e8 0f 1a 0a 81 c2 00 f7 05 1b 2c 81 f0 f4 0f 1a 22 19 c7 e3 e3 f8 1c 44 45 91 3c 07 12 50 75 77 81 c4 47 50 89 32 22 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81\n",
            "=======\n",
            "byte1: 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 a6 81 81 81 82 d5 81 f8 81 81 81 82 0f 81 eb 81 81 81 85 f9 26 0c 81 81 81 81 00 27 10 81 81 82 81 09 25 1e 81 81 81 da 19 29 29 81 81 81 08 22 1f 29 81 83 81 e4 1c 1c 1c 81 81 dd f4 1a 17 16 81 cd fc 00 08 21 21 c5 f3 00 ff 0f 22 22 29 e5 e7 f9 27 46 3d ff 38 f9 39 7f 7c 5c 81 eb 52 3e 81 50 1e 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81\n",
            "=======\n",
            "byte2: 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 83 8c 81 81 81 81 81 81 ef 81 81 81 81 81 81 13 07 81 81 81 81 8c 20 32 81 81 82 81 f4 28 27 8c 81 81 84 0b 15 2c b1 81 83 81 ef 07 27 f8 83 81 9b f0 06 20 32 81 81 f6 01 25 1a 25 98 d6 f0 fe 20 10 3d df f0 07 00 14 10 44 01 df ed 01 3e 46 38 2b 2b ff 43 51 7b 4e 81 24 53 16 81 3c 17 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81\n",
            "=======\n",
            "byte3: 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 84 88 81 81 81 81 81 81 81 81 81 81 81 81 81 97 81 81 81 81 b6 2f 1a 81 81 81 81 09 30 15 81 81 81 84 f3 19 0f 81 81 81 81 db 03 0f 81 81 85 81 ee 10 10 81 83 81 ed f6 1a 0d 81 81 96 f0 06 2a 0f ac b7 f7 f2 0b 0c 1b bf db f3 08 17 fe 0a bb e9 e2 eb 15 3e 3b a5 3c 19 00 51 31 7b b2 8d 39 52 d3 81 2f 8c 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81\n",
            "=======\n",
            "===\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'Q_SELayer' object has no attribute 'weights'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[97], line 92\u001b[0m\n\u001b[0;32m     90\u001b[0m input_or_weight_gen(q_input_activation[\u001b[39m\"\u001b[39m\u001b[39mConv.1\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     91\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m===\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 92\u001b[0m input_or_weight_gen(quantized_model\u001b[39m.\u001b[39;49mConv[\u001b[39m4\u001b[39;49m]\u001b[39m.\u001b[39;49mweights)\n\u001b[0;32m     94\u001b[0m \u001b[39mprint\u001b[39m(quantized_model\u001b[39m.\u001b[39mConv[\u001b[39m4\u001b[39m]\u001b[39m.\u001b[39minput_zero_point)\n\u001b[0;32m     96\u001b[0m DeS \u001b[39m=\u001b[39m quantized_model\u001b[39m.\u001b[39mConv[\u001b[39m3\u001b[39m]\u001b[39m.\u001b[39mstore_scale\n",
            "File \u001b[1;32mc:\\Users\\胡家豪\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1693\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m   1694\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1695\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'Q_SELayer' object has no attribute 'weights'"
          ]
        }
      ],
      "source": [
        "def signed_dec2hex_matrix(input):\n",
        "    '''Convert a matrix which data is signed decimal to 8 bits hex with 2's complement'''\n",
        "    temp = []\n",
        "    bin8 = lambda x : ''.join(reversed( [str((x >> i) & 1) for i in range(8)] ) )\n",
        "    for i in input:\n",
        "        test =bin8(i)\n",
        "        test = int(test,base=2)\n",
        "        hex_test = hex(test)[2:].zfill(2)\n",
        "        temp.append(hex_test)\n",
        "\n",
        "    return temp\n",
        "\n",
        "def signed_dec2hex(input):\n",
        "    '''Convert a number which data is signed decimal to 8 bits hex with 2's complement'''\n",
        "    bin8 = lambda x : ''.join(reversed( [str((x >> i) & 1) for i in range(8)] ) )\n",
        "    test =bin8(input)\n",
        "    test = int(test,base=2)\n",
        "    hex_test = hex(test)[2:].zfill(2)\n",
        "\n",
        "    return hex_test\n",
        "\n",
        "\n",
        "def golden_gen(golden_layer_decimal):\n",
        "    '''Convert a layer output which is signed decimal in GPU to 8 bits hex with 2's complement in CPU and\n",
        "     make it 4 element in a line, example of use : golden_gen(q_output_activation[\"Conv.3\"]) '''\n",
        "    golden = []\n",
        "    i=0\n",
        "    golden_in_numpy = golden_layer_decimal.cpu().numpy()\n",
        "    test = golden_in_numpy.flatten()\n",
        "    test =test.astype('int32')\n",
        "    golden.append([])\n",
        "    for j, data in enumerate(test):\n",
        "        if(j%4==0 ):\n",
        "            golden.append([])\n",
        "            i = i+1\n",
        "            golden[i].append(signed_dec2hex(data))\n",
        "        if(j%4!=0):\n",
        "            golden[i].append(signed_dec2hex(data))\n",
        "    golden.pop(0)\n",
        "    for indice,data in enumerate(golden):\n",
        "        print(*data,sep='')\n",
        "\n",
        "def input_or_weight_gen(layer_decimal):\n",
        "    '''Convert a layer output which is signed decimal in GPU to 8 bits hex with 2's complement in CPU and\n",
        "     make each byte display in different place, example of use : input_or_weight_gen(quantized_model.Conv[1].weights)'''\n",
        "    byte0 = []\n",
        "    byte1 = []\n",
        "    byte2 = []\n",
        "    byte3 = []\n",
        "\n",
        "    data_in_numpy = layer_decimal.cpu().numpy()\n",
        "    data_test = data_in_numpy.flatten()\n",
        "    data_test = data_test.astype('int32')\n",
        "    data_test = signed_dec2hex_matrix(data_test)\n",
        "    for indice,data in enumerate(data_test):\n",
        "        if(indice%4 == 0):\n",
        "            byte0.append(data)\n",
        "        elif(indice%4 == 1):\n",
        "            byte1.append(data)\n",
        "        elif(indice%4 == 2):\n",
        "            byte2.append(data)\n",
        "        else:\n",
        "            byte3.append(data)\n",
        "    print(\"byte0:\",*byte0)\n",
        "    print(\"=======\")\n",
        "    print(\"byte1:\",*byte1)\n",
        "    print(\"=======\")\n",
        "    print(\"byte2:\",*byte2)\n",
        "    print(\"=======\")\n",
        "    print(\"byte3:\",*byte3)\n",
        "    print(\"=======\")\n",
        "    return byte0,byte1,byte2,byte3\n",
        "\n",
        "def DecToBin_machine(num,accuracy):\n",
        "    integer = int(num)\n",
        "    flo = num - integer\n",
        "    integercom = '{:1b}'.format(integer)\n",
        "    tem = flo\n",
        "    flo_list = []\n",
        "    for i in range(accuracy):\n",
        "        tem *= 2\n",
        "        flo_list += str(int(tem))\n",
        "        tem -= int(tem)\n",
        "    flocom = flo_list\n",
        "    binary_value =  ''.join(flocom)\n",
        "    return binary_value\n",
        "\n",
        "#golden_gen(q_output_activation[\"Conv.3\"])\n",
        "print(signed_dec2hex(quantized_model.Conv[1].input_zero_point))\n",
        "input_or_weight_gen(q_input_activation[\"Conv.1\"])\n",
        "print(\"===\")\n",
        "input_or_weight_gen(quantized_model.Conv[4].weights)\n",
        "\n",
        "print(quantized_model.Conv[4].input_zero_point)\n",
        "\n",
        "DeS = quantized_model.Conv[3].store_scale\n",
        "print(DeS)\n",
        "#print(DeS *8192) # 2**13\n",
        "#print(\"deq_scale (shift 13):\",DecToBin_machine(quantized_model.Conv[1].,8))\n",
        "print(\"req_scale (shift 6):\",)\n",
        "print(\"output zero\",)\n",
        "#binary_value = integercom + '.' + ''.join(flocom)\n",
        "result = DecToBin_machine(DeS,8)\n",
        "print(result)\n",
        "# 0.1100111101011100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMccqTL6URaZ"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRMXzNeCgDuq",
        "outputId": "0fa65b9f-3a60-41e0-a935-a601a8db0484"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Error: \n",
            " Accuracy: 87.0%, Avg loss: 0.000476 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_loop(test_loader, FP32_model, loss_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knTzO1mbheBe",
        "outputId": "411fc256-b7ea-4757-9f75-6acaae605324"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Error: \n",
            " Accuracy: 32.4%, Avg loss: 0.014689 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_loop(test_loader, quantized_model, loss_fn)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
