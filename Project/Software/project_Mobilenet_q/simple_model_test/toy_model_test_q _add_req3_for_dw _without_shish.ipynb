{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sHXk_L8g3fDh"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "tVH9mlCdXrkw"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import math\n",
        "import random\n",
        "from collections import OrderedDict, defaultdict\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import *\n",
        "from torch.optim.lr_scheduler import *\n",
        "import torchvision.models as models\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.datasets import *\n",
        "from torchvision.transforms import *\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "no_cuda = False\n",
        "use_gpu = not no_cuda and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_gpu else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _make_divisible(v, divisor, min_value=None):\n",
        "    \"\"\"\n",
        "    This function is taken from the original tf repo.\n",
        "    It ensures that all layers have a channel number that is divisible by 8\n",
        "    It can be seen here:\n",
        "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
        "    :param v:\n",
        "    :param divisor:\n",
        "    :param min_value:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if min_value is None:\n",
        "        min_value = divisor\n",
        "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "    # Make sure that round down does not go down by more than 10%.\n",
        "    if new_v < 0.9 * v:\n",
        "        new_v += divisor\n",
        "    return new_v\n",
        "\n",
        "class h_sigmoid(nn.Module):\n",
        "    def __init__(self, inplace=True):\n",
        "        super(h_sigmoid, self).__init__()\n",
        "        self.relu = nn.ReLU6(inplace=inplace)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.relu(x + 3) / 6\n",
        "\n",
        "\n",
        "class h_swish(nn.Module):\n",
        "    def __init__(self, inplace=True):\n",
        "        super(h_swish, self).__init__()\n",
        "        self.sigmoid = h_sigmoid(inplace=inplace)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * self.sigmoid(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class SELayer(nn.Module):\n",
        "    def __init__(self, channel, reduction=4):\n",
        "        super(SELayer, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "                nn.Linear(channel, _make_divisible(channel // reduction, 8),bias=False),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(_make_divisible(channel // reduction, 8), channel,bias=False),\n",
        "                nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk1U6PcMXtDB",
        "outputId": "58b165e2-e66b-41c5-987d-4fcc1b6a26fa"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "batch_size = 32\n",
        "test_batch = 1\n",
        "#Dataset\n",
        "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "#Dataloader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=test_batch, shuffle=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JzMtMm9n3hsZ"
      },
      "source": [
        "Create NN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-pKE7xJbOc7",
        "outputId": "fce122fd-5aa8-4d0c-fe2c-94bb60cc64ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ToyModel(\n",
            "  (Conv): Sequential(\n",
            "    (0): Conv2d(1, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(8, 8, kernel_size=(3, 3), stride=(3, 3), padding=(1, 1), groups=8, bias=False)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): SELayer(\n",
            "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "      (fc): Sequential(\n",
            "        (0): Linear(in_features=8, out_features=8, bias=False)\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Linear(in_features=8, out_features=8, bias=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (7): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (8): ReLU(inplace=True)\n",
            "  )\n",
            "  (backbone): Sequential(\n",
            "    (0): Linear(in_features=100, out_features=120, bias=False)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=120, out_features=84, bias=False)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=84, out_features=10, bias=False)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class ToyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.Conv = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=1, out_channels=8, kernel_size=1, stride=1,padding= 0, bias=False),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Conv2d(in_channels=8, out_channels=8, kernel_size=1, stride=1,padding= 0, bias=False),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3, stride=3,padding= 1, bias=False,groups=8),\n",
        "      nn.ReLU(inplace=True),\n",
        "      SELayer(8),\n",
        "      nn.Conv2d(in_channels=8, out_channels=1, kernel_size=1, stride=1,padding= 0, bias=False),\n",
        "      nn.ReLU(inplace=True),\n",
        "    )  \n",
        "    self.backbone = nn.Sequential(\n",
        "      nn.Linear(10*10, 120, bias=False),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(120, 84, bias=False),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(84, 10, bias=False)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x=self.Conv(x)\n",
        "    x = x.view(-1, 10*10) #transform 28*28 figure to 784 vector\n",
        "    x = self.backbone(x)\n",
        "    return x\n",
        "\n",
        "FP32_model = ToyModel()\n",
        "print(FP32_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "MOyeqSPDbvr5"
      },
      "outputs": [],
      "source": [
        "#train model\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  #Set the model to train mode\n",
        "  model.train()\n",
        "  for batch, (x, y) in enumerate(dataloader):\n",
        "    if use_gpu:\n",
        "      x, y = x.cuda(), y.cuda()\n",
        "    optimizer.zero_grad()\n",
        "    #forward\n",
        "    pred = model(x)\n",
        "\n",
        "    #loss\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    #backward\n",
        "    loss.backward()\n",
        "\n",
        "    #optimize\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), (batch + 1) * len(x)\n",
        "      print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "  #set model to evaluate mode\n",
        "  model.eval()\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for x, y in dataloader:\n",
        "      if use_gpu:\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "      pred = model(x)\n",
        "      test_loss = loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item() #calculate accuracy\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LsfzIw4b1AU",
        "outputId": "03aeb700-d0fe-4e88-a24e-d000b63c4184"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ToyModel(\n",
              "  (Conv): Sequential(\n",
              "    (0): Conv2d(1, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): Conv2d(8, 8, kernel_size=(3, 3), stride=(3, 3), padding=(1, 1), groups=8, bias=False)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): SELayer(\n",
              "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "      (fc): Sequential(\n",
              "        (0): Linear(in_features=8, out_features=8, bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Linear(in_features=8, out_features=8, bias=False)\n",
              "        (3): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (7): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (8): ReLU(inplace=True)\n",
              "  )\n",
              "  (backbone): Sequential(\n",
              "    (0): Linear(in_features=100, out_features=120, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=120, out_features=84, bias=False)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=84, out_features=10, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "learning_rate = 1e-3\n",
        "epochs = 3\n",
        "loss_fn = nn.CrossEntropyLoss() #define loss function\n",
        "optimizer = torch.optim.Adam(FP32_model.parameters(), lr=learning_rate)  #define optimizer\n",
        "\n",
        "FP32_model.to(device) #let model on GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "LH6kt0eqb9tl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.302585  [   32/60000]\n",
            "loss: 2.294250  [ 3232/60000]\n",
            "loss: 1.526727  [ 6432/60000]\n",
            "loss: 0.785593  [ 9632/60000]\n",
            "loss: 1.007656  [12832/60000]\n",
            "loss: 0.653374  [16032/60000]\n",
            "loss: 0.682098  [19232/60000]\n",
            "loss: 0.753057  [22432/60000]\n",
            "loss: 0.494787  [25632/60000]\n",
            "loss: 0.730136  [28832/60000]\n",
            "loss: 0.489663  [32032/60000]\n",
            "loss: 0.573711  [35232/60000]\n",
            "loss: 0.593057  [38432/60000]\n",
            "loss: 0.403741  [41632/60000]\n",
            "loss: 0.426896  [44832/60000]\n",
            "loss: 0.579764  [48032/60000]\n",
            "loss: 0.581057  [51232/60000]\n",
            "loss: 0.508279  [54432/60000]\n",
            "loss: 0.855842  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 79.5%, Avg loss: 0.000126 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.432545  [   32/60000]\n",
            "loss: 0.360006  [ 3232/60000]\n",
            "loss: 0.481926  [ 6432/60000]\n",
            "loss: 0.569693  [ 9632/60000]\n",
            "loss: 0.882042  [12832/60000]\n",
            "loss: 0.636134  [16032/60000]\n",
            "loss: 0.671663  [19232/60000]\n",
            "loss: 0.573292  [22432/60000]\n",
            "loss: 0.465550  [25632/60000]\n",
            "loss: 0.407123  [28832/60000]\n",
            "loss: 0.410661  [32032/60000]\n",
            "loss: 0.275104  [35232/60000]\n",
            "loss: 0.514747  [38432/60000]\n",
            "loss: 0.190807  [41632/60000]\n",
            "loss: 0.417928  [44832/60000]\n",
            "loss: 0.543528  [48032/60000]\n",
            "loss: 0.540798  [51232/60000]\n",
            "loss: 0.392756  [54432/60000]\n",
            "loss: 0.664267  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.0%, Avg loss: 0.000057 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.256373  [   32/60000]\n",
            "loss: 0.263918  [ 3232/60000]\n",
            "loss: 0.436103  [ 6432/60000]\n",
            "loss: 0.549286  [ 9632/60000]\n",
            "loss: 0.495212  [12832/60000]\n",
            "loss: 0.409255  [16032/60000]\n",
            "loss: 0.277256  [19232/60000]\n",
            "loss: 0.433150  [22432/60000]\n",
            "loss: 0.613387  [25632/60000]\n",
            "loss: 0.337084  [28832/60000]\n",
            "loss: 0.739062  [32032/60000]\n",
            "loss: 0.363223  [35232/60000]\n",
            "loss: 0.588380  [38432/60000]\n",
            "loss: 0.394345  [41632/60000]\n",
            "loss: 0.348902  [44832/60000]\n",
            "loss: 0.420568  [48032/60000]\n",
            "loss: 0.233931  [51232/60000]\n",
            "loss: 0.384838  [54432/60000]\n",
            "loss: 0.345980  [57632/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.2%, Avg loss: 0.000034 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Training\n",
        "for i in range(epochs):\n",
        "  print(f\"Epoch {i+1}\\n-------------------------------\")\n",
        "  train_loop(train_loader, FP32_model, loss_fn, optimizer)\n",
        "  test_loop(test_loader, FP32_model, loss_fn)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oTAK3-fH3qGh"
      },
      "source": [
        "# Quantization definition"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0lWzxrde4G5i"
      },
      "source": [
        "####Question 1.####\n",
        "\n",
        "Use\n",
        ">$S=(r_{\\mathrm{max}} - r_{\\mathrm{min}}) / (q_{\\mathrm{max}} - q_{\\mathrm{min}})$\n",
        "\n",
        ">$Z = q_{\\mathrm{min}} - r_{\\mathrm{min}} / S$\n",
        "\n",
        "to calculate scale factor and zero point of a tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "kJIr-5SpcgQr"
      },
      "outputs": [],
      "source": [
        "def get_scale_and_zero_point(fp32_tensor, bitwidth=8):\n",
        "  q_min, q_max = -(2**(bitwidth-1)), 2**(bitwidth-1) - 1\n",
        "  fp_min = fp32_tensor.min().item()\n",
        "  fp_max = fp32_tensor.max().item()\n",
        "  \n",
        "  #####################################################\n",
        "\n",
        "  scale = (fp_max-fp_min) / (q_max-q_min)\n",
        "  zero_point = q_min-fp_min /scale\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "\n",
        "  zero_point = round(zero_point)          #round\n",
        "  zero_point = max(q_min, min(zero_point, q_max)) #clip\n",
        "\n",
        "  return scale, int(zero_point)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "D4YA7ano5nS1"
      },
      "source": [
        "####Question 2.####\n",
        "\n",
        "Use $q=r/S + Z$ to quantize a tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "sBMKB5Le54wr"
      },
      "outputs": [],
      "source": [
        "def linear_quantize(fp32_tensor, bitwidth=8):\n",
        "  q_min, q_max = -(2**(bitwidth-1)), 2**(bitwidth-1) - 1\n",
        "\n",
        "  scale, zero_point = get_scale_and_zero_point(fp32_tensor)\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "  q_tensor = torch.round( fp32_tensor/scale ) +zero_point\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "  #clamp\n",
        "  q_tensor = torch.clamp(q_tensor, q_min, q_max)\n",
        "  return q_tensor, scale, zero_point  "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0taJXSmz6KDS"
      },
      "source": [
        "####Question 3.####\n",
        "\n",
        "Use\n",
        "> $q_{\\mathrm{output}} = M * \\mathrm{Linear}[q_{\\mathrm{input}}, q_{\\mathrm{weight}}] + Z_{\\mathrm{output}}$\n",
        "\n",
        "> $M = S_{\\mathrm{input}} * S_{\\mathrm{weight}} / S_{\\mathrm{output}}$\n",
        "\n",
        "to compute quantized linear operation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "sbXY0vaCcn7l"
      },
      "outputs": [],
      "source": [
        "def quantized_linear(input, weights, input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point, device, bitwidth=8, activation_bitwidth=8):\n",
        "  input, weights = input.to(device), weights.to(device)\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "  M = input_scale * weight_scale / output_scale\n",
        "  output = torch.nn.functional.linear((input - input_zero_point ), (weights - weight_zero_point))\n",
        "  output *= M\n",
        "  output += output_zero_point\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "  #clamp and round\n",
        "  output = output.round().clamp(-(2**(activation_bitwidth-1)), 2**(activation_bitwidth-1)-1)\n",
        "\n",
        "  return output\n",
        "\n",
        "def quantized_conv(input, weights,stride, padding,groups,input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point, device, bitwidth=8, activation_bitwidth=8):\n",
        "  input, weights = input.to(device), weights.to(device)\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "  M = input_scale * weight_scale / output_scale\n",
        "  output_only_conv = torch.nn.functional.conv2d((input - input_zero_point ), (weights - weight_zero_point) ,stride=stride,padding=padding,groups=groups)\n",
        "  output = M * output_only_conv\n",
        "  output += output_zero_point\n",
        "  #####################################################\n",
        "\n",
        "  #clamp and round\n",
        "  output = output.round().clamp(-(2**(activation_bitwidth-1)), 2**(activation_bitwidth-1)-1)\n",
        "  return output\n",
        "\n",
        "def do_requant(input, scale,zero_point,bitwidth=8):\n",
        "    output = input / scale\n",
        "    output = output.round()\n",
        "    output += zero_point\n",
        "    output = output.round().clamp(-(2**(bitwidth-1)), 2**(bitwidth-1)-1)\n",
        "    return output\n",
        "\n",
        "def do_fake_quant(input, deq_scale, q_scale, q_zero_point,bitwidth=8):\n",
        "    M = deq_scale/q_scale\n",
        "    N = q_zero_point\n",
        "    output = input * M\n",
        "    output += N\n",
        "    output = output.round().clamp(-(2**(bitwidth-1)), 2**(bitwidth-1)-1)\n",
        "    return output\n",
        "   "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vK10k10R7II7"
      },
      "source": [
        "# Design quantized linear layer and preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "IwrXNVKadKfG"
      },
      "outputs": [],
      "source": [
        "class Q_SELayer(nn.Module):\n",
        "  def __init__(self,weights1,input_scale1,weight_scale1,output_scale1, input_zero_point1, weight_zero_point1, output_zero_point1,\n",
        "               weights2, input_scale2, weight_scale2, output_scale2, input_zero_point2, weight_zero_point2, output_zero_point2,\n",
        "               input_SE_scale,in_SE_zero_point,\n",
        "               output_SE_scale,output_SE_zero_point,\n",
        "               out_pool_scale,out_pool_zero_point):\n",
        "    super().__init__()\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "    self.fc = nn.Sequential(\n",
        "        QuantizedLinear(weights1,input_scale1,weight_scale1,output_scale1, input_zero_point1, weight_zero_point1, output_zero_point1),\n",
        "        QuantizedLinear(weights2, input_scale2, weight_scale2, output_scale2, input_zero_point2, weight_zero_point2, output_zero_point2)\n",
        "    )   \n",
        "    self.input_SE_scale, self.in_SE_zero_point = input_SE_scale,in_SE_zero_point\n",
        "    self.output_SE_scale, self.output_SE_zero_point = output_SE_scale, output_SE_zero_point,\n",
        "    self.out_pool_scale, self.out_pool_zero_point = out_pool_scale,out_pool_zero_point\n",
        "    self.linear_out_scale, self.linear_out_zero_point = output_scale2, output_zero_point2\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    b, c, _, _ = x.size()\n",
        "    y = self.avg_pool(x).view(b, c)\n",
        "    y = (y- self.in_SE_zero_point) \n",
        "    y = do_fake_quant(y, self.input_SE_scale, self.out_pool_scale, self.out_pool_zero_point,bitwidth=8)\n",
        "    y = self.fc(y).view(b, c, 1, 1)\n",
        "    z = (x-self.in_SE_zero_point)*(y-self.linear_out_zero_point)\n",
        "    return do_fake_quant(z, deq_scale=(self.input_SE_scale *self.linear_out_scale), \n",
        "                         q_scale=self.output_SE_scale, q_zero_point=self.output_SE_zero_point,bitwidth=8)\n",
        "  \n",
        "  def __repr__(self):\n",
        "    return f\"Quantized_SE(in_channels={self.fc[0].weights.size(1)}, out_channels={self.fc[1].weights.size(0)})\"\n",
        "    \n",
        "\n",
        "\n",
        "class QuantizedConv(nn.Module):\n",
        "  def __init__(self,weights,stride,padding,groups ,input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point, bitwidth=8, activation_bitwidth=8):\n",
        "    super().__init__()\n",
        "    self.stride, self.padding, self.groups = stride, padding,groups\n",
        "    self.weights = weights\n",
        "    self.input_scale, self.input_zero_point = input_scale, input_zero_point\n",
        "    self.weight_scale, self.weight_zero_point = weight_scale, weight_zero_point\n",
        "    self.output_scale, self.output_zero_point = output_scale, output_zero_point\n",
        "    self.bitwidth = bitwidth\n",
        "    self.activation_bitwidth = activation_bitwidth\n",
        "    self.q_weight = weights - weight_zero_point\n",
        "    self.ReQ_scale = input_scale*weight_scale/output_scale\n",
        "  def forward(self, x):\n",
        "    return quantized_conv(x, self.weights, self.stride, self.padding, self.groups, self.input_scale, self.weight_scale, self.output_scale, self.input_zero_point, self.weight_zero_point, self.output_zero_point, device)\n",
        "  def __repr__(self):\n",
        "    return f\"QuantizedConv(in_channels={self.weights.size(1)}, out_channels={self.weights.size(0)})\"\n",
        "\n",
        "class QuantizedLinear(nn.Module):\n",
        "  def __init__(self, weights, input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point, bitwidth=8, activation_bitwidth=8):\n",
        "    super().__init__()\n",
        "    self.weights = weights\n",
        "    self.input_scale, self.input_zero_point = input_scale, input_zero_point\n",
        "    self.weight_scale, self.weight_zero_point = weight_scale, weight_zero_point\n",
        "    self.output_scale, self.output_zero_point = output_scale, output_zero_point\n",
        "\n",
        "    self.bitwidth = bitwidth\n",
        "    self.activation_bitwidth = activation_bitwidth\n",
        "\n",
        "  def forward(self, x):\n",
        "    return quantized_linear(x, self.weights, self.input_scale, self.weight_scale, self.output_scale, self.input_zero_point, self.weight_zero_point, self.output_zero_point, device)\n",
        "  def __repr__(self):\n",
        "    return f\"QuantizedLinear(in_channels={self.weights.size(1)}, out_channels={self.weights.size(0)})\"\n",
        "\n",
        "#Transform input data to correct integer range\n",
        "class Preprocess(nn.Module):\n",
        "  def __init__(self, input_scale, input_zero_point, activation_bitwidth=8):\n",
        "    super().__init__()\n",
        "    self.input_scale, self.input_zero_point = input_scale, input_zero_point\n",
        "    self.activation_bitwidth = activation_bitwidth\n",
        "  def forward(self, x):\n",
        "    x = x / self.input_scale + self.input_zero_point\n",
        "    x = x.round() \n",
        "    return x\n",
        "  \n",
        "class Quantizer(nn.Module):\n",
        "  def __init__(self,scale,zero_point,bitwidth=8):\n",
        "    super().__init__()\n",
        "    self.scale = scale\n",
        "    self.zero = zero_point\n",
        "    self.store_scale = scale *64\n",
        "\n",
        "  def forward(self,x):\n",
        "    return do_requant(x,self.scale,self.zero)\n",
        "    "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EUpiPDiu7RCH"
      },
      "source": [
        "# Calibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "cBdXFnr5dZqT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          ...,\n",
            "          [0.3275, 0.3275, 0.2119,  ..., 0.0000, 0.0000, 0.3275],\n",
            "          [0.3275, 0.3275, 0.0706,  ..., 0.0000, 0.2171, 0.3275],\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275]],\n",
            "\n",
            "         [[1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          ...,\n",
            "          [1.1521, 1.1521, 0.7455,  ..., 0.0000, 0.0000, 1.1521],\n",
            "          [1.1521, 1.1521, 0.2485,  ..., 0.0000, 0.7635, 1.1521],\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521]],\n",
            "\n",
            "         [[1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          ...,\n",
            "          [1.0985, 1.0985, 0.7108,  ..., 0.0000, 0.0000, 1.0985],\n",
            "          [1.0985, 1.0985, 0.2369,  ..., 0.0000, 0.7281, 1.0985],\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0260, 0.0162, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0175, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          ...,\n",
            "          [0.5139, 0.5139, 0.3325,  ..., 0.0000, 0.0000, 0.5139],\n",
            "          [0.5139, 0.5139, 0.1108,  ..., 0.0000, 0.3406, 0.5139],\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.5322, 0.3304, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.3583, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          ...,\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275]],\n",
            "\n",
            "         [[1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          ...,\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521]],\n",
            "\n",
            "         [[1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          ...,\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          ...,\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          ...,\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275]],\n",
            "\n",
            "         [[1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          ...,\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521]],\n",
            "\n",
            "         [[1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          ...,\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          ...,\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          ...,\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275]],\n",
            "\n",
            "         [[1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          ...,\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521]],\n",
            "\n",
            "         [[1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          ...,\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          ...,\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          ...,\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275]],\n",
            "\n",
            "         [[1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          ...,\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521]],\n",
            "\n",
            "         [[1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          ...,\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          ...,\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          ...,\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275],\n",
            "          [0.3275, 0.3275, 0.3275,  ..., 0.3275, 0.3275, 0.3275]],\n",
            "\n",
            "         [[1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          ...,\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521],\n",
            "          [1.1521, 1.1521, 1.1521,  ..., 1.1521, 1.1521, 1.1521]],\n",
            "\n",
            "         [[1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          ...,\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985],\n",
            "          [1.0985, 1.0985, 1.0985,  ..., 1.0985, 1.0985, 1.0985]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          ...,\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139],\n",
            "          [0.5139, 0.5139, 0.5139,  ..., 0.5139, 0.5139, 0.5139]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]])\n",
            "dict_keys(['Conv.0', 'Conv.1', 'Conv.2', 'Conv.3', 'Conv.4', 'Conv.5', 'Conv.6.avg_pool', 'Conv.6.fc.0', 'Conv.6.fc.1', 'Conv.6.fc.2', 'Conv.6.fc.3', 'Conv.7', 'Conv.8', 'backbone.0', 'backbone.1', 'backbone.2', 'backbone.3', 'backbone.4'])\n",
            "tensor([[[[ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          ...,\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755]],\n",
            "\n",
            "         [[-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          ...,\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435]],\n",
            "\n",
            "         [[ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          ...,\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          ...,\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037]],\n",
            "\n",
            "         [[-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          ...,\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275]],\n",
            "\n",
            "         [[ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          ...,\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          ...,\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755]],\n",
            "\n",
            "         [[-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          ...,\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435]],\n",
            "\n",
            "         [[ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          ...,\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          ...,\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037]],\n",
            "\n",
            "         [[-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          ...,\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275]],\n",
            "\n",
            "         [[ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          ...,\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          ...,\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0417,  1.0755],\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755]],\n",
            "\n",
            "         [[-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          ...,\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3328, -0.3435],\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435]],\n",
            "\n",
            "         [[ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          ...,\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0085,  1.0412],\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          ...,\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.3597,  1.4037],\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037]],\n",
            "\n",
            "         [[-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          ...,\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2204, -0.2275],\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275]],\n",
            "\n",
            "         [[ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          ...,\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2440,  1.2843],\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          ...,\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755]],\n",
            "\n",
            "         [[-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          ...,\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435]],\n",
            "\n",
            "         [[ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          ...,\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          ...,\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037]],\n",
            "\n",
            "         [[-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          ...,\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275]],\n",
            "\n",
            "         [[ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          ...,\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          ...,\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755]],\n",
            "\n",
            "         [[-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          ...,\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435]],\n",
            "\n",
            "         [[ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          ...,\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          ...,\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037]],\n",
            "\n",
            "         [[-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          ...,\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275]],\n",
            "\n",
            "         [[ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          ...,\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          ...,\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755],\n",
            "          [ 1.0755,  1.0755,  1.0755,  ...,  1.0755,  1.0755,  1.0755]],\n",
            "\n",
            "         [[-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          ...,\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435],\n",
            "          [-0.3435, -0.3435, -0.3435,  ..., -0.3435, -0.3435, -0.3435]],\n",
            "\n",
            "         [[ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          ...,\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412],\n",
            "          [ 1.0412,  1.0412,  1.0412,  ...,  1.0412,  1.0412,  1.0412]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          ...,\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037],\n",
            "          [ 1.4037,  1.4037,  1.4037,  ...,  1.4037,  1.4037,  1.4037]],\n",
            "\n",
            "         [[-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          ...,\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275],\n",
            "          [-0.2275, -0.2275, -0.2275,  ..., -0.2275, -0.2275, -0.2275]],\n",
            "\n",
            "         [[ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          ...,\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843],\n",
            "          [ 1.2843,  1.2843,  1.2843,  ...,  1.2843,  1.2843,  1.2843]]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# add hook to record the min max value of the activation\n",
        "input_activation = {}\n",
        "output_activation = {}\n",
        "\n",
        "#Define a hook to record the feature map of each layer\n",
        "def add_range_recoder_hook(model):\n",
        "    import functools\n",
        "    def _record_range(self, x, y, module_name):\n",
        "        x = x[0]\n",
        "        input_activation[module_name] = x.detach()\n",
        "        output_activation[module_name] = y.detach()\n",
        "\n",
        "    all_hooks = []\n",
        "    for name, m in model.named_modules():\n",
        "        if isinstance(m, (nn.Linear, nn.ReLU,nn.Conv2d,h_swish,nn.AdaptiveAvgPool2d)):\n",
        "            all_hooks.append(m.register_forward_hook(\n",
        "                functools.partial(_record_range, module_name=name)))\n",
        "\n",
        "\n",
        "    return all_hooks\n",
        "\n",
        "hooks = add_range_recoder_hook(FP32_model)\n",
        "sample_data = iter(train_loader).__next__()[0].to(device) #Use a batch of training data to calibrate\n",
        "FP32_model(sample_data) #Forward to use hook\n",
        "print(output_activation['Conv.1'])\n",
        "# print(\"==\")\n",
        "# print(input_activation['Conv.2.avg_pool'])\n",
        "print(output_activation.keys())\n",
        "# remove hooks\n",
        "for h in hooks:\n",
        "    h.remove()\n",
        "\n",
        "print(output)\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YVf8vpiVTsDa"
      },
      "source": [
        "# Quantize model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "SVh-SRj8eOrs"
      },
      "outputs": [],
      "source": [
        "#copy original model\n",
        "quantized_model = copy.deepcopy(FP32_model)\n",
        "\n",
        "#Record each layer in original model\n",
        "quantized_backbone = []\n",
        "quantized_Conv = []\n",
        "i = 0\n",
        "\n",
        "#Record input scale and zero point\n",
        "input_scale, input_zero_point = get_scale_and_zero_point(input_activation[\"Conv.0\"])\n",
        "preprocess = Preprocess(input_scale, input_zero_point)\n",
        "quantized_Conv.append(preprocess)\n",
        "\n",
        "input_scale, input_zero_point = get_scale_and_zero_point(input_activation['Conv.0'])\n",
        "output_scale, output_zero_point = get_scale_and_zero_point(output_activation['Conv.1'])\n",
        "quantized_weights12, weight_scale, weight_zero_point = linear_quantize(FP32_model.Conv[0].weight.data)\n",
        "quantizedConv1 = QuantizedConv(quantized_weights12, 1,0,1,input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point)\n",
        "quantized_Conv.append(quantizedConv1)\n",
        "\n",
        "input_scale, input_zero_point = get_scale_and_zero_point(input_activation['Conv.2'])\n",
        "output_scale, output_zero_point = get_scale_and_zero_point(output_activation['Conv.3'])\n",
        "quantized_weights12, weight_scale, weight_zero_point = linear_quantize(FP32_model.Conv[2].weight.data)\n",
        "quantizedConv2 = QuantizedConv(quantized_weights12, 1,0,1,input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point)\n",
        "#quantized_model.Conv[0] = quantizedConv1 \n",
        "\n",
        "\n",
        "quantized_Conv.append(quantizedConv2)\n",
        "\n",
        "#####################\n",
        "input_scale, input_zero_point = get_scale_and_zero_point(input_activation['Conv.4'])\n",
        "output_scale, output_zero_point = get_scale_and_zero_point(output_activation['Conv.5'])\n",
        "quantized_weights12, weight_scale, weight_zero_point = linear_quantize(FP32_model.Conv[4].weight.data)\n",
        "quantizedConv3 = QuantizedConv(quantized_weights12, 3,1,8,input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point)\n",
        "\n",
        "quantized_Conv.append(quantizedConv3)\n",
        "\n",
        "###############\n",
        "input_scale1, input_zero_point1 = get_scale_and_zero_point(input_activation['Conv.6.fc.0'])\n",
        "output_scale1, output_zero_point1 = get_scale_and_zero_point(output_activation['Conv.6.fc.1'])\n",
        "quantized_weights1, weight_scale1, weight_zero_point1 = linear_quantize(FP32_model.Conv[6].fc[0].weight.data)\n",
        "\n",
        "input_scale2, input_zero_point2 = get_scale_and_zero_point(input_activation['Conv.6.fc.2'])\n",
        "output_scale2, output_zero_point2 = get_scale_and_zero_point(output_activation['Conv.6.fc.3'])\n",
        "quantized_weights2, weight_scale2, weight_zero_point2 = linear_quantize(FP32_model.Conv[6].fc[2].weight.data)\n",
        "\n",
        "SE_in_scale, SE_in_zero_point = get_scale_and_zero_point(output_activation['Conv.5'])\n",
        "\n",
        "SE_out_scale, SE_out_zero_point = get_scale_and_zero_point(input_activation['Conv.7'])\n",
        "\n",
        "SE_out_pool_scale, SE_out_pool_zero_point = get_scale_and_zero_point(output_activation['Conv.6.avg_pool'])\n",
        "\n",
        "quantizedSE_linear1 =Q_SELayer(quantized_weights1,input_scale1,weight_scale1,output_scale1,input_zero_point1,weight_zero_point1,output_zero_point1, \n",
        "                               quantized_weights2,input_scale2,weight_scale2,output_scale2,input_zero_point2,weight_zero_point2,output_zero_point2,\n",
        "                               SE_in_scale, SE_in_zero_point,\n",
        "                               SE_out_scale, SE_out_zero_point,\n",
        "                               SE_out_pool_scale, SE_out_pool_zero_point)\n",
        "##################\n",
        "quantized_Conv.append(quantizedSE_linear1)\n",
        "\n",
        "\n",
        "input_scale, input_zero_point = get_scale_and_zero_point(input_activation['Conv.7'])\n",
        "output_scale, output_zero_point = get_scale_and_zero_point(output_activation['Conv.8'])\n",
        "quantized_weights, weight_scale, weight_zero_point = linear_quantize(FP32_model.Conv[7].weight.data)\n",
        "quantizedConv4 = QuantizedConv(quantized_weights, 1,0,1,input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point)\n",
        "\n",
        "\n",
        "quantized_Conv.append(quantizedConv4)\n",
        "\n",
        "\n",
        "\n",
        "################# below is linear\n",
        "\n",
        "input_scale, input_zero_point = get_scale_and_zero_point(input_activation['backbone.0'])\n",
        "output_scale, output_zero_point = get_scale_and_zero_point(output_activation['backbone.1'])\n",
        "quantized_weights, weight_scale, weight_zero_point = linear_quantize(FP32_model.backbone[0].weight.data)\n",
        "quantizedLinear1 = QuantizedLinear(quantized_weights, input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point)\n",
        "quantized_backbone.append(quantizedLinear1)\n",
        "\n",
        "input_scale, input_zero_point = get_scale_and_zero_point(input_activation['backbone.2'])\n",
        "output_scale, output_zero_point = get_scale_and_zero_point(output_activation['backbone.3'])\n",
        "quantized_weights, weight_scale, weight_zero_point = linear_quantize(FP32_model.backbone[2].weight.data)\n",
        "quantizedLinear2 = QuantizedLinear(quantized_weights, input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point)\n",
        "quantized_backbone.append(quantizedLinear2)\n",
        "\n",
        "# #Record Linear + ReLU of the model (except the last Linear)\n",
        "# while i < len(quantized_model.backbone) - 1:\n",
        "#   if isinstance(quantized_model.backbone[i], nn.Linear) and isinstance(quantized_model.backbone[i+1], nn.ReLU):\n",
        "#     linear = quantized_model.backbone[i]\n",
        "#     linear_name = f\"backbone.{i}\"\n",
        "#     relu = quantized_model.backbone[i + 1]\n",
        "#     relu_name = f\"backbone.{i + 1}\"\n",
        "\n",
        "#     #Use the calibration data to calculate scale and zero point of each layer\n",
        "#     input_scale, input_zero_point = get_scale_and_zero_point(input_activation[linear_name])\n",
        "#     output_scale, output_zero_point = get_scale_and_zero_point(output_activation[relu_name])\n",
        "#     quantized_weights, weight_scale, weight_zero_point = linear_quantize(linear.weight.data)\n",
        "\n",
        "#     quantizedLinear = QuantizedLinear(quantized_weights, input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point)\n",
        "\n",
        "#     quantized_backbone.append(quantizedLinear)\n",
        "#     i += 2\n",
        "\n",
        "#Record the last Linear layer\n",
        "linear = quantized_model.backbone[4]\n",
        "linear_name = f\"backbone.4\"\n",
        "input_scale, input_zero_point = get_scale_and_zero_point(input_activation[linear_name])\n",
        "output_scale, output_zero_point = get_scale_and_zero_point(output_activation[linear_name])\n",
        "quantized_weights, weight_scale, weight_zero_point = linear_quantize(linear.weight.data)\n",
        "quantizedLinear3 = QuantizedLinear(quantized_weights, input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point)\n",
        "quantized_backbone.append(quantizedLinear3)\n",
        "\n",
        "quantized_model.Conv = nn.Sequential(*quantized_Conv)\n",
        "quantized_model.backbone = nn.Sequential(*quantized_backbone)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRB96PKbfNX4",
        "outputId": "58ce882a-3521-4b40-ff98-44dcea373546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ToyModel(\n",
            "  (Conv): Sequential(\n",
            "    (0): Preprocess()\n",
            "    (1): QuantizedConv(in_channels=1, out_channels=8)\n",
            "    (2): QuantizedConv(in_channels=8, out_channels=8)\n",
            "    (3): QuantizedConv(in_channels=1, out_channels=8)\n",
            "    (4): Quantized_SE(in_channels=8, out_channels=8)\n",
            "    (5): QuantizedConv(in_channels=8, out_channels=1)\n",
            "  )\n",
            "  (backbone): Sequential(\n",
            "    (0): QuantizedLinear(in_channels=100, out_channels=120)\n",
            "    (1): QuantizedLinear(in_channels=120, out_channels=84)\n",
            "    (2): QuantizedLinear(in_channels=84, out_channels=10)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(quantized_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1, 28, 28])\n",
            "dict_keys(['Conv.0', 'Conv.1', 'Conv.2', 'Conv.3', 'Conv.4.avg_pool', 'Conv.4.fc.0', 'Conv.4.fc.1', 'Conv.4', 'Conv.5', 'backbone.0', 'backbone.1', 'backbone.2'])\n"
          ]
        }
      ],
      "source": [
        "# add hook to record the min max value of the activation\n",
        "q_input_activation = {}\n",
        "q_output_activation = {}\n",
        "\n",
        "#Define a hook to record the feature map of each layer\n",
        "def add_range_recoder_hook(model):\n",
        "    import functools\n",
        "    def _record_range(self, x, y, module_name):\n",
        "        x = x[0]\n",
        "        q_input_activation[module_name] = x.detach()\n",
        "        q_output_activation[module_name] = y.detach()\n",
        "\n",
        "    all_hooks = []\n",
        "    for name, m in model.named_modules():\n",
        "        if isinstance(m, (QuantizedConv,  QuantizedLinear,h_swish,Quantizer,Preprocess,Q_SELayer,nn.AdaptiveAvgPool2d)):\n",
        "            all_hooks.append(m.register_forward_hook(\n",
        "                functools.partial(_record_range, module_name=name)))\n",
        "\n",
        "\n",
        "    return all_hooks\n",
        "\n",
        "\n",
        "q_test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
        "hooks = add_range_recoder_hook(quantized_model)\n",
        "sample_data = iter(test_loader).__next__()[0].to(device) #Use a batch of training data to calibrate\n",
        "quantized_model(sample_data) #Forward to use hook\n",
        "print(q_input_activation[\"Conv.1\"].shape)\n",
        "print(q_output_activation.keys())\n",
        "#print(q_intput_activation.keys())\n",
        "#print(quantized_model.Conv[4].weights2)\n",
        "#print(q_output_activation[\"Conv.4\"])\n",
        "\n",
        "# remove hooks\n",
        "for h in hooks:\n",
        "    h.remove()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7648062378522773\n",
            "11000011\n",
            "(6272,)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(array([   6.,   10.,  163.,  149.,  174.,   81.,  691.,   61.,   43.,\n",
              "          25.,   26.,   15.,  151.,  652.,   41.,   29.,   59.,  591.,\n",
              "          53., 1100.,   32.,  548.,   27.,   29.,  564.,   12.,  169.,\n",
              "         542.,    4.,    2.,  223.]),\n",
              " array([-121., -113., -105.,  -97.,  -89.,  -81.,  -73.,  -65.,  -57.,\n",
              "         -49.,  -41.,  -33.,  -25.,  -17.,   -9.,   -1.,    7.,   15.,\n",
              "          23.,   31.,   39.,   47.,   55.,   63.,   71.,   79.,   87.,\n",
              "          95.,  103.,  111.,  119.,  127.]),\n",
              " <BarContainer object of 31 artists>)"
            ]
          },
          "execution_count": 183,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def signed_dec2hex_matrix(input):\n",
        "    '''Convert a matrix which data is signed decimal to 8 bits hex with 2's complement'''\n",
        "    temp = []\n",
        "    bin8 = lambda x : ''.join(reversed( [str((x >> i) & 1) for i in range(8)] ) )\n",
        "    for i in input:\n",
        "        test =bin8(i)\n",
        "        test = int(test,base=2)\n",
        "        hex_test = hex(test)[2:].zfill(2)\n",
        "        temp.append(hex_test)\n",
        "\n",
        "    return temp\n",
        "\n",
        "def signed_dec2hex(input):\n",
        "    '''Convert a number which data is signed decimal to 8 bits hex with 2's complement'''\n",
        "    bin8 = lambda x : ''.join(reversed( [str((x >> i) & 1) for i in range(8)] ) )\n",
        "    test =bin8(input)\n",
        "    test = int(test,base=2)\n",
        "    hex_test = hex(test)[2:].zfill(2)\n",
        "\n",
        "    return hex_test\n",
        "\n",
        "\n",
        "def golden_gen(golden_layer_decimal):\n",
        "    '''Convert a layer output which is signed decimal in GPU to 8 bits hex with 2's complement in CPU and\n",
        "     make it 4 element in a line, example of use : golden_gen(q_output_activation[\"Conv.3\"]) '''\n",
        "    golden = []\n",
        "    i=0\n",
        "    golden_in_numpy = golden_layer_decimal.cpu().numpy()\n",
        "    test = golden_in_numpy.flatten()\n",
        "    test =test.astype('int32')\n",
        "    golden.append([])\n",
        "    for j, data in enumerate(test):\n",
        "        if(j%4==0 ):\n",
        "            golden.append([])\n",
        "            i = i+1\n",
        "            golden[i].append(signed_dec2hex(data))\n",
        "        if(j%4!=0):\n",
        "            golden[i].append(signed_dec2hex(data))\n",
        "    golden.pop(0)\n",
        "    for indice,data in enumerate(golden):\n",
        "        print(*data,sep='')\n",
        "\n",
        "def input_or_weight_gen(layer_decimal):\n",
        "    '''Convert a layer output which is signed decimal in GPU to 8 bits hex with 2's complement in CPU and\n",
        "     make each byte display in different place, example of use : input_or_weight_gen(quantized_model.Conv[1].weights)'''\n",
        "    byte0 = []\n",
        "    byte1 = []\n",
        "    byte2 = []\n",
        "    byte3 = []\n",
        "\n",
        "    data_in_numpy = layer_decimal.cpu().numpy()\n",
        "    data_test = data_in_numpy.flatten()\n",
        "    data_test = data_test.astype('int32')\n",
        "    data_test = signed_dec2hex_matrix(data_test)\n",
        "    for indice,data in enumerate(data_test):\n",
        "        if(indice%4 == 0):\n",
        "            byte0.append(data)\n",
        "        elif(indice%4 == 1):\n",
        "            byte1.append(data)\n",
        "        elif(indice%4 == 2):\n",
        "            byte2.append(data)\n",
        "        else:\n",
        "            byte3.append(data)\n",
        "    print(\"byte0:\",*byte0)\n",
        "    print(\"=======\")\n",
        "    print(\"byte1:\",*byte1)\n",
        "    print(\"=======\")\n",
        "    print(\"byte2:\",*byte2)\n",
        "    print(\"=======\")\n",
        "    print(\"byte3:\",*byte3)\n",
        "    print(\"=======\")\n",
        "    return byte0,byte1,byte2,byte3\n",
        "\n",
        "def DecToBin_machine(num,accuracy):\n",
        "    integer = int(num)\n",
        "    flo = num - integer\n",
        "    integercom = '{:1b}'.format(integer)\n",
        "    tem = flo\n",
        "    flo_list = []\n",
        "    for i in range(accuracy):\n",
        "        tem *= 2\n",
        "        flo_list += str(int(tem))\n",
        "        tem -= int(tem)\n",
        "    flocom = flo_list\n",
        "    binary_value =  ''.join(flocom)\n",
        "    return binary_value\n",
        "\n",
        "def customize_dw_input_gen(layer_decimal):\n",
        "    '''Convert a layer output which is signed decimal in GPU to 8 bits hex with 2's complement in CPU and\n",
        "     make each byte display in different place, example of use : input_or_weight_gen(quantized_model.Conv[1].weights)'''\n",
        "    batch,channel,rows, cols = layer_decimal.shape\n",
        "    patches = []\n",
        "    for d in range(channel):\n",
        "        for i in range(0, rows, 3):\n",
        "            for j in range(0, cols, 3):\n",
        "                patch = layer_decimal[0,d,i:i+3, j:j+3]\n",
        "                patches.append(patch)\n",
        "    temp_data_in_np = []\n",
        "    for i , data in enumerate(patches):\n",
        "        data =data.cpu()\n",
        "        temp = np.array(data)\n",
        "        temp_data_in_np.append(temp)\n",
        "    temp_np = np.array(temp_data_in_np)\n",
        "    temp_np = temp_np.flatten()\n",
        "\n",
        "    byte0 = []\n",
        "    byte1 = []\n",
        "    byte2 = []\n",
        "    byte3 = []\n",
        "\n",
        "    # data_in_numpy = layer_decimal.cpu().numpy()\n",
        "    # data_test = data_in_numpy.flatten()\n",
        "    data_test =temp_np.astype('int32')\n",
        "    data_test = signed_dec2hex_matrix(data_test)\n",
        "    for indice,data in enumerate(data_test):\n",
        "        if(indice%3 == 0):\n",
        "            byte0.append(data)\n",
        "            byte3.append('00')\n",
        "        elif(indice%3 == 1):\n",
        "            byte1.append(data)\n",
        "        elif(indice%3 == 2):\n",
        "            byte2.append(data)\n",
        "        # else:\n",
        "        #     byte3.append(data)\n",
        "    print(\"byte0:\",*byte0)\n",
        "    print(\"=======\")\n",
        "    print(\"byte1:\",*byte1)\n",
        "    print(\"=======\")\n",
        "    print(\"byte2:\",*byte2)\n",
        "    print(\"=======\")\n",
        "    print(\"byte3:\",*byte3)\n",
        "    print(\"=======\")\n",
        "    return byte0,byte1,byte2,byte3\n",
        "\n",
        "def input_gen_with_0x_pw_ifmap(golden_layer_decimal):\n",
        "    '''Only for pw ifmap, because HW request pw ifmap need to begin from channel,then W, finally H.Convert a layer output which is signed decimal in GPU to 8 bits hex with 2's complement in CPU and\n",
        "     make it 4 element in a line, example of use : golden_gen(q_output_activation[\"Conv.3\"]) '''\n",
        "    golden_layer_decimal = golden_layer_decimal.permute(0,2,3,1)\n",
        "    golden = []\n",
        "    i=0\n",
        "    golden_in_numpy = golden_layer_decimal.cpu().numpy()\n",
        "    test = golden_in_numpy.flatten()\n",
        "    test =test.astype('int32')\n",
        "    golden.append([])\n",
        "    for j, data in enumerate(test):\n",
        "        if(j%4==0 ):\n",
        "            golden.append([])\n",
        "            i = i+1\n",
        "            golden[i].append(signed_dec2hex(data))\n",
        "        if(j%4!=0):\n",
        "            golden[i].append(signed_dec2hex(data))\n",
        "    golden.pop(0)\n",
        "    temp = '0x'\n",
        "    temp1 = ',\\\\'\n",
        "    for indice,data in enumerate(golden):\n",
        "        golden[indice].insert(0,temp)\n",
        "        golden[indice].append(temp1)\n",
        "\n",
        "    for indice,data in enumerate(golden):\n",
        "        print(*data,sep='')\n",
        "    return golden\n",
        "#golden_gen(q_output_activation[\"Conv.3\"])\n",
        "# torch.save(quantized_model,\"dw_customize_Toymodel.pt\")\n",
        "# print(signed_dec2hex(quantized_model.Conv[1].input_zero_point))\n",
        "# input_or_weight_gen(q_input_activation[\"Conv.1\"])\n",
        "# print(\"===\")\n",
        "# input_or_weight_gen(quantized_model.Conv[4].weights)\n",
        "\n",
        "# print(quantized_model.Conv[4].input_zero_point)\n",
        "\n",
        "# DeS = quantized_model.Conv[3].store_scale\n",
        "# print(DeS)\n",
        "# #print(DeS *8192) # 2**13\n",
        "# #print(\"deq_scale (shift 13):\",DecToBin_machine(quantized_model.Conv[1].,8))\n",
        "# print(\"req_scale (shift 6):\",)\n",
        "# print(\"output zero\",)\n",
        "# #binary_value = integercom + '.' + ''.join(flocom)\n",
        "# result = DecToBin_machine(DeS,8)\n",
        "# print(result)\n",
        "# # 0.1100111101011100\n",
        "#print(q_output_activation[\"Conv.2\"])\n",
        "#pw_input0, pw_input1, pw_input2, pw_input3 = input_or_weight_gen(q_input_activation[\"Conv.3\"] - quantized_model.Conv[3].input_zero_point)\n",
        "#pw_weight0, pw_weight, pw_weight2, pw_weight3 = input_or_weight_gen(quantized_model.Conv[2].weights - quantized_model.Conv[2].weight_zero_point)\n",
        "#golden = golden_gen(q_output_activation[\"Conv.2\"])\n",
        "#print(quantized_model.Conv[2].ReQ_scale *256)\n",
        "#test=quantized_model.Conv[2].ReQ_scale *256\n",
        "#print(DecToBin_machine(test ,8))\n",
        "#print(q_input_activation[\"Conv.3\"].shape)\n",
        "#print((input_activation[\"Conv.2\"] - quantized_model.Conv[2].input_zero_point).round().clamp(-(2**(8-1)), 2**(8-1)-1))\n",
        "#print(quantized_model.Conv[2].weights - quantized_model.Conv[2].weight_zero_point)\n",
        "#q_input_activation_pw = q_input_activation[\"Conv.2\"] .permute(0,2,3,1)\n",
        "#pw_input0, pw_input1, pw_input2, pw_input3 = input_or_weight_gen(q_input_activation_pw)\n",
        "#print(q_input_activation[\"Conv.2\"])\n",
        "#print(quantized_model.Conv[2].weights)\n",
        "#pw_input0, pw_input1, pw_input2, pw_input3 = input_or_weight_gen(q_input_activation_pw- quantized_model.Conv[2].input_zero_point)\n",
        "\n",
        "#######################################################################################################\n",
        "import sys\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "#input_gen_with_0x_pw_ifmap(q_input_activation[\"Conv.2\"])\n",
        "#input_or_weight_gen(quantized_model.Conv[2].weights)\n",
        "#output = torch.nn.functional.conv2d(input = q_input_activation[\"Conv.2\"] , weight = quantized_model.Conv[2].weights , stride=1,padding=0,groups=1)\n",
        "#print(output)\n",
        "#print(q_input_activation[\"Conv.2\"].numpy())\n",
        "output = torch.nn.functional.conv2d(input = q_input_activation[\"Conv.2\"]  , weight = quantized_model.Conv[2].weights, stride=1,padding=0,groups=1)\n",
        "# print(output.numpy())\n",
        "# print(output.int().numpy())\n",
        "print(quantized_model.Conv[2].ReQ_scale *256)\n",
        "test = DecToBin_machine(quantized_model.Conv[2].ReQ_scale*256,8)\n",
        "\n",
        "output = quantized_model.Conv[2].ReQ_scale * output\n",
        "#print(output.numpy())\n",
        "#output += quantized_model.Conv[2].output_zero_point\n",
        "\n",
        "#clamp and round\n",
        "output = output.round().clamp(-(2**(8-1)), 2**(8-1)-1)\n",
        "#print(quantized_model.Conv[2].output_zero_point)\n",
        "#print(output.numpy())\n",
        "#golden = golden_gen(output)\n",
        "\n",
        "#######################################################################################################\n",
        "y = torch.flatten(output)\n",
        "y = y.cpu()\n",
        "y = torch.flatten(y)\n",
        "y = y.detach()\n",
        "y = y.numpy()\n",
        "print(y.shape)\n",
        "\n",
        "plt.hist(y, bins='auto',density=False)\n",
        "#print(q_input_activation[\"Conv.2\"])\n",
        "\n",
        "#print(q_output_activation[\"Conv.2\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "4343433e\n",
            "41434338\n",
            "430a4343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43414043\n",
            "19c23243\n",
            "43434343\n",
            "438c4343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43414343\n",
            "bc819a43\n",
            "43434321\n",
            "b4a04343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "433c43f1\n",
            "808b8284\n",
            "82838182\n",
            "83814343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "40433281\n",
            "80808384\n",
            "83838482\n",
            "82814343\n",
            "43434343\n",
            "43434143\n",
            "4041433e\n",
            "43439394\n",
            "a0818382\n",
            "82838381\n",
            "82833243\n",
            "43434343\n",
            "41434343\n",
            "43433e43\n",
            "43ba81b9\n",
            "b3828280\n",
            "82848481\n",
            "8384fb43\n",
            "43434343\n",
            "4343403c\n",
            "41434343\n",
            "ad819a9b\n",
            "9a838181\n",
            "82838381\n",
            "83848c43\n",
            "43434040\n",
            "41404343\n",
            "43431b9d\n",
            "8fab988f\n",
            "81828182\n",
            "82828381\n",
            "82828443\n",
            "3e434343\n",
            "43434322\n",
            "f1b68f98\n",
            "a5938081\n",
            "81828384\n",
            "82828281\n",
            "81828301\n",
            "43431ff1\n",
            "dfcec08e\n",
            "80869895\n",
            "8e808381\n",
            "81818381\n",
            "82838182\n",
            "848385e5\n",
            "43dab3b9\n",
            "98949894\n",
            "93808181\n",
            "81828082\n",
            "82818283\n",
            "83838181\n",
            "828386eb\n",
            "d78480a3\n",
            "ada9b3ae\n",
            "ada69da0\n",
            "8c8b8082\n",
            "82838585\n",
            "86868685\n",
            "8685850d\n",
            "2a828485\n",
            "85858482\n",
            "818b8280\n",
            "82858687\n",
            "878b8784\n",
            "8a8a8a8a\n",
            "8a8887f7\n",
            "43434330\n",
            "dca08385\n",
            "86878787\n",
            "878582c5\n",
            "36434343\n",
            "84878584\n",
            "83838232\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "43434343\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80838080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "8080848a\n",
            "86888286\n",
            "89838080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808082\n",
            "8180878a\n",
            "87898b85\n",
            "85848080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80828986\n",
            "86888983\n",
            "86878080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808380\n",
            "80868581\n",
            "85898a83\n",
            "87898080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80828080\n",
            "80878284\n",
            "85878984\n",
            "87898080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "82868186\n",
            "86868783\n",
            "84868b80\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808081\n",
            "83868889\n",
            "86858683\n",
            "82858880\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808083\n",
            "81828783\n",
            "86878486\n",
            "8a878d80\n",
            "80808080\n",
            "80808080\n",
            "80808282\n",
            "83808085\n",
            "86838480\n",
            "87878482\n",
            "86878f80\n",
            "80898080\n",
            "80808080\n",
            "80808080\n",
            "80808085\n",
            "86898d8d\n",
            "8f8f8f8d\n",
            "8f8d8c80\n",
            "8080898d\n",
            "8d8c8986\n",
            "82808080\n",
            "848c8f92\n",
            "919b928b\n",
            "999b9a9a\n",
            "99949080\n",
            "80808080\n",
            "8080888c\n",
            "8f929292\n",
            "918d8580\n",
            "80808080\n",
            "8b918d8a\n",
            "87878580\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c38\n",
            "3b3c3c32\n",
            "3c053c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3b3a3c\n",
            "14c02c3c\n",
            "3c3c3c3c\n",
            "3c8c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3b3c3c\n",
            "ba80993c\n",
            "3c3c3c1c\n",
            "b29f3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c363cee\n",
            "808a8080\n",
            "80808080\n",
            "80803c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3a3c2c80\n",
            "80808080\n",
            "80808080\n",
            "80803c3c\n",
            "3c3c3c3c\n",
            "3c3c3b3c\n",
            "3a3b3c38\n",
            "3c3c9293\n",
            "9f808080\n",
            "80808080\n",
            "80802c3c\n",
            "3c3c3c3c\n",
            "3b3c3c3c\n",
            "3c3c383c\n",
            "3cb880b7\n",
            "b1808080\n",
            "80808080\n",
            "8080f73c\n",
            "3c3c3c3c\n",
            "3c3c3a36\n",
            "3b3c3c3c\n",
            "ab80999a\n",
            "99808080\n",
            "80808080\n",
            "80808c3c\n",
            "3c3c3a3a\n",
            "3b3a3c3c\n",
            "3c3c169c\n",
            "8fa9988f\n",
            "80808080\n",
            "80808080\n",
            "8080803c\n",
            "383c3c3c\n",
            "3c3c3c1d\n",
            "eeb48f98\n",
            "a4928080\n",
            "80808080\n",
            "80808080\n",
            "808080fd\n",
            "3c3c1aee\n",
            "dcccbe8d\n",
            "80869895\n",
            "8d808380\n",
            "80808080\n",
            "80808080\n",
            "808080e2\n",
            "3cd8b1b7\n",
            "98939893\n",
            "92808080\n",
            "80828080\n",
            "80808083\n",
            "80808080\n",
            "808080e8\n",
            "d48080a2\n",
            "aba8b1ac\n",
            "aba59c9f\n",
            "8c8a8080\n",
            "80808080\n",
            "80808080\n",
            "80808008\n",
            "25828080\n",
            "80808080\n",
            "808a8280\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "808080f3\n",
            "3c3c3c2a\n",
            "d99f8080\n",
            "80808080\n",
            "808080c3\n",
            "313c3c3c\n",
            "80808080\n",
            "8080802c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "3c3c3c3c\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0de\n",
            "e0e0e0db\n",
            "e0c4e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0dfe0\n",
            "cca1d8e0\n",
            "e0e0e0e0\n",
            "e086e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "9e858de0\n",
            "e0e0e0d0\n",
            "9a90e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0dde0b8\n",
            "8185868f\n",
            "8a8c8289\n",
            "8d84e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "dfe0d883\n",
            "81808b8f\n",
            "8a8d9087\n",
            "8885e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "dfe0e0de\n",
            "e0e0898a\n",
            "90838d88\n",
            "898c8d85\n",
            "8a8ad8e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0dee0\n",
            "e09d849c\n",
            "99888781\n",
            "888d8e85\n",
            "8a8dbde0\n",
            "e0e0e0e0\n",
            "e0e0dfdd\n",
            "e0e0e0e0\n",
            "96838d8e\n",
            "8d8b8285\n",
            "878a8d85\n",
            "8a8d86e0\n",
            "e0e0dfdf\n",
            "e0dfe0e0\n",
            "e0e0cd8e\n",
            "87958c87\n",
            "83898289\n",
            "89898b85\n",
            "868990e0\n",
            "dee0e0e0\n",
            "e0e0e0d0\n",
            "b89a878c\n",
            "92898182\n",
            "85898c8e\n",
            "89888985\n",
            "84878cc0\n",
            "e0e0cfb8\n",
            "afa7a087\n",
            "80838c8a\n",
            "87808184\n",
            "82838b84\n",
            "898b8589\n",
            "8e8b94b2\n",
            "e0ad999c\n",
            "8c8a8c8a\n",
            "89808283\n",
            "85818088\n",
            "89858781\n",
            "8b8b8584\n",
            "888b96b5\n",
            "ab8d8191\n",
            "96949997\n",
            "96938e90\n",
            "86858187\n",
            "898d9494\n",
            "96969693\n",
            "969492c6\n",
            "d4818e93\n",
            "93928e88\n",
            "82858180\n",
            "8692969a\n",
            "99a99a90\n",
            "a5a8a7a7\n",
            "a69d99bb\n",
            "e0e0e0d7\n",
            "ae908c92\n",
            "979a9b9a\n",
            "999487a2\n",
            "dae0e0e0\n",
            "9099938f\n",
            "8b8a88d8\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "e0e0e0e0\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "2222221e\n",
            "20222219\n",
            "22f32222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22201f22\n",
            "ffb71422\n",
            "22222222\n",
            "228a2222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22202222\n",
            "b2809622\n",
            "22222206\n",
            "ab9b2222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "221d22de\n",
            "80898080\n",
            "80808080\n",
            "80802222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "1f221480\n",
            "80808080\n",
            "80808080\n",
            "80802222\n",
            "22222222\n",
            "22222022\n",
            "1f20221e\n",
            "22228f91\n",
            "9b808080\n",
            "80808080\n",
            "80801422\n",
            "22222222\n",
            "20222222\n",
            "22221e22\n",
            "22b080af\n",
            "aa808080\n",
            "80808080\n",
            "8080e622\n",
            "22222222\n",
            "22221f1d\n",
            "20222222\n",
            "a5809697\n",
            "96808080\n",
            "80808080\n",
            "80808a22\n",
            "22221f1f\n",
            "201f2222\n",
            "22220198\n",
            "8da4948d\n",
            "80808080\n",
            "80808080\n",
            "80808022\n",
            "1e222222\n",
            "22222207\n",
            "dead8d94\n",
            "9f8f8080\n",
            "80808080\n",
            "80808080\n",
            "808080eb\n",
            "222204de\n",
            "cfc1b68b\n",
            "80859492\n",
            "8b808380\n",
            "80808080\n",
            "80808080\n",
            "808080d4\n",
            "22cbaaaf\n",
            "94919491\n",
            "8f808080\n",
            "80818080\n",
            "80808083\n",
            "80808080\n",
            "808080d9\n",
            "c880809d\n",
            "a5a2aaa6\n",
            "a5a0989b\n",
            "8a898080\n",
            "80808080\n",
            "80808080\n",
            "808080f5\n",
            "0d818080\n",
            "80808080\n",
            "80898180\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "808080e3\n",
            "22222212\n",
            "cc9b8080\n",
            "80808080\n",
            "808080b9\n",
            "17222222\n",
            "80808080\n",
            "80808014\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "22222222\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e78\n",
            "7c7e7e70\n",
            "7e347e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7c7a7e\n",
            "48d6687e\n",
            "7e7e7e7e\n",
            "7e907e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7c7e7e\n",
            "ce80a27e\n",
            "7e7e7e52\n",
            "c4aa7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e767e14\n",
            "808e8080\n",
            "80808080\n",
            "80807e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7a7e6880\n",
            "80808080\n",
            "80808080\n",
            "80807e7e\n",
            "7e7e7e7e\n",
            "7e7e7c7e\n",
            "7a7c7e78\n",
            "7e7e989a\n",
            "aa808080\n",
            "80808080\n",
            "8080687e\n",
            "7e7e7e7e\n",
            "7c7e7e7e\n",
            "7e7e787e\n",
            "7ecc80ca\n",
            "c2808080\n",
            "80808080\n",
            "8080207e\n",
            "7e7e7e7e\n",
            "7e7e7a76\n",
            "7c7e7e7e\n",
            "ba80a2a4\n",
            "a2808080\n",
            "80808080\n",
            "8080907e\n",
            "7e7e7a7a\n",
            "7c7a7e7e\n",
            "7e7e4aa6\n",
            "94b8a094\n",
            "80808080\n",
            "80808080\n",
            "8080807e\n",
            "787e7e7e\n",
            "7e7e7e54\n",
            "14c694a0\n",
            "b0988080\n",
            "80808080\n",
            "80808080\n",
            "80808028\n",
            "7e7e5014\n",
            "fce6d492\n",
            "8088a09c\n",
            "92808480\n",
            "80808080\n",
            "80808080\n",
            "80808004\n",
            "7ef6c2ca\n",
            "a09aa09a\n",
            "98808080\n",
            "80828080\n",
            "80808084\n",
            "80808080\n",
            "8080800c\n",
            "f28080ae\n",
            "bab6c2bc\n",
            "bab2a6aa\n",
            "908e8080\n",
            "80808080\n",
            "80808080\n",
            "80808038\n",
            "5e828080\n",
            "80808080\n",
            "808e8280\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "8080801c\n",
            "7e7e7e66\n",
            "f8aa8080\n",
            "80808080\n",
            "808080da\n",
            "6e7e7e7e\n",
            "80808080\n",
            "80808068\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "7e7e7e7e\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "80808080\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686863\n",
            "6768685b\n",
            "68256868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68676568\n",
            "37cf5468\n",
            "68686868\n",
            "688f6868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68676868\n",
            "c7849f68\n",
            "68686840\n",
            "bea76868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68616808\n",
            "818d858d\n",
            "888b8287\n",
            "8b846868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "65685483\n",
            "8180898d\n",
            "898b8e86\n",
            "87856868\n",
            "68686868\n",
            "68686768\n",
            "65676863\n",
            "68689698\n",
            "a7838b87\n",
            "888a8b84\n",
            "88885468\n",
            "68686868\n",
            "67686868\n",
            "68686368\n",
            "68c683c4\n",
            "bc878681\n",
            "878b8c84\n",
            "898b1268\n",
            "68686868\n",
            "68686561\n",
            "67686868\n",
            "b5839fa1\n",
            "9f898285\n",
            "86898b85\n",
            "888b8f68\n",
            "68686565\n",
            "67656868\n",
            "686839a3\n",
            "92b39d92\n",
            "83888287\n",
            "87888984\n",
            "85888e68\n",
            "63686868\n",
            "68686842\n",
            "08c0929d\n",
            "ac968182\n",
            "84878a8c\n",
            "87878784\n",
            "83868a1a\n",
            "68683e08\n",
            "f1ddcd90\n",
            "80889d9a\n",
            "90808483\n",
            "82838984\n",
            "88898588\n",
            "8c8991f9\n",
            "68ecbcc4\n",
            "9d989d98\n",
            "96808283\n",
            "84828087\n",
            "87848684\n",
            "89898583\n",
            "87899300\n",
            "e88b81aa\n",
            "b5b1bcb7\n",
            "b5aea3a7\n",
            "8f8d8186\n",
            "888b9191\n",
            "93939390\n",
            "93918f28\n",
            "4b828c90\n",
            "908f8c87\n",
            "828d8280\n",
            "85909396\n",
            "96a3968e\n",
            "a0a2a2a2\n",
            "a099950e\n",
            "68686852\n",
            "eea78a90\n",
            "94969796\n",
            "969186d2\n",
            "5a686868\n",
            "8e96908d\n",
            "89888754\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n",
            "68686868\n"
          ]
        }
      ],
      "source": [
        "# p2d = (1,1,1,1)\n",
        "# test = golden_layer_decimal = torch.nn.functional.pad(q_input_activation[\"Conv.4\"],p2d,\"constant\",0)\n",
        "# customize_dw_input_gen(test)\n",
        "# input_or_weight_gen(quantized_model.Conv[4].weights)\n",
        "# golden_gen(q_output_activation[\"Conv.2\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BMccqTL6URaZ"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRMXzNeCgDuq",
        "outputId": "0fa65b9f-3a60-41e0-a935-a601a8db0484"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Error: \n",
            " Accuracy: 83.2%, Avg loss: 0.000034 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_loop(test_loader, FP32_model, loss_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knTzO1mbheBe",
        "outputId": "411fc256-b7ea-4757-9f75-6acaae605324"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Error: \n",
            " Accuracy: 83.0%, Avg loss: 0.000000 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_loop(test_loader, quantized_model, loss_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['Conv.0', 'Conv.1', 'Conv.2', 'Conv.3', 'Conv.4', 'Conv.5', 'Conv.6.avg_pool', 'Conv.6.fc.0', 'Conv.6.fc.1', 'Conv.6.fc.2', 'Conv.6.fc.3', 'Conv.7', 'Conv.8', 'backbone.0', 'backbone.1', 'backbone.2', 'backbone.3', 'backbone.4'])\n",
            "dict_keys(['Conv.0', 'Conv.1', 'Conv.2', 'Conv.3', 'Conv.4.avg_pool', 'Conv.4.fc.0', 'Conv.4.fc.1', 'Conv.4', 'Conv.5', 'backbone.0', 'backbone.1', 'backbone.2'])\n"
          ]
        }
      ],
      "source": [
        "print(output_activation.keys())\n",
        "print(q_output_activation.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(200704,)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(array([7.5951e+04, 8.3700e+03, 6.6440e+03, 7.1500e+03, 4.7330e+03,\n",
              "        2.4850e+03, 1.2930e+03, 9.4700e+02, 9.7200e+02, 9.5900e+02,\n",
              "        1.0030e+03, 1.0340e+03, 9.3900e+02, 9.6800e+02, 1.0750e+03,\n",
              "        1.3371e+04, 6.6700e+02, 6.2700e+02, 6.4900e+02, 6.2500e+02,\n",
              "        5.8000e+02, 6.4100e+02, 4.8200e+02, 4.9900e+02, 6.2600e+02,\n",
              "        1.3242e+04, 3.7400e+02, 3.7200e+02, 4.7300e+02, 1.3223e+04,\n",
              "        1.2961e+04, 1.3600e+02, 1.5100e+02, 1.3800e+02, 1.7600e+02,\n",
              "        2.3200e+02, 1.2867e+04, 6.5000e+01, 1.2300e+02, 1.2881e+04]),\n",
              " array([0.        , 0.03509332, 0.07018664, 0.10527997, 0.14037329,\n",
              "        0.17546661, 0.21055993, 0.24565326, 0.28074658, 0.31583989,\n",
              "        0.35093322, 0.38602656, 0.42111987, 0.45621318, 0.49130651,\n",
              "        0.52639985, 0.56149316, 0.59658647, 0.63167977, 0.66677314,\n",
              "        0.70186645, 0.73695976, 0.77205312, 0.80714643, 0.84223974,\n",
              "        0.87733305, 0.91242635, 0.94751972, 0.98261303, 1.01770639,\n",
              "        1.0527997 , 1.08789301, 1.12298632, 1.15807962, 1.19317293,\n",
              "        1.22826624, 1.26335955, 1.29845297, 1.33354628, 1.36863959,\n",
              "        1.4037329 ]),\n",
              " <BarContainer object of 40 artists>)"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGdCAYAAADwjmIIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxbElEQVR4nO3de1xVdb7/8TcX98bbxrwAcsS0rJQyHVFxdx2L3BV18qSl5jHGMI8OehJOKpY/UOukD7tpqXm6THgeJ/Iyj/KUKEaY2iRpoZxRE6ZGHZyxjXYStjEJCuv3x3mwxp3YuJGLfH09H4/1eMT6ftZan+9SN+8Way2CLMuyBAAAYJjglm4AAACgKRByAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGCm3pBlpSbW2tjh49qo4dOyooKKil2wEAABfAsiydPHlS0dHRCg4+//WayzrkHD16VDExMS3dBgAAaIAjR46oR48e5x2/rENOx44dJf3fSXK5XC3cDQAAuBA+n08xMTH29/HzuaxDTt2PqFwuFyEHAIBW5u/dasKNxwAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGCm3pBkzVKz3ngmsPL0pswk4AALg8cSUHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgpIBCTq9evRQUFHTOkpKSIkk6deqUUlJS1KVLF3Xo0EGjRo1SWVmZ3z5KS0uVmJiodu3aKSIiQjNnztSZM2f8arZu3apBgwbJ6XSqT58+ysrKOqeX5cuXq1evXgoLC1N8fLx27doV4NQBAIDJAgo5X3zxhb799lt7ycvLkyQ99NBDkqTU1FR9+OGHWrdunbZt26ajR4/qwQcftLevqalRYmKiqqurtWPHDq1atUpZWVnKyMiwaw4dOqTExEQNHz5cRUVFmjFjhiZNmqTNmzfbNWvWrFFaWpoyMzO1e/duDRgwQB6PR8eOHbuokwEAAMwRZFmW1dCNZ8yYoQ0bNujrr7+Wz+dTt27dlJ2drdGjR0uSiouL1a9fPxUUFGjYsGHatGmT7rvvPh09elSRkZGSpJUrV2r27Nk6fvy4HA6HZs+erZycHO3bt88+ztixY1VeXq7c3FxJUnx8vIYMGaJly5ZJkmpraxUTE6Pp06crPT39gvv3+XwKDw9XRUWFXC5XQ09DvXql51xw7eFFiY16bAAATHah378bfE9OdXW1/uu//kuPPfaYgoKCVFhYqNOnTyshIcGu6du3r3r27KmCggJJUkFBgfr3728HHEnyeDzy+Xzav3+/XXP2Pupq6vZRXV2twsJCv5rg4GAlJCTYNedTVVUln8/ntwAAADM1OOSsX79e5eXl+tWvfiVJ8nq9cjgc6tSpk19dZGSkvF6vXXN2wKkbrxv7uRqfz6cff/xR3333nWpqauqtqdvH+SxcuFDh4eH2EhMTE9CcAQBA69HgkPPWW2/pnnvuUXR0dGP206TmzJmjiooKezly5EhLtwQAAJpIaEM2+tOf/qSPP/5Y7733nr0uKipK1dXVKi8v97uaU1ZWpqioKLvmp09B1T19dXbNT5/IKisrk8vlUtu2bRUSEqKQkJB6a+r2cT5Op1NOpzOwyQIAgFapQVdy3n77bUVERCgx8W83zMbFxalNmzbKz8+315WUlKi0tFRut1uS5Ha7tXfvXr+noPLy8uRyuRQbG2vXnL2Pupq6fTgcDsXFxfnV1NbWKj8/364BAAAI+EpObW2t3n77bSUlJSk09G+bh4eHKzk5WWlpaercubNcLpemT58ut9utYcOGSZJGjBih2NhYTZgwQYsXL5bX69XcuXOVkpJiX2GZMmWKli1bplmzZumxxx7Tli1btHbtWuXk/O1ppbS0NCUlJWnw4MEaOnSolixZosrKSk2cOPFizwcAADBEwCHn448/VmlpqR577LFzxl5++WUFBwdr1KhRqqqqksfj0YoVK+zxkJAQbdiwQVOnTpXb7Vb79u2VlJSkBQsW2DW9e/dWTk6OUlNTtXTpUvXo0UNvvvmmPB6PXTNmzBgdP35cGRkZ8nq9GjhwoHJzc8+5GRkAAFy+Luo9Oa0d78kBAKD1afL35AAAAFzKCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYKSAQ85f/vIX/fM//7O6dOmitm3bqn///vryyy/tccuylJGRoe7du6tt27ZKSEjQ119/7beP77//XuPHj5fL5VKnTp2UnJysH374wa/m97//vW699VaFhYUpJiZGixcvPqeXdevWqW/fvgoLC1P//v21cePGQKcDAAAMFVDIOXHihG6++Wa1adNGmzZt0ldffaUXX3xRV1xxhV2zePFivfLKK1q5cqV27typ9u3by+Px6NSpU3bN+PHjtX//fuXl5WnDhg3avn27Jk+ebI/7fD6NGDFCV155pQoLC/X8889r3rx5ev311+2aHTt2aNy4cUpOTtaePXs0cuRIjRw5Uvv27buY8wEAAAwRZFmWdaHF6enp+uyzz/Tpp5/WO25ZlqKjo/Vv//ZvevLJJyVJFRUVioyMVFZWlsaOHasDBw4oNjZWX3zxhQYPHixJys3N1b333qs///nPio6O1muvvaann35aXq9XDofDPvb69etVXFwsSRozZowqKyu1YcMG+/jDhg3TwIEDtXLlyguaj8/nU3h4uCoqKuRyuS70NFyQXuk5F1x7eFFiox4bAACTXej374Cu5HzwwQcaPHiwHnroIUVEROgXv/iF3njjDXv80KFD8nq9SkhIsNeFh4crPj5eBQUFkqSCggJ16tTJDjiSlJCQoODgYO3cudOuue222+yAI0kej0clJSU6ceKEXXP2cepq6o5Tn6qqKvl8Pr8FAACYKaCQc/DgQb322mu65pprtHnzZk2dOlX/+q//qlWrVkmSvF6vJCkyMtJvu8jISHvM6/UqIiLCbzw0NFSdO3f2q6lvH2cf43w1deP1WbhwocLDw+0lJiYmkOkDAIBWJKCQU1tbq0GDBum5557TL37xC02ePFmPP/74Bf94qKXNmTNHFRUV9nLkyJGWbgkAADSRgEJO9+7dFRsb67euX79+Ki0tlSRFRUVJksrKyvxqysrK7LGoqCgdO3bMb/zMmTP6/vvv/Wrq28fZxzhfTd14fZxOp1wul98CAADMFFDIufnmm1VSUuK37g9/+IOuvPJKSVLv3r0VFRWl/Px8e9zn82nnzp1yu92SJLfbrfLychUWFto1W7ZsUW1treLj4+2a7du36/Tp03ZNXl6errvuOvtJLrfb7Xecupq64wAAgMtbQCEnNTVVn3/+uZ577jl98803ys7O1uuvv66UlBRJUlBQkGbMmKFnn31WH3zwgfbu3atHH31U0dHRGjlypKT/u/Jz99136/HHH9euXbv02Wefadq0aRo7dqyio6MlSY888ogcDoeSk5O1f/9+rVmzRkuXLlVaWprdyxNPPKHc3Fy9+OKLKi4u1rx58/Tll19q2rRpjXRqAABAaxYaSPGQIUP0/vvva86cOVqwYIF69+6tJUuWaPz48XbNrFmzVFlZqcmTJ6u8vFy33HKLcnNzFRYWZte88847mjZtmu68804FBwdr1KhReuWVV+zx8PBwffTRR0pJSVFcXJy6du2qjIwMv3fp3HTTTcrOztbcuXP11FNP6ZprrtH69et1ww03XMz5AAAAhgjoPTmm4T05AAC0Pk3ynhwAAIDWgpADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYKKOTMmzdPQUFBfkvfvn3t8VOnTiklJUVdunRRhw4dNGrUKJWVlfnto7S0VImJiWrXrp0iIiI0c+ZMnTlzxq9m69atGjRokJxOp/r06aOsrKxzelm+fLl69eqlsLAwxcfHa9euXYFMBQAAGC7gKznXX3+9vv32W3v53e9+Z4+lpqbqww8/1Lp167Rt2zYdPXpUDz74oD1eU1OjxMREVVdXa8eOHVq1apWysrKUkZFh1xw6dEiJiYkaPny4ioqKNGPGDE2aNEmbN2+2a9asWaO0tDRlZmZq9+7dGjBggDwej44dO9bQ8wAAAAwTZFmWdaHF8+bN0/r161VUVHTOWEVFhbp166bs7GyNHj1aklRcXKx+/fqpoKBAw4YN06ZNm3Tffffp6NGjioyMlCStXLlSs2fP1vHjx+VwODR79mzl5ORo37599r7Hjh2r8vJy5ebmSpLi4+M1ZMgQLVu2TJJUW1urmJgYTZ8+Xenp6Rc8eZ/Pp/DwcFVUVMjlcl3wdheiV3rOBdceXpTYqMcGAMBkF/r9O+ArOV9//bWio6N11VVXafz48SotLZUkFRYW6vTp00pISLBr+/btq549e6qgoECSVFBQoP79+9sBR5I8Ho98Pp/2799v15y9j7qaun1UV1ersLDQryY4OFgJCQl2DQAAQGggxfHx8crKytJ1112nb7/9VvPnz9ett96qffv2yev1yuFwqFOnTn7bREZGyuv1SpK8Xq9fwKkbrxv7uRqfz6cff/xRJ06cUE1NTb01xcXFP9t/VVWVqqqq7K99Pt+FTx4AALQqAYWce+65x/7vG2+8UfHx8bryyiu1du1atW3bttGba2wLFy7U/PnzW7oNAADQDC7qEfJOnTrp2muv1TfffKOoqChVV1ervLzcr6asrExRUVGSpKioqHOetqr7+u/VuFwutW3bVl27dlVISEi9NXX7OJ85c+aooqLCXo4cORLwnAEAQOtwUSHnhx9+0B//+Ed1795dcXFxatOmjfLz8+3xkpISlZaWyu12S5Lcbrf27t3r9xRUXl6eXC6XYmNj7Zqz91FXU7cPh8OhuLg4v5ra2lrl5+fbNefjdDrlcrn8FgAAYKaAQs6TTz6pbdu26fDhw9qxY4f+6Z/+SSEhIRo3bpzCw8OVnJystLQ0ffLJJyosLNTEiRPldrs1bNgwSdKIESMUGxurCRMm6H/+53+0efNmzZ07VykpKXI6nZKkKVOm6ODBg5o1a5aKi4u1YsUKrV27VqmpqXYfaWlpeuONN7Rq1SodOHBAU6dOVWVlpSZOnNiIpwYAALRmAd2T8+c//1njxo3T//7v/6pbt2665ZZb9Pnnn6tbt26SpJdfflnBwcEaNWqUqqqq5PF4tGLFCnv7kJAQbdiwQVOnTpXb7Vb79u2VlJSkBQsW2DW9e/dWTk6OUlNTtXTpUvXo0UNvvvmmPB6PXTNmzBgdP35cGRkZ8nq9GjhwoHJzc8+5GRkAAFy+AnpPjml4Tw4AAK1Pk70nBwAAoDUg5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASBcVchYtWqSgoCDNmDHDXnfq1CmlpKSoS5cu6tChg0aNGqWysjK/7UpLS5WYmKh27dopIiJCM2fO1JkzZ/xqtm7dqkGDBsnpdKpPnz7Kyso65/jLly9Xr169FBYWpvj4eO3atetipgMAAAzS4JDzxRdf6D/+4z904403+q1PTU3Vhx9+qHXr1mnbtm06evSoHnzwQXu8pqZGiYmJqq6u1o4dO7Rq1SplZWUpIyPDrjl06JASExM1fPhwFRUVacaMGZo0aZI2b95s16xZs0ZpaWnKzMzU7t27NWDAAHk8Hh07dqyhUwIAAAYJsizLCnSjH374QYMGDdKKFSv07LPPauDAgVqyZIkqKirUrVs3ZWdna/To0ZKk4uJi9evXTwUFBRo2bJg2bdqk++67T0ePHlVkZKQkaeXKlZo9e7aOHz8uh8Oh2bNnKycnR/v27bOPOXbsWJWXlys3N1eSFB8fryFDhmjZsmWSpNraWsXExGj69OlKT0+/oHn4fD6Fh4eroqJCLpcr0NPws3ql51xw7eFFiY16bAAATHah378bdCUnJSVFiYmJSkhI8FtfWFio06dP+63v27evevbsqYKCAklSQUGB+vfvbwccSfJ4PPL5fNq/f79d89N9ezweex/V1dUqLCz0qwkODlZCQoJdU5+qqir5fD6/BQAAmCk00A1Wr16t3bt364svvjhnzOv1yuFwqFOnTn7rIyMj5fV67ZqzA07deN3Yz9X4fD79+OOPOnHihGpqauqtKS4uPm/vCxcu1Pz58y9sogAAoFUL6ErOkSNH9MQTT+idd95RWFhYU/XUZObMmaOKigp7OXLkSEu3BAAAmkhAIaewsFDHjh3ToEGDFBoaqtDQUG3btk2vvPKKQkNDFRkZqerqapWXl/ttV1ZWpqioKElSVFTUOU9b1X3992pcLpfatm2rrl27KiQkpN6aun3Ux+l0yuVy+S0AAMBMAYWcO++8U3v37lVRUZG9DB48WOPHj7f/u02bNsrPz7e3KSkpUWlpqdxutyTJ7XZr7969fk9B5eXlyeVyKTY21q45ex91NXX7cDgciouL86upra1Vfn6+XQMAAC5vAd2T07FjR91www1+69q3b68uXbrY65OTk5WWlqbOnTvL5XJp+vTpcrvdGjZsmCRpxIgRio2N1YQJE7R48WJ5vV7NnTtXKSkpcjqdkqQpU6Zo2bJlmjVrlh577DFt2bJFa9euVU7O355YSktLU1JSkgYPHqyhQ4dqyZIlqqys1MSJEy/qhAAAADMEfOPx3/Pyyy8rODhYo0aNUlVVlTwej1asWGGPh4SEaMOGDZo6darcbrfat2+vpKQkLViwwK7p3bu3cnJylJqaqqVLl6pHjx5688035fF47JoxY8bo+PHjysjIkNfr1cCBA5Wbm3vOzcgAAODy1KD35JiC9+QAAND6NOl7cgAAAC51hBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMFJAIee1117TjTfeKJfLJZfLJbfbrU2bNtnjp06dUkpKirp06aIOHTpo1KhRKisr89tHaWmpEhMT1a5dO0VERGjmzJk6c+aMX83WrVs1aNAgOZ1O9enTR1lZWef0snz5cvXq1UthYWGKj4/Xrl27ApkKAAAwXEAhp0ePHlq0aJEKCwv15Zdf6o477tADDzyg/fv3S5JSU1P14Ycfat26ddq2bZuOHj2qBx980N6+pqZGiYmJqq6u1o4dO7Rq1SplZWUpIyPDrjl06JASExM1fPhwFRUVacaMGZo0aZI2b95s16xZs0ZpaWnKzMzU7t27NWDAAHk8Hh07duxizwcAADBEkGVZ1sXsoHPnznr++ec1evRodevWTdnZ2Ro9erQkqbi4WP369VNBQYGGDRumTZs26b777tPRo0cVGRkpSVq5cqVmz56t48ePy+FwaPbs2crJydG+ffvsY4wdO1bl5eXKzc2VJMXHx2vIkCFatmyZJKm2tlYxMTGaPn260tPTL7h3n8+n8PBwVVRUyOVyXcxpOEev9JwLrj28KLFRjw0AgMku9Pt3g+/Jqamp0erVq1VZWSm3263CwkKdPn1aCQkJdk3fvn3Vs2dPFRQUSJIKCgrUv39/O+BIksfjkc/ns68GFRQU+O2jrqZuH9XV1SosLPSrCQ4OVkJCgl1zPlVVVfL5fH4LAAAwU8AhZ+/everQoYOcTqemTJmi999/X7GxsfJ6vXI4HOrUqZNffWRkpLxeryTJ6/X6BZy68bqxn6vx+Xz68ccf9d1336mmpqbemrp9nM/ChQsVHh5uLzExMYFOHwAAtBIBh5zrrrtORUVF2rlzp6ZOnaqkpCR99dVXTdFbo5szZ44qKirs5ciRIy3dEgAAaCKhgW7gcDjUp08fSVJcXJy++OILLV26VGPGjFF1dbXKy8v9ruaUlZUpKipKkhQVFXXOU1B1T1+dXfPTJ7LKysrkcrnUtm1bhYSEKCQkpN6aun2cj9PplNPpDHTKAACgFbro9+TU1taqqqpKcXFxatOmjfLz8+2xkpISlZaWyu12S5Lcbrf27t3r9xRUXl6eXC6XYmNj7Zqz91FXU7cPh8OhuLg4v5ra2lrl5+fbNQAAAAFdyZkzZ47uuece9ezZUydPnlR2dra2bt2qzZs3Kzw8XMnJyUpLS1Pnzp3lcrk0ffp0ud1uDRs2TJI0YsQIxcbGasKECVq8eLG8Xq/mzp2rlJQU+wrLlClTtGzZMs2aNUuPPfaYtmzZorVr1yon529PK6WlpSkpKUmDBw/W0KFDtWTJElVWVmrixImNeGoAAEBrFlDIOXbsmB599FF9++23Cg8P14033qjNmzfrrrvukiS9/PLLCg4O1qhRo1RVVSWPx6MVK1bY24eEhGjDhg2aOnWq3G632rdvr6SkJC1YsMCu6d27t3JycpSamqqlS5eqR48eevPNN+XxeOyaMWPG6Pjx48rIyJDX69XAgQOVm5t7zs3IAADg8nXR78lpzXhPDgAArU+TvycHAADgUkbIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjBRRyFi5cqCFDhqhjx46KiIjQyJEjVVJS4ldz6tQppaSkqEuXLurQoYNGjRqlsrIyv5rS0lIlJiaqXbt2ioiI0MyZM3XmzBm/mq1bt2rQoEFyOp3q06ePsrKyzuln+fLl6tWrl8LCwhQfH69du3YFMh0AAGCwgELOtm3blJKSos8//1x5eXk6ffq0RowYocrKSrsmNTVVH374odatW6dt27bp6NGjevDBB+3xmpoaJSYmqrq6Wjt27NCqVauUlZWljIwMu+bQoUNKTEzU8OHDVVRUpBkzZmjSpEnavHmzXbNmzRqlpaUpMzNTu3fv1oABA+TxeHTs2LGLOR8AAMAQQZZlWQ3d+Pjx44qIiNC2bdt02223qaKiQt26dVN2drZGjx4tSSouLla/fv1UUFCgYcOGadOmTbrvvvt09OhRRUZGSpJWrlyp2bNn6/jx43I4HJo9e7ZycnK0b98++1hjx45VeXm5cnNzJUnx8fEaMmSIli1bJkmqra1VTEyMpk+frvT09Avq3+fzKTw8XBUVFXK5XA09DfXqlZ5zwbWHFyU26rEBADDZhX7/vqh7cioqKiRJnTt3liQVFhbq9OnTSkhIsGv69u2rnj17qqCgQJJUUFCg/v372wFHkjwej3w+n/bv32/XnL2Pupq6fVRXV6uwsNCvJjg4WAkJCXYNAAC4vIU2dMPa2lrNmDFDN998s2644QZJktfrlcPhUKdOnfxqIyMj5fV67ZqzA07deN3Yz9X4fD79+OOPOnHihGpqauqtKS4uPm/PVVVVqqqqsr/2+XwBzBgAALQmDb6Sk5KSon379mn16tWN2U+TWrhwocLDw+0lJiampVsCAABNpEEhZ9q0adqwYYM++eQT9ejRw14fFRWl6upqlZeX+9WXlZUpKirKrvnp01Z1X/+9GpfLpbZt26pr164KCQmpt6ZuH/WZM2eOKioq7OXIkSOBTRwAALQaAYUcy7I0bdo0vf/++9qyZYt69+7tNx4XF6c2bdooPz/fXldSUqLS0lK53W5Jktvt1t69e/2egsrLy5PL5VJsbKxdc/Y+6mrq9uFwOBQXF+dXU1tbq/z8fLumPk6nUy6Xy28BAABmCuienJSUFGVnZ+u///u/1bFjR/semvDwcLVt21bh4eFKTk5WWlqaOnfuLJfLpenTp8vtdmvYsGGSpBEjRig2NlYTJkzQ4sWL5fV6NXfuXKWkpMjpdEqSpkyZomXLlmnWrFl67LHHtGXLFq1du1Y5OX97YiktLU1JSUkaPHiwhg4dqiVLlqiyslITJ05srHMDAABasYBCzmuvvSZJ+uUvf+m3/u2339avfvUrSdLLL7+s4OBgjRo1SlVVVfJ4PFqxYoVdGxISog0bNmjq1Klyu91q3769kpKStGDBArumd+/eysnJUWpqqpYuXaoePXrozTfflMfjsWvGjBmj48ePKyMjQ16vVwMHDlRubu45NyMDAIDL00W9J6e14z05AAC0Ps3ynhwAAIBLFSEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgpNCWbgBAy+iVnhNQ/eFFiU3UCQA0DUIOALRSgQTVSyWktsae0XoRcgAAlySuNuJiEXIAAGgFLpWrYJdKHxeCG48BAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMFHHK2b9+u+++/X9HR0QoKCtL69ev9xi3LUkZGhrp37662bdsqISFBX3/9tV/N999/r/Hjx8vlcqlTp05KTk7WDz/84Ffz+9//XrfeeqvCwsIUExOjxYsXn9PLunXr1LdvX4WFhal///7auHFjoNMBAACGCjjkVFZWasCAAVq+fHm944sXL9Yrr7yilStXaufOnWrfvr08Ho9OnTpl14wfP1779+9XXl6eNmzYoO3bt2vy5Mn2uM/n04gRI3TllVeqsLBQzz//vObNm6fXX3/drtmxY4fGjRun5ORk7dmzRyNHjtTIkSO1b9++QKcEAAAMFPCvdbjnnnt0zz331DtmWZaWLFmiuXPn6oEHHpAk/ed//qciIyO1fv16jR07VgcOHFBubq6++OILDR48WJL06quv6t5779ULL7yg6OhovfPOO6qurtZvfvMbORwOXX/99SoqKtJLL71kh6GlS5fq7rvv1syZMyVJzzzzjPLy8rRs2TKtXLmyQScDAACYo1HvyTl06JC8Xq8SEhLsdeHh4YqPj1dBQYEkqaCgQJ06dbIDjiQlJCQoODhYO3futGtuu+02ORwOu8bj8aikpEQnTpywa84+Tl1N3XHqU1VVJZ/P57cAAAAzNWrI8Xq9kqTIyEi/9ZGRkfaY1+tVRESE33hoaKg6d+7sV1PfPs4+xvlq6sbrs3DhQoWHh9tLTExMoFMEAACtxGX1dNWcOXNUUVFhL0eOHGnplgAAQBNp1JATFRUlSSorK/NbX1ZWZo9FRUXp2LFjfuNnzpzR999/71dT3z7OPsb5aurG6+N0OuVyufwWAABgpkYNOb1791ZUVJTy8/PtdT6fTzt37pTb7ZYkud1ulZeXq7Cw0K7ZsmWLamtrFR8fb9ds375dp0+ftmvy8vJ03XXX6YorrrBrzj5OXU3dcQAAwOUt4JDzww8/qKioSEVFRZL+72bjoqIilZaWKigoSDNmzNCzzz6rDz74QHv37tWjjz6q6OhojRw5UpLUr18/3X333Xr88ce1a9cuffbZZ5o2bZrGjh2r6OhoSdIjjzwih8Oh5ORk7d+/X2vWrNHSpUuVlpZm9/HEE08oNzdXL774ooqLizVv3jx9+eWXmjZt2sWfFQAA0OoF/Aj5l19+qeHDh9tf1wWPpKQkZWVladasWaqsrNTkyZNVXl6uW265Rbm5uQoLC7O3eeeddzRt2jTdeeedCg4O1qhRo/TKK6/Y4+Hh4froo4+UkpKiuLg4de3aVRkZGX7v0rnpppuUnZ2tuXPn6qmnntI111yj9evX64YbbmjQiQAAAGYJOOT88pe/lGVZ5x0PCgrSggULtGDBgvPWdO7cWdnZ2T97nBtvvFGffvrpz9Y89NBDeuihh36+YQAAcFkKOOSg8fVKzwmo/vCixCbqBAAAc1xWj5ADAIDLByEHAAAYiZADAACMRMgBAABGIuQAAAAj8XSV4QJ5countgAAJuFKDgAAMBJXclqhQN+rAwDA5YgrOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkXgZIGyBvmSQXwMBALiUcSUHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIzEr3VAgwXyayD4FRAAgObGlRwAAGAkQg4AADASIQcAABiJkAMAAIzEjcdoFtykDABoboQcoBFcKiEukD4AwHStPuQsX75czz//vLxerwYMGKBXX31VQ4cObem2cBFM/0Zt+vwA4FLRqkPOmjVrlJaWppUrVyo+Pl5LliyRx+NRSUmJIiIiWro9wCitMZwFctWMq3GAeVp1yHnppZf0+OOPa+LEiZKklStXKicnR7/5zW+Unp7ewt0BaGlNFRgIIv44H7hUtdqQU11drcLCQs2ZM8deFxwcrISEBBUUFNS7TVVVlaqqquyvKyoqJEk+n6/R+6ut+muj7xMAGqpn6rqWbqHJNcVneaBuyNzc0i1IatpzEcj3t6bqo26/lmX9bF2rDTnfffedampqFBkZ6bc+MjJSxcXF9W6zcOFCzZ8//5z1MTExTdIjAKD5hC9p6Q4uHZfKuWjqPk6ePKnw8PDzjrfakNMQc+bMUVpamv11bW2tvv/+e3Xp0kVBQUGNdhyfz6eYmBgdOXJELper0fbbWlzu85c4B8yf+V/O85c4B009f8uydPLkSUVHR/9sXasNOV27dlVISIjKysr81peVlSkqKqrebZxOp5xOp9+6Tp06NVWLcrlcl+Vf7jqX+/wlzgHzZ/6X8/wlzkFTzv/nruDUabVvPHY4HIqLi1N+fr69rra2Vvn5+XK73S3YGQAAuBS02is5kpSWlqakpCQNHjxYQ4cO1ZIlS1RZWWk/bQUAAC5frTrkjBkzRsePH1dGRoa8Xq8GDhyo3Nzcc25Gbm5Op1OZmZnn/GjscnG5z1/iHDB/5n85z1/iHFwq8w+y/t7zVwAAAK1Qq70nBwAA4OcQcgAAgJEIOQAAwEiEHAAAYCRCTgMtX75cvXr1UlhYmOLj47Vr166frV+3bp369u2rsLAw9e/fXxs3bmymTptGIPN/4403dOutt+qKK67QFVdcoYSEhL97vlqDQP8O1Fm9erWCgoI0cuTIpm2wiQU6//LycqWkpKh79+5yOp269tprW/W/g0Dnv2TJEl133XVq27atYmJilJqaqlOnTjVTt41r+/btuv/++xUdHa2goCCtX7/+726zdetWDRo0SE6nU3369FFWVlaT99lUAp3/e++9p7vuukvdunWTy+WS2+3W5s2Xxu+4aoiG/PnX+eyzzxQaGqqBAwc2WX9nI+Q0wJo1a5SWlqbMzEzt3r1bAwYMkMfj0bFjx+qt37Fjh8aNG6fk5GTt2bNHI0eO1MiRI7Vv375m7rxxBDr/rVu3aty4cfrkk09UUFCgmJgYjRgxQn/5y1+aufPGE+g5qHP48GE9+eSTuvXWW5up06YR6Pyrq6t111136fDhw/rtb3+rkpISvfHGG/qHf/iHZu68cQQ6/+zsbKWnpyszM1MHDhzQW2+9pTVr1uipp55q5s4bR2VlpQYMGKDly5dfUP2hQ4eUmJio4cOHq6ioSDNmzNCkSZNa7Tf6QOe/fft23XXXXdq4caMKCws1fPhw3X///dqzZ08Td9o0Ap1/nfLycj366KO68847m6izelgI2NChQ62UlBT765qaGis6OtpauHBhvfUPP/ywlZiY6LcuPj7e+pd/+Zcm7bOpBDr/nzpz5ozVsWNHa9WqVU3VYpNryDk4c+aMddNNN1lvvvmmlZSUZD3wwAPN0GnTCHT+r732mnXVVVdZ1dXVzdVikwp0/ikpKdYdd9zhty4tLc26+eabm7TP5iDJev/993+2ZtasWdb111/vt27MmDGWx+Npws6ax4XMvz6xsbHW/PnzG7+hZhbI/MeMGWPNnTvXyszMtAYMGNCkfdXhSk6AqqurVVhYqISEBHtdcHCwEhISVFBQUO82BQUFfvWS5PF4zlt/KWvI/H/qr3/9q06fPq3OnTs3VZtNqqHnYMGCBYqIiFBycnJztNlkGjL/Dz74QG63WykpKYqMjNQNN9yg5557TjU1Nc3VdqNpyPxvuukmFRYW2j/SOnjwoDZu3Kh77723WXpuaSZ9BjaG2tpanTx5stV+BjbE22+/rYMHDyozM7NZj9uq33jcEr777jvV1NSc81blyMhIFRcX17uN1+utt97r9TZZn02lIfP/qdmzZys6OvqcD73WoiHn4He/+53eeustFRUVNUOHTash8z948KC2bNmi8ePHa+PGjfrmm2/061//WqdPn272D72L1ZD5P/LII/ruu+90yy23yLIsnTlzRlOmTGm1P64K1Pk+A30+n3788Ue1bdu2hTprGS+88IJ++OEHPfzwwy3dSrP4+uuvlZ6erk8//VShoc0bO7iSg2a1aNEirV69Wu+//77CwsJaup1mcfLkSU2YMEFvvPGGunbt2tLttIja2lpFRETo9ddfV1xcnMaMGaOnn35aK1eubOnWmsXWrVv13HPPacWKFdq9e7fee+895eTk6Jlnnmnp1tDMsrOzNX/+fK1du1YREREt3U6Tq6mp0SOPPKL58+fr2muvbfbjcyUnQF27dlVISIjKysr81peVlSkqKqrebaKiogKqv5Q1ZP51XnjhBS1atEgff/yxbrzxxqZss0kFeg7++Mc/6vDhw7r//vvtdbW1tZKk0NBQlZSU6Oqrr27aphtRQ/4OdO/eXW3atFFISIi9rl+/fvJ6vaqurpbD4WjSnhtTQ+b///7f/9OECRM0adIkSVL//v1VWVmpyZMn6+mnn1ZwsNn/v3m+z0CXy3VZXcVZvXq1Jk2apHXr1rXaK9mBOnnypL788kvt2bNH06ZNk/R/n3+WZSk0NFQfffSR7rjjjiY7vtn/spqAw+FQXFyc8vPz7XW1tbXKz8+X2+2udxu32+1XL0l5eXnnrb+UNWT+krR48WI988wzys3N1eDBg5uj1SYT6Dno27ev9u7dq6KiInv5x3/8R/tJk5iYmOZs/6I15O/AzTffrG+++cYOd5L0hz/8Qd27d29VAUdq2Pz/+te/nhNk6gKfdRn8+kCTPgMb6t1339XEiRP17rvvKjExsaXbaTYul+ucz78pU6bouuuuU1FRkeLj45u2gWa5vdkwq1evtpxOp5WVlWV99dVX1uTJk61OnTpZXq/XsizLmjBhgpWenm7Xf/bZZ1ZoaKj1wgsvWAcOHLAyMzOtNm3aWHv37m2pKVyUQOe/aNEiy+FwWL/97W+tb7/91l5OnjzZUlO4aIGeg59q7U9XBTr/0tJSq2PHjta0adOskpISa8OGDVZERIT17LPPttQULkqg88/MzLQ6duxovfvuu9bBgwetjz76yLr66quthx9+uKWmcFFOnjxp7dmzx9qzZ48lyXrppZesPXv2WH/6058sy7Ks9PR0a8KECXb9wYMHrXbt2lkzZ860Dhw4YC1fvtwKCQmxcnNzW2oKFyXQ+b/zzjtWaGiotXz5cr/PwPLy8paawkUJdP4/1ZxPVxFyGujVV1+1evbsaTkcDmvo0KHW559/bo/dfvvtVlJSkl/92rVrrWuvvdZyOBzW9ddfb+Xk5DRzx40rkPlfeeWVlqRzlszMzOZvvBEF+nfgbK095FhW4PPfsWOHFR8fbzmdTuuqq66y/v3f/906c+ZMM3fdeAKZ/+nTp6158+ZZV199tRUWFmbFxMRYv/71r60TJ040f+ON4JNPPqn333TdnJOSkqzbb7/9nG0GDhxoORwO66qrrrLefvvtZu+7sQQ6/9tvv/1n61ubhvz5n605Q06QZV0G10oBAMBlh3tyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADDS/wdHSrGM2i/ldQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#y = torch.flatten(FP32_model.Conv[0].weight)\n",
        "y = torch.flatten(output_activation['Conv.2'])\n",
        "y = y.cpu()\n",
        "y = torch.flatten(y)\n",
        "y = y.detach()\n",
        "y = y.numpy()\n",
        "print(y.shape)\n",
        "\n",
        "plt.hist(y, bins='auto',density=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6272,)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(array([2587.,  176.,   74.,   46.,   34.,  556.,   20.,   18.,  562.,\n",
              "          18., 1084.,   11.,  546.,  540.]),\n",
              " array([-128.        , -109.85713959,  -91.7142868 ,  -73.57142639,\n",
              "         -55.42856979,  -37.2857132 ,  -19.1428566 ,   -1.        ,\n",
              "          17.1428566 ,   35.2857132 ,   53.42856979,   71.57142639,\n",
              "          89.7142868 ,  107.85713959,  126.        ]),\n",
              " <BarContainer object of 14 artists>)"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#x = torch.flatten(quantized_weights12)\n",
        "#x = torch.flatten(quantized_model.Conv[1].weights)\n",
        "#print(q_output_activation['Conv.3'])\n",
        "x = torch.flatten(q_output_activation['Conv.2'])\n",
        "x = x.cpu()\n",
        "x = torch.flatten(x)\n",
        "x = x.detach()\n",
        "x = x.numpy()\n",
        "print(x.shape)\n",
        "\n",
        "plt.hist(x, bins='auto',density=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Operational Intensities (FLOP/byte) and Throughputs (FLOP/s)\n",
        "# Replace these values with your calculated values\n",
        "oi_avg = 10.64  # Operational intensity for average case (FLOP/byte)\n",
        "oi_best = 4.0   # Operational intensity for best case (FLOP/byte)\n",
        "\n",
        "throughput_avg = 800e6  # Throughput for average case (FLOP/s)\n",
        "throughput_best = 1600e6  # Throughput for best case (FLOP/s)\n",
        "\n",
        "# Plotting the roofline model\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Plot the points for average and best case\n",
        "plt.plot([oi_avg], [throughput_avg], marker='o', markersize=8, color='blue', label='Average Case')\n",
        "plt.plot([oi_best], [throughput_best], marker='o', markersize=8, color='green', label='Best Case')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Operational Intensity (FLOP/byte)')\n",
        "plt.ylabel('Operational Throughput (FLOP/s)')\n",
        "plt.title('Roofline Model')\n",
        "\n",
        "# Add a legend\n",
        "plt.legend()\n",
        "\n",
        "# Show plot\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
