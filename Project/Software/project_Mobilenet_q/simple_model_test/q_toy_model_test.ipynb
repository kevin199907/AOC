{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\胡家豪\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import math\n",
    "import random\n",
    "from collections import OrderedDict, defaultdict\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.datasets import *\n",
    "from torchvision.transforms import *\n",
    "\n",
    "\n",
    "no_cuda = False\n",
    "use_gpu = not no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n",
    "\n",
    "class h_sigmoid(nn.Module):\n",
    "    def __init__(self, inplace=True):\n",
    "        super(h_sigmoid, self).__init__()\n",
    "        self.relu = nn.ReLU6(inplace=inplace)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(x + 3) / 6\n",
    "\n",
    "\n",
    "class h_swish(nn.Module):\n",
    "    def __init__(self, inplace=True):\n",
    "        super(h_swish, self).__init__()\n",
    "        self.sigmoid = h_sigmoid(inplace=inplace)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.sigmoid(x)\n",
    "\n",
    "class ToyModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.Conv = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=1, out_channels=8, kernel_size=1, stride=1,padding= 0, bias=True),\n",
    "      h_swish(inplace=True),\n",
    "      nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3, stride=3,padding= 1, bias=True,groups=8),\n",
    "      h_swish(inplace=True),\n",
    "      SELayer(8),\n",
    "      nn.Conv2d(in_channels=8, out_channels=1, kernel_size=1, stride=1,padding= 0, bias=True),\n",
    "      h_swish(inplace=True)\n",
    "    )  \n",
    "    self.backbone = nn.Sequential(\n",
    "      nn.Linear(10*10, 120, bias=False),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(120, 84, bias=False),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(84, 10, bias=False)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x=self.Conv(x)\n",
    "    x = x.view(-1, 10*10) #transform 28*28 figure to 784 vector\n",
    "    x = self.backbone(x)\n",
    "    return x\n",
    "class Q_SELayer(nn.Module):\n",
    "  def __init__(self,weights1,input_scale1,weight_scale1,output_scale1, input_zero_point1, weight_zero_point1, output_zero_point1,\n",
    "               weights2, input_scale2, weight_scale2, output_scale2, input_zero_point2, weight_zero_point2, output_zero_point2,\n",
    "               input_SE_scale,in_SE_zero_point,\n",
    "               output_SE_scale,output_SE_zero_point,\n",
    "               out_pool_scale,out_pool_zero_point):\n",
    "    super().__init__()\n",
    "    self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "    self.fc = nn.Sequential(\n",
    "        QuantizedLinear(weights1,input_scale1,weight_scale1,output_scale1, input_zero_point1, weight_zero_point1, output_zero_point1),\n",
    "        QuantizedLinear(weights2, input_scale2, weight_scale2, output_scale2, input_zero_point2, weight_zero_point2, output_zero_point2)\n",
    "    )   \n",
    "    self.input_SE_scale, self.in_SE_zero_point = input_SE_scale,in_SE_zero_point\n",
    "    self.output_SE_scale, self.output_SE_zero_point = output_SE_scale, output_SE_zero_point,\n",
    "    self.out_pool_scale, self.out_pool_zero_point = out_pool_scale,out_pool_zero_point\n",
    "    self.linear_out_scale, self.linear_out_zero_point = output_scale2, output_zero_point2\n",
    "\n",
    "\n",
    "  def forward(self,x):\n",
    "    b, c, _, _ = x.size()\n",
    "    y = self.avg_pool(x).view(b, c)\n",
    "    y = (y- self.in_SE_zero_point) \n",
    "    y = do_fake_quant(y, self.input_SE_scale, self.out_pool_scale, self.out_pool_zero_point,bitwidth=8)\n",
    "    y = self.fc(y).view(b, c, 1, 1)\n",
    "    z = (x-self.in_SE_zero_point)*(y-self.linear_out_zero_point)\n",
    "    return do_fake_quant(z, deq_scale=(self.input_SE_scale *self.linear_out_scale), \n",
    "                         q_scale=self.output_SE_scale, q_zero_point=self.output_SE_zero_point,bitwidth=8)\n",
    "  \n",
    "  def __repr__(self):\n",
    "    return f\"Quantized_SE(in_channels={self.fc[0].weights.size(1)}, out_channels={self.fc[1].weights.size(0)})\"\n",
    "    \n",
    "\n",
    "class QuantizedConv(nn.Module):\n",
    "  def __init__(self,bias ,weights,stride,padding,groups ,input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point, bitwidth=8, activation_bitwidth=8):\n",
    "    super().__init__()\n",
    "    weights.to(device),weight_zero_point.to(device)\n",
    "    self.stride, self.padding, self.groups = stride, padding,groups\n",
    "    self.weights = weights\n",
    "    self.input_scale, self.input_zero_point = input_scale, input_zero_point\n",
    "    self.weight_scale, self.weight_zero_point = weight_scale, weight_zero_point\n",
    "    self.output_scale, self.output_zero_point = output_scale, output_zero_point\n",
    "    self.bias = bias\n",
    "    self.bitwidth = bitwidth\n",
    "    self.activation_bitwidth = activation_bitwidth\n",
    "    self.q_bias = torch.round(bias / (input_scale*weight_scale))\n",
    "    self.q_weight = weights- weight_zero_point\n",
    "    self.DeQ_scale = input_scale*weight_scale\n",
    "  def forward(self, x):\n",
    "    return quantized_conv(x, self.bias, self.weights, self.stride, self.padding, self.groups, self.input_scale, self.weight_scale, self.output_scale, self.input_zero_point, self.weight_zero_point, self.output_zero_point, device)\n",
    "  def __repr__(self):\n",
    "    return f\"QuantizedConv(in_channels={self.weights.size(1)}, out_channels={self.weights.size(0)})\"\n",
    "\n",
    "class QuantizedLinear(nn.Module):\n",
    "  def __init__(self, weights, input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point, bitwidth=8, activation_bitwidth=8):\n",
    "    super().__init__()\n",
    "    self.weights = weights\n",
    "    self.input_scale, self.input_zero_point = input_scale, input_zero_point\n",
    "    self.weight_scale, self.weight_zero_point = weight_scale, weight_zero_point\n",
    "    self.output_scale, self.output_zero_point = output_scale, output_zero_point\n",
    "\n",
    "    self.bitwidth = bitwidth\n",
    "    self.activation_bitwidth = activation_bitwidth\n",
    "\n",
    "  def forward(self, x):\n",
    "    return quantized_linear(x, self.weights, self.input_scale, self.weight_scale, self.output_scale, self.input_zero_point, self.weight_zero_point, self.output_zero_point, device)\n",
    "  def __repr__(self):\n",
    "    return f\"QuantizedLinear(in_channels={self.weights.size(1)}, out_channels={self.weights.size(0)})\"\n",
    "\n",
    "#Transform input data to correct integer range\n",
    "class Preprocess(nn.Module):\n",
    "  def __init__(self, input_scale, input_zero_point, activation_bitwidth=8):\n",
    "    super().__init__()\n",
    "    self.input_scale, self.input_zero_point = input_scale, input_zero_point\n",
    "    self.activation_bitwidth = activation_bitwidth\n",
    "  def forward(self, x):\n",
    "    x = x / self.input_scale + self.input_zero_point\n",
    "    x = x.round() \n",
    "    return x\n",
    "  \n",
    "class Quantizer(nn.Module):\n",
    "  def __init__(self,scale,zero_point,bitwidth=8):\n",
    "    super().__init__()\n",
    "    self.scale = scale\n",
    "    self.zero = zero_point\n",
    "    self.store_scale = scale *64\n",
    "\n",
    "  def forward(self,x):\n",
    "    return do_requant(x,self.scale,self.zero)\n",
    "    \n",
    "\n",
    "def quantized_linear(input, weights, input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point, device, bitwidth=8, activation_bitwidth=8):\n",
    "  input, weights = input.to(device), weights.to(device)\n",
    "\n",
    "  #####################################################\n",
    "\n",
    "  M = input_scale * weight_scale / output_scale\n",
    "  output = torch.nn.functional.linear((input - input_zero_point ), (weights - weight_zero_point))\n",
    "  output *= M\n",
    "  output += output_zero_point\n",
    "\n",
    "  #####################################################\n",
    "\n",
    "  #clamp and round\n",
    "  output = output.round().clamp(-2**(activation_bitwidth-1)-1, 2**(activation_bitwidth-1)-1)\n",
    "\n",
    "  return output\n",
    "\n",
    "def quantized_conv(input, bias,weights,stride, padding,groups,input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point, device, bitwidth=8, activation_bitwidth=16):\n",
    "  input, weights = input.to(device), weights.to(device)\n",
    "\n",
    "  #####################################################\n",
    "\n",
    "  M = input_scale * weight_scale \n",
    "  conv_bias = bias /M\n",
    "  conv_bias = conv_bias.round()\n",
    "  output = torch.nn.functional.conv2d((input - input_zero_point ), (weights - weight_zero_point),bias = conv_bias ,stride=stride,padding=padding,groups=groups)\n",
    "  output *= M\n",
    "  #output += output_zero_point\n",
    "\n",
    "  #####################################################\n",
    "\n",
    "  #clamp and round\n",
    "  output = output.round().clamp(-2**(activation_bitwidth-1)-1, 2**(activation_bitwidth-1)-1)\n",
    "\n",
    "  return output\n",
    "\n",
    "def do_requant(input, scale,zero_point,bitwidth=8):\n",
    "    output = input / scale\n",
    "    output = output.round()\n",
    "    output += zero_point\n",
    "    output = output.clamp(-2**(bitwidth-1)-1, 2**(bitwidth-1)-1)\n",
    "    return output\n",
    "\n",
    "def linear_quantize(fp32_tensor, bitwidth=8):\n",
    "  q_min, q_max = -(2**(bitwidth-1)-1), 2**(bitwidth-1) - 1\n",
    "\n",
    "  scale, zero_point = get_scale_and_zero_point(fp32_tensor)\n",
    "\n",
    "  #####################################################\n",
    "\n",
    "  q_tensor = torch.round( fp32_tensor/scale ) +zero_point\n",
    "\n",
    "  #####################################################\n",
    "\n",
    "  #clamp\n",
    "  q_tensor = torch.clamp(q_tensor, q_min, q_max)\n",
    "  return q_tensor, scale, zero_point  \n",
    "def do_fake_quant(input, deq_scale, q_scale, q_zero_point,bitwidth=8):\n",
    "    M = deq_scale/q_scale\n",
    "    N = q_zero_point\n",
    "    output = input * M\n",
    "    output += N\n",
    "    output = output.round().clamp(-(2**(bitwidth-1)), 2**(bitwidth-1)-1)\n",
    "    return output\n",
    "\n",
    "def get_scale_and_zero_point(fp32_tensor, bitwidth=8):\n",
    "  q_min, q_max = -(2**(bitwidth-1)-1), 2**(bitwidth-1) - 1\n",
    "  fp_min = fp32_tensor.min().item()\n",
    "  fp_max = fp32_tensor.max().item()\n",
    "\n",
    "  #####################################################\n",
    "\n",
    "  scale = (fp_max-fp_min) / (q_max-q_min)\n",
    "  zero_point = q_min-fp_min /scale\n",
    "\n",
    "  #####################################################\n",
    "\n",
    "\n",
    "  zero_point = round(zero_point)          #round\n",
    "  zero_point = max(q_min, min(zero_point, q_max)) #clip\n",
    "\n",
    "  return scale, int(zero_point)\n",
    "\n",
    "def signed_dec2hex_matrix_16b(input):\n",
    "    '''Convert a matrix which data is signed decimal to 8 bits hex with 2's complement'''\n",
    "    temp = []\n",
    "    bin8 = lambda x : ''.join(reversed( [str((x >> i) & 1) for i in range(16)] ) )\n",
    "    for i in input:\n",
    "        test =bin8(i)\n",
    "        test = int(test,base=2)\n",
    "        hex_test = hex(test)[2:].zfill(2)\n",
    "        temp.append(hex_test)\n",
    "\n",
    "    return temp\n",
    "\n",
    "def signed_dec2hex_16b(input):\n",
    "    '''Convert a number which data is signed decimal to 8 bits hex with 2's complement'''\n",
    "    bin8 = lambda x : ''.join(reversed( [str((x >> i) & 1) for i in range(16)] ) )\n",
    "    test =bin8(input)\n",
    "    test = int(test,base=2)\n",
    "    hex_test = hex(test)[2:].zfill(2)\n",
    "\n",
    "    return hex_test\n",
    "\n",
    "\n",
    "def signed_dec2hex_matrix(input):\n",
    "    '''Convert a matrix which data is signed decimal to 8 bits hex with 2's complement'''\n",
    "    temp = []\n",
    "    bin8 = lambda x : ''.join(reversed( [str((x >> i) & 1) for i in range(8)] ) )\n",
    "    for i in input:\n",
    "        test =bin8(i)\n",
    "        test = int(test,base=2)\n",
    "        hex_test = hex(test)[2:].zfill(2)\n",
    "        temp.append(hex_test)\n",
    "\n",
    "    return temp\n",
    "\n",
    "def signed_dec2hex(input):\n",
    "    '''Convert a number which data is signed decimal to 8 bits hex with 2's complement'''\n",
    "    bin8 = lambda x : ''.join(reversed( [str((x >> i) & 1) for i in range(8)] ) )\n",
    "    test =bin8(input)\n",
    "    test = int(test,base=2)\n",
    "    hex_test = hex(test)[2:].zfill(2)\n",
    "\n",
    "    return hex_test\n",
    "\n",
    "\n",
    "def golden_gen(golden_layer_decimal):\n",
    "    '''Convert a layer output which is signed decimal in GPU to 8 bits hex with 2's complement in CPU and\n",
    "     make it 4 element in a line, example of use : golden_gen(q_output_activation[\"Conv.3\"]) '''\n",
    "    golden = []\n",
    "    i=0\n",
    "    golden_in_numpy = golden_layer_decimal.cpu().numpy()\n",
    "    test = golden_in_numpy.flatten()\n",
    "    test =test.astype('int32')\n",
    "    golden.append([])\n",
    "    for j, data in enumerate(test):\n",
    "        if(j%4==0 ):\n",
    "            golden.append([])\n",
    "            i = i+1\n",
    "            golden[i].append(signed_dec2hex(data))\n",
    "        if(j%4!=0):\n",
    "            golden[i].append(signed_dec2hex(data))\n",
    "    golden.pop(0)\n",
    "    for indice,data in enumerate(golden):\n",
    "        print(*data,sep='')\n",
    "\n",
    "def input_or_weight_gen(layer_decimal):\n",
    "    '''Convert a layer output which is signed decimal in GPU to 8 bits hex with 2's complement in CPU and\n",
    "     make each byte display in different place, example of use : input_or_weight_gen(quantized_model.Conv[1].weights)'''\n",
    "    byte0 = []\n",
    "    byte1 = []\n",
    "    byte2 = []\n",
    "    byte3 = []\n",
    "\n",
    "    data_in_numpy = layer_decimal.cpu().numpy()\n",
    "    data_test = data_in_numpy.flatten()\n",
    "    data_test = data_test.astype('int32')\n",
    "    data_test = signed_dec2hex_matrix(data_test)\n",
    "    for indice,data in enumerate(data_test):\n",
    "        if(indice%4 == 0):\n",
    "            byte0.append(data)\n",
    "        elif(indice%4 == 1):\n",
    "            byte1.append(data)\n",
    "        elif(indice%4 == 2):\n",
    "            byte2.append(data)\n",
    "        else:\n",
    "            byte3.append(data)\n",
    "    print(\"byte0:\",*byte0)\n",
    "    print(\"=======\")\n",
    "    print(\"byte1:\",*byte1)\n",
    "    print(\"=======\")\n",
    "    print(\"byte2:\",*byte2)\n",
    "    print(\"=======\")\n",
    "    print(\"byte3:\",*byte3)\n",
    "    print(\"=======\")\n",
    "    return byte0,byte1,byte2,byte3\n",
    "\n",
    "\n",
    "def bias_gen(layer_decimal):\n",
    "    byte0 = []\n",
    "    byte1 = []\n",
    "    byte2 = []\n",
    "    byte3 = []\n",
    "    temp1 = []\n",
    "\n",
    "    data_in_numpy = layer_decimal.cpu().numpy()\n",
    "    data_test = data_in_numpy.flatten()\n",
    "    data_test = data_test.astype('int32')\n",
    "    data_test = signed_dec2hex_matrix_16b(data_test)\n",
    "    for indice,data in enumerate(data_test):\n",
    "        if(indice%2 == 0):\n",
    "            if(len(data)==1):\n",
    "                byte1.append('00')\n",
    "                byte0.append('0'+str(data))\n",
    "            elif(len(data)==2):\n",
    "                byte1.append('00')\n",
    "                byte0.append(data)\n",
    "            elif(len(data)==3):\n",
    "                temp = data[2]\n",
    "                byte1.append('0'+data[0])\n",
    "                byte0.append(data[1]+data[2])\n",
    "            elif(len(data)==4):\n",
    "                byte1.append(data[0:2])\n",
    "                byte0.append(data[2:4])\n",
    "        elif(indice%2 == 1):\n",
    "            if(len(data)==1):\n",
    "                byte3.append('00')\n",
    "                byte2.append('0'+str(data))\n",
    "            elif(len(data)==2):\n",
    "                byte3.append('00')\n",
    "                byte2.append(data)\n",
    "            elif(len(data)==3):\n",
    "                byte3.append('0'+data[0])\n",
    "                byte2.append(data[1]+data[2])\n",
    "            elif(len(data)==4):\n",
    "                byte3.append(data[0:2])\n",
    "                byte2.append(data[2:4])\n",
    "\n",
    "    print(\"byte0:\",*byte0)\n",
    "    print(\"=======\")\n",
    "    print(\"byte1:\",*byte1)\n",
    "    print(\"=======\")\n",
    "    print(\"byte2:\",*byte2)\n",
    "    print(\"=======\")\n",
    "    print(\"byte3:\",*byte3)\n",
    "    print(\"=======\")\n",
    "    return byte0,byte1,byte2,byte3\n",
    "\n",
    "def DecToBin_machine(num,accuracy):\n",
    "    integer = int(num)\n",
    "    flo = num - integer\n",
    "    integercom = '{:1b}'.format(integer)\n",
    "    tem = flo\n",
    "    flo_list = []\n",
    "    for i in range(accuracy):\n",
    "        tem *= 2\n",
    "        flo_list += str(int(tem))\n",
    "        tem -= int(tem)\n",
    "    flocom = flo_list\n",
    "    binary_value =  ''.join(flocom)\n",
    "    return binary_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToyModel(\n",
      "  (Conv): Sequential(\n",
      "    (0): Preprocess()\n",
      "    (1): QuantizedConv(in_channels=1, out_channels=8)\n",
      "    (2): h_swish(\n",
      "      (sigmoid): h_sigmoid(\n",
      "        (relu): ReLU6(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): Quantizer()\n",
      "    (4): QuantizedConv(in_channels=1, out_channels=8)\n",
      "    (5): h_swish(\n",
      "      (sigmoid): h_sigmoid(\n",
      "        (relu): ReLU6(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Quantizer()\n",
      "    (7): Quantized_SE(in_channels=8, out_channels=8)\n",
      "    (8): QuantizedConv(in_channels=8, out_channels=1)\n",
      "    (9): h_swish(\n",
      "      (sigmoid): h_sigmoid(\n",
      "        (relu): ReLU6(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (10): Quantizer()\n",
      "  )\n",
      "  (backbone): Sequential(\n",
      "    (0): QuantizedLinear(in_channels=100, out_channels=120)\n",
      "    (1): QuantizedLinear(in_channels=120, out_channels=84)\n",
      "    (2): QuantizedLinear(in_channels=84, out_channels=10)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "#Dataset\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "model = torch.load('dw_customize_Toymodel.pt',map_location=device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Conv.0', 'Conv.1', 'Conv.2', 'Conv.3', 'Conv.4', 'Conv.5', 'Conv.6', 'Conv.7.fc.0', 'Conv.7.fc.1', 'Conv.8', 'Conv.9', 'Conv.10', 'backbone.0', 'backbone.1', 'backbone.2'])\n",
      "tensor([[[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  1.,  2.,  1.,  2.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  1.,  2.,  2.,  2.,  2.,  1.],\n",
      "          [ 0.,  0.,  0.,  1.,  2.,  2.,  2.,  2.,  2.,  1.],\n",
      "          [ 1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  1.],\n",
      "          [ 1.,  1.,  2.,  2.,  2.,  1.,  1.,  2.,  2.,  1.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
      "\n",
      "         [[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.]],\n",
      "\n",
      "         [[ 2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.],\n",
      "          [ 2.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  2.],\n",
      "          [ 2.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  2.],\n",
      "          [ 2.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  2.],\n",
      "          [ 2.,  3.,  3.,  3.,  3.,  3.,  3.,  1.,  2.,  2.],\n",
      "          [ 2.,  3.,  3.,  3.,  3.,  3.,  3.,  2.,  3.,  2.],\n",
      "          [ 2.,  3.,  3.,  3.,  3.,  3.,  2.,  2.,  1.,  1.],\n",
      "          [ 2.,  2.,  2.,  3.,  2.,  2.,  2.,  2.,  2.,  2.],\n",
      "          [ 2.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  2.],\n",
      "          [ 2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  1.,  2.,  2.,  2.,  2.,  0.],\n",
      "          [ 0.,  0.,  0.,  1.,  2.,  2.,  2.,  2.,  2.,  1.],\n",
      "          [ 1.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  1.],\n",
      "          [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
      "\n",
      "         [[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "          [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.]],\n",
      "\n",
      "         [[-0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
      "          [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
      "          [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
      "          [-0., -0., -0., -0., -0., -1., -2., -1., -2., -0.],\n",
      "          [-0., -0., -0., -0., -1., -2., -3., -3., -3., -0.],\n",
      "          [-0., -0., -0., -1., -2., -3., -3., -3., -3., -1.],\n",
      "          [-1., -2., -3., -3., -3., -3., -3., -3., -3., -2.],\n",
      "          [-1., -1., -2., -2., -2., -2., -1., -2., -2., -1.],\n",
      "          [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
      "          [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0., -1., -0., -0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0., -1., -1., -1.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0., -0., -1., -1., -1., -1.],\n",
      "          [ 0.,  0.,  0., -0., -1., -1., -1., -1., -1., -1.],\n",
      "          [ 0., -0., -0., -1., -1., -1., -0., -1., -1., -1.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
      "\n",
      "         [[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "          [ 1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  1.],\n",
      "          [ 1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  1.],\n",
      "          [ 1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  1.],\n",
      "          [ 1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  1.],\n",
      "          [ 1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  1.],\n",
      "          [ 1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  1.],\n",
      "          [ 1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  1.],\n",
      "          [ 1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  1.],\n",
      "          [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# add hook to record the min max value of the activation\n",
    "q_input_activation = {}\n",
    "q_output_activation = {}\n",
    "\n",
    "#Define a hook to record the feature map of each layer\n",
    "def add_range_recoder_hook(model):\n",
    "    import functools\n",
    "    def _record_range(self, x, y, module_name):\n",
    "        x = x[0]\n",
    "        q_input_activation[module_name] = x.detach()\n",
    "        q_output_activation[module_name] = y.detach()\n",
    "\n",
    "    all_hooks = []\n",
    "    for name, m in model.named_modules():\n",
    "        if isinstance(m, (QuantizedConv,  QuantizedLinear,h_swish,Quantizer,Preprocess)):\n",
    "            all_hooks.append(m.register_forward_hook(\n",
    "                functools.partial(_record_range, module_name=name)))\n",
    "\n",
    "\n",
    "    return all_hooks\n",
    "\n",
    "\n",
    "q_test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "hooks = add_range_recoder_hook(model)\n",
    "sample_data = iter(q_test_loader).__next__()[0].to(device) #Use a batch of training data to calibrate\n",
    "model(sample_data) #Forward to use hook\n",
    "#print(quantized_model.Conv[1].weights)\n",
    "print(q_output_activation.keys())\n",
    "# print(q_input_activation[\"Conv.2\"])\n",
    "print(q_output_activation[\"Conv.4\"])\n",
    "# print(quantized_model.Conv[1].bias)\n",
    "# print(quantized_model.Conv[1].q_bias)\n",
    "# print(quantized_model.Conv[1].input_scale)\n",
    "# print(quantized_model.Conv[1].weight_scale)\n",
    "# remove hooks\n",
    "for h in hooks:\n",
    "    h.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 37.1%, Avg loss: 0.001331 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "#Dataset\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "#Dataloader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() #define loss function\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "  #set model to evaluate mode\n",
    "  model.eval()\n",
    "  size = len(dataloader.dataset)\n",
    "  num_batches = len(dataloader)\n",
    "  test_loss, correct = 0, 0\n",
    "  with torch.no_grad():\n",
    "    for x, y in dataloader:\n",
    "      if use_gpu:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "      pred = model(x)\n",
    "      test_loss = loss_fn(pred, y).item()\n",
    "      correct += (pred.argmax(1) == y).type(torch.float).sum().item() #calculate accuracy\n",
    "  test_loss /= num_batches\n",
    "  correct /= size\n",
    "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "test_loop(test_loader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-22791., -22080.,  14448., -19011.,  -7044., -19033.,  11902., -20904.],\n",
      "       device='cuda:0')\n",
      "byte0: f9 70 7c 7e\n",
      "=======\n",
      "byte1: a6 38 e4 2e\n",
      "=======\n",
      "byte2: c0 bd a7 58\n",
      "=======\n",
      "byte3: a9 b5 b5 ae\n",
      "=======\n",
      "=========dividen=============\n",
      "byte0: f9 70 7c 7e\n",
      "=======\n",
      "byte1: a6 38 e4 2e\n",
      "=======\n",
      "byte2: c0 bd a7 58\n",
      "=======\n",
      "byte3: a9 b5 b5 ae\n",
      "=======\n",
      "deq_scale (shift 13): 01011010\n",
      "req_scale (shift 6): 00000001\n"
     ]
    }
   ],
   "source": [
    "#golden_gen(q_output_activation[\"Conv.3\"])\n",
    "#print(model.Conv[1].input_zero_point)\n",
    "#input_or_weight_gen(q_input_activation[\"Conv.1\"])\n",
    "#print(\"===\")\n",
    "\n",
    "#input_or_weight_gen(model.Conv[1].weights)\n",
    "print(model.Conv[1].q_bias)\n",
    "bias_gen(model.Conv[1].q_bias)\n",
    "print(\"=========dividen=============\")\n",
    "bias_gen(model.Conv[1].q_bias)\n",
    "#golden_gen(q_output_activation[\"Conv.3\"])\n",
    "#print(model.Conv[1].DeQ_scale)\n",
    "#print(model.Conv[3].scale)\n",
    "print(\"deq_scale (shift 13):\",DecToBin_machine(model.Conv[1].DeQ_scale*8192 ,8))\n",
    "print(\"req_scale (shift 6):\",DecToBin_machine(model.Conv[3].scale ,8))\n",
    "#print(\"output zero\",)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
