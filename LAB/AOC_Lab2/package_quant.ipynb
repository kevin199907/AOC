{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# This code can help you to find out the ways to print out ifmap, ofmap, weight and help you understand the process of QAT and PTQ quantization.\n",
        "# However,  through verification, the ofmap calculated by the package is different from the equation  below, which is in the paper \"Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference\".\n",
        "# The operation under the package is still unknown.\n",
        "# If you are insterested in this code, maybe you can start from export PTQ.onnx file to Netron and try to understand the details of each block.\n",
        "# You can also discuss with us on discord or share what you figure out in your report.\n",
        "# Also, if you want to modify the code to do some experiment and answer report question 3 is perfectly fine.\n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAsgAAAC1CAYAAABCiAlAAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAEnQAABJ0Ad5mH3gAAABhaVRYdFNuaXBNZXRhZGF0YQAAAAAAeyJjbGlwUG9pbnRzIjpbeyJ4IjowLCJ5IjowfSx7IngiOjcxMywieSI6MH0seyJ4Ijo3MTMsInkiOjE4MX0seyJ4IjowLCJ5IjoxODF9XX1K7tOYAABxf0lEQVR4Xu3dB1xT9xYH8JMFCKKgIgoOXKiIRcW9UVu3Fq17i6uO1lVX3fM5qlXrHnXvURVH3RMXdc+6qaKi4ACEQJLfuxlIgCQECCp4vu9Dn9yE5I5zz//ce//3f0UQEGOMMcYYY0xDrPt/xhhjjDHGmIALZMYYY4wxxvRwgcwYY4wxxpgeLpAZY4wxxhjTwwUyY4wxxhhjerhAZowxxhhjTA8XyIwxxhhjjOnhApkxxhhjjDE9XCAzxhhjjDGmhwtkxhhjjDHG9HCB/AmolCrdv750KlIqdf9MLyo5RUREk0L3a3pRxcSk7TtUMRST3jP5BVPJP5A8o4RtulJRzNccCEYoU50oPsH6FObN8NxlnG2Z5vzFUkelFKKEMS0RBLp/x1Pcoh1z99C/sUlfSp6IbD196acm7rrfv0ZKenv/DB3Y4097du2iC4Wn0/WV35ON7tUvywd6FniE9vrvod27D1B4ywN09FcPkuhetQRV6AVaNeN32v7Pa4pVhNDNizcoROxMJasLcTJpMnUv72DBIzUlPV7Xher12kKhJX+iTYdmUP0cKft05eN11KVeL9oSWpJ+2nSIZtTP8XUcSYbfoA3T/kcbzt8VttFlCorOSgUrfk8Dps2kQTWcdG/6iigf07ou9ajXllAq+dMmOjSjPqUwlDIPVSQFXz1Jhw7+Tfv27afTuUbRne1dyF73slnSbX2qKDL4Kp08dJD+3reP9p/ORaPubKcu+jOXYbZl2vMXSxnl2/t05sAe8t+zi3ZdKEzTr6+k77/Mxpp9auoCOQnlWzy8cBibf+uOcg5idZWs+RFnL4YajZqhWTO9n6aN0fA7H1T5piAcZCLhfWI4tt+m+6CvUSTOzu+OBt/khkykXm9i5Oq0E1G6V78o0RewuOf3qFrYHmLNvMpQYdJNKHQvW0LklXlokj8Pavx6EE/l2mnyOyvQsoAMIuH4TFKgDw5ZdOW8x+rmtsJnC8sjyY8+h6J10833fnVz2GrWhwT5+xxCyj8hA3p/GmMrOcK9116EKIHY+3+ihatUsx6lJYfp3vSVeb8azW3VOY0gyS/E6VcRCEkpXx/FrB6tUL+cC6w0+wXBuumfwp6WQumxPpWvcXRWD7SqXw4uVtrPJuum+DPxzGWYbZn2/MXMF3l2Pro3+Aa5NbWLUOPk6oSdX2RjzT4HwwXyR9E4/GNBSNQ7q1AsuPjtM1kshN/6E+0Ky5Ct1SbdlK9Y+A50yq0+uPiCC2QdxZ1pqCxTb2MLF8hv9qNPMRnsas7C3UQfGnFpJurllkJW9CcctWgboMQL/yGoUSgfSjaZjoBw3eQUUL7wx5AahZCvZBNMT80HZDjRuPCrF6ykhTHgWPzGeHN8LHzcXFDmx526KV8Z5Qv4D6mBQvlKosn0AHwNkWBS5D70zCfRFBKpKpDTdX1GYl/PfNq2ylCBnGG2ZdrzF0upcOzolBtiLpBZIskUyArcmlwBMl2BXPDHw8mcTVPiybw6cPRdp/s984u9sxhDZl2E7uRoPPkpDHKXZogCGW9Xoom1pQtkBe7OqA4bkQzlxl1FrG6qPmX4Czx/a8nz1SkQeweLh8zCxSQb7isUtV9b+Mi8MeG6oS2VEcXizuIhmMUb2HJir2G8t8x0gfzZ9qtYXBvvrW2rDBXIXxij7Qb7DOQ4NcgdUi6QWSLJdm6ysrLS/cscYnKt35ZaFHfQ/Z7JRZyjSV1G0N4XsboJ7CPVU9q37wLJIaIcuXMb7MMrzupMebJbsrezuSLo3KQuNGLvC+ItR6T49ywFvlTf1iQmsViknZjBRZybRF1G7CXeNS1IJMSHyfD4nPuVKOPELrcbjGUIFu/9L3HvScunNdb9lompXtKugZ1p2oUI9alXlljMDbp+RyGsGxHZZMnyBd3kpqKXuwZS52kXKII3nIbi6TN6kd6jl3xCqpe7aGDnaXSBN/AnxPuVWbjdYCzDkIwX6P5tAOhNwCpacOg/If2JyaFCJxrQuDBJda8m8OEMLVhwj4pVLkxZdJPifHhyiraefEvuxfOQ9MNDOrJ2GW34+w6h0Dfkli1R6aQIozsndtG2nbvJ/++T9M+dYJJndaH8uUwVWR/ov7M7adcdO/Isoh4RQUGvrvnT+tWbyf/UDXpt40bFXezi/14ZRjf/3kKbtu2iAwH3KDJHESrqZCOUcmZSPKP9o1pSp4VX6QNEZF+4ElVwjqKn/z2lN5SD8mS3Er4jiP5etJrOhYJsvdrQYN8SJBW+98b+TbRB+N6/A+5QmF0Bcs+rN18GqN49psATf9PenTtp35mb9FyZkwrmdyTr1J4sUbyia/t0y376FoXaCvOQ4x5tnrWL/lVKyLVOH+pR08ngPJk1L/Jgun7xGt2/f5w2rThJ/ynF5OzlQ+5Wz+m///77+PPk4b9062ognTlygG6JvKi0a9IrFYqwW/T3xuP0tlgpUr8sf36B/lqzhrbuD6C777NT4WLOlMXYetAs5y66JvGgIh/vAlfQs/2jqGWnhXT1g1C62xemShWcKerpf/T0DVGOPNkpfi7UMbSPdl2TkEcRY6NYKCjszgnatW0n7fb/m07+c4eC5VnJJX8uymJio6ZpuZJj9v4TQy9uXqCr94IoKNCf1hx+QHKxAxWv6kWO755qttGz9zLKndve8P6eRDrvg9HPKPDgPtq/bw/tOXCKLj98Q1Z53MjFPuHcKZ7tp1EtO9HCqx8IInsqXKkCOUcJy6PdwKTeNeOYm5cUr67Rvl3XSOJR5OPIB6rQu3Thyl16EhQf05p19lZCTk4KenjxMt15HBQ/PdyKnHNnNX90mA//0dmdu+iOnScVcRC+VB3P/utp9WZ/OnXjNdm4FScXu/h5VIbdpL+3bKJtuw5QwL1IylGkKDnZxK/NmOc36MK1exSkm5+nrxSULY8jad4S84JuXrhK9z4uy1MKibWnPDkSbQ+8opPLl9CxYBVJi39Pw9qVIWvNCynZrwyvz49U7+ju4U10JtKDSjhLtMu1eQNt3XWIzt97R7b5C1EeO0NrEfTq5HJaciyYVNLi9P2wdlRGO3MJmPxuHWX4E7p86iD5b99JBwPvUXC4sB8UdCa91Z1IND0LPEj79u+jPXsO0KnLD+mNVR5yc0m075jTbsQxmL8SS03+Ef7m1t+08fhbKlbKVdgucnp+4S9as2Yr7Q+4S++zF6ZizlnMbwtNiHlxky5cjY85TdyFaOPO6vUdOn818f7zlJ59sCHXXHaa71e9fUD/XLpNjzTveUYR1nnJKWuiBRPi5XHgCfp7707aue8M3XyupJwF85NjihpIJQX9vYhWnwsl2HpRm8G+VEKqpLAb+2nThm206+8AuhNmRwXc85qIAXWKCqSD+/bTvj176MCpy/TwjRXlcXOh+BQlxMn1i3T9fnxe0KyT4A9k45KL7HSzLBf21Yt6++qzyCyU38lO+6KOxesCZpiuq4URCtyfUc2sPsjRJ36GR715eKrU/q4Iu4PDK8fD7zsP5JSJYN14BUKD92KgdzZNZ3j1CHPZGi7FM9371TcK3d8xEo2K5UbRut0xYuYiLPl9NDpXzguZ2A5FGgzHtnv63x6FB0dXYvKAH1CtiAOkIgkKDziOyBcn8Fs7TzhIdHc0Cz8iaV40+uOG8A0KPDs8FS3c40Zt0L2epQR67gzGx1kxSYE7K/xQr+Y3yKu581UEuwLeqFmrFmrVqoPuy+9q+/Am6oMcenMNepR1gET/e6XOqDvjIiI1n5uIMgSnfmsH7+Jl8W2rbujZzRcVXa0gEsmQt/pg7Hic0r6iCgQfnozmxRyRv2o7DJr6BxbM+AWtvN1RrVsLlDF1k14K5kX5bD361K6GauULI7tY/ZliOLpXQrVqwjThp2qVyqjgVQy5s4i1d2qTNRouC9P9tfD3b29g9/xR6FbfC3lshPdY1cWC4DBcXNQZpbPH/Y3wI7JCAd9luK2/GpQReHRyLab0aYIyztYQiV3gtzc+ZhR3VsCvXk18k1c9goaw/u0KwLumervVQp3uy3FXoUTEo5NYO6UPmpRxhrVIDBe/vQZjPvr+DoxsJCxH0broPmImFi35HaM7VxZiQgy7Ig0wfNu9BH+XpuUySwr3H+Vr7BhUV7PsNT2dhf1H+G6xPQqV164P9U/dAVvw3ORO8Sn2wXBcXdETFfM4oVzX6VjnfwB71k1Fh9LZILEviU6r7sT341TcwQq/eqj5jbDM6s8W2aGAd03t8tTpjuV3FWbnpf/eP8LJtVPQp0kZOFuLIHbxg14oQfniCvxXjEKD/NpYUse5Q9VBWH38PiIUL3Fp+0Q0dpVAJHMR9q+xWHTogcE4SiDqAY6unIwBP1RDEQcpRJLCGHA8Ei9O/IZ2nvq5QwRp3kb444bwiYpnODy1Bdzt9WJIeD1LiZ7YGRy/NuVPz2P7nC74JqtuJIdC/fHxfsyo+zi65g+MbV0KWTXfIUG+3geTzq/iBiaWT9oHOfn9Sr1rmlqfUXh6fhvmDGmNqgWzCstpjWarXuL6n34o6yCsQ73lEjuUgd+a2wbWpQI3JpY32AfZ9HfrUQTjyLRW+KaABxr9OB5zFi7EjAE+cBHi2K5wY4w/9DxJfIZfXYGeFfPAqVxXTF/njwN71mFqh9LIJrFHyU6rcCc+OJNvN5LJX/pSln+UeHtjN+aP6ob6XnlgIxbBqu4CBIddxKLOpYU8rbefWhWA77LbBu8ZSanoB3sxysfp435l5d4a07dfxmthJSqencGfoxogv270CJLkQc3+s7Hh7LOP7Y8y5ALW/Vof+YT1b1W8Mzbc1e+xrUTIKWG/8C6Ost+2Qree3eBb0RVWIhFkeatj8I7HKViGRH2QQ29iTY+yCfIXiaRwrjsDFw011uFXsaJnReRxKoeu09fB/8AerJvaAaWzSWBfshNWfQyCSNw7NBfdveJzjaxoK8zYfB56u6qQBo5i6c/VkVPYLlk8OmHeySDdKwKL1wXMFMsUyO+v4LfvcsLGR1cgK1/g6OJJGDegHvJLtUFm/e0ITPStg85jJ6J3VSehMRU2vs9cPNIEhhw3FzWDq8wGpX8+pBlm6qPYR9jcpZjQ4KkbhYaYfz1uDsJx/9wxHF7TE56anUwC5xot0aRmUwyevx0nbjzF8/uHMOVbZ82dzeKczTBpTidU8ekrNFY3EPzmPV7f8ceoGg5CsAqf7T4Yp1Nyx0TUX+jspB6lQoriQwOS3myhVyA71umElmUrotPEFdhz/gauHl0CPy+hQBDmS5S1DuY9TFSSKsNwdJg3cpT6Ef7P4l9TPN+JboXUd5EL685rOE6ZfYez+s7o/ihtZwV3v53Q+0hhOW5hYRNn3Q5roEBO5bwo7s9ANU3RbYXvFr3UTY33flc3uErUr1uj+eoI3VTh60JvI+DYLkz8TpdYZWXRqmtNeDcbjsU7TyHw/D7M6+wB4WhbKOhywHfNi4+N1tuAlZg4YTS6Vcyh/VuDDUwU/uqs/Wxp8aEI0N9wbwOwcuIEjO5WETl0xb2hAll+cxGaucpgU/pnHEoYrHi0uQuKCfGoLggbzr/+8W/TslzJS83+Ey9yc2tkV3+vzAujL6Ukwab3Pig0gju6aHKIzGsM9GdNfnms5qBOvf/MfZBw/4n6qzOc1NtPWhxD9Tew2Xnpf9i+fCImjO6Gijm0w1waK6oiAyehajb1Z4mQte48PNLNivLFerTKkxeNF91OmhuMCb+Pc8cOY01PT22BL3FGjZZNULPpYMzffgI3nj7H/UNT8K2zer8TI2ezSZjTqQp8+i7CoRvBePP+Ne74j0IN9dCcQoPuPvh0ou9+i7W+9pqCM0GBHCd8K9ppljdlBbKWif1K+N6AlSbW53uhEJo2Dv3r5dceqAl5yKt+Q3h6fY+BM5Zj3Z9zMLJLdeTTDeMmsiqO/gfe6P44jrECOZnvjqN4hA0diyCLa1MsuKZXBSmDsPC7rJp1JnZsgEV6saYM2YEu+YUDGWG/GZMwODG2jLCeRFlRZ+6DhPnURLthXv5KTf5RIvR2AI7tmojvNN9NkJVtha41vdFs+GLsPBWI8/vmobOHnXY5c/hizQvzs48pitvTUS2LeruJ4dxttxAl+kKxvZOLJjeI7FtiQ3wzEO/Nn2hq54RWG0L08qESYUeHwTtHKfzoH19QC40SdnYrpP28LF4YbnYDqVcgO9ZBp5ZlUbHTRKzYcx43rh7FEj8v2KvziXp7znuYqH0MwY4u6rgVYnbMJb2iXI7LY8sI8SjkhTpzoZ+i5FcmoqJmyEERbOovhqFVrXgwE9VtiqDvYb1lsHhdwJKTggJZOIpzKgavMmVQ5uOPF77xKAJnO+1RvlVcgRwn9gJGemoTqsjWEz8fCNUGuTwIZ7ZtwfFH2t039spkVLITQZK3M3Ykzntq7w/hxyLqYlMIAO+xCe+Qlp/GYE0hKjSiHv0TJQzh5fPD4SHVzr99pXE4lyh4wv/qgjzq4Jd5YuSFFBQHZhfIQsPv2gTzryTc+yOP9ENhdYEoyoIGS17q7fzCPB3qiyKy3Gi3JVQ3JY4Cd6ZW0m4PUTY0XPw0wd8ZowzejPauEojztMNm9eF7IrEXf0VpI2eQUzsvyRXIsZfHwEv9usgG369NelgeurQhrNWfLXZAlVFHExZ94XvgJyyPet06tNqY5G76yB0dhaNv9d+msECOE7kDHXOqt62BAjn2CiZXEhoSSV50NhysOPRjEU2yFWXxxthEt/OnZbmMSdP+I0h9gayTbvtgBDa2yqbJLVL3ITijP99RO9Epl7CNRLZovuqtbqKW0QI5jpl5SVgz2NExpyZWjJ51FPb8a/+rDnth/YmkhdBzb5iwwz3FpvZuyN9qHYISrgqzyE8Phrt6fQmNrkf/RAc8wvedH+6hiS8S2aPSuHOJhiwLx19d8mjmWeY5EglTWhT8u2tfM1ggRx9BXzd1/Fm6QI5jen3Kzw5DSU2cSJD3+6W4k+B1BR6ta4P8mrN6IliXn4hrCZbN+BlkLVPfrcDNmTVhL8kF31XPEuVUJR7Nq6MdF13Ic603xeeqiI2tkE09XeqOIQmDEzs75RK+SwTb5quEEl1Pcu2GwGT+SlP+CcXShtaa7Sd2qIJRR/WLTnX68dOetBA5oNVGc7NPMpQvsdrXURsXRQbgWKIRIqJPDdLGusQV3fckrewi9nRHvkJ9cFC/iQg/hL5FZMjdbouwRAkp7kxFJU27o74StDhhPWJUfIEskrqiyfwrQubRE3kE/QrrCtAGS/BS/zMjNqKV5gBZOCAdcibB9oza2Qm5hO0osm2OhCkqDDs6u2oL+WwNsST+MrqOEk8WfIuclafipl5jbOm6gCVPiFtziShryQbUqUsX6qL307lzZ+rUqjoV0Ovv9pHIkbLrnmYkK9+NBn6r68tplZ+qtmxFtdzUncTekf+cBXQxUkT2NRrRt4YGwLD3oQF+3qQ+gRB1eRHN3vVW94JAbEu2uu+2KlGFqgotoz4rj1LkbqV+XUJ5q9ajslm10+NkKVaU8gmRSorHdPeeXDvRokTkUMePengl7ENk612BPNXzBQU9ffwk/vGWqmDaOHsdPZJ5UUXPGHrx4oXezyuyLelJedXzi3A68/cxeq/9KxMUdG3x/2hrMMipfhtqLGTexKRFC1MBQ5Fg8XnRIxLp+qOKDPZ3s7G1IYlms7nRt61qUILNaluWvnHXfDFFBv9HIYluMJNkz0ZCwZJ6kuyUzcgHvPOfQwsuRgq1SQ1qZDhYyWeAH3mrn6gQdZkWzd5FetGapuUyLI37jyWk2z5oQ161qlMeq6xUrE4NKiq0YB+JrMla3eEOsRQW+iZ+/zGHWXlJTULZs9kbjM94VlR64HwaXklYKGH+Vw0ZQ2sW9KPBp6vSrLntKH/CVWEWsa2ttm+w8NklqlRNGCPCNI9S7sK2FP4pyUtV65WlhKszCxUrmk/T11nx+C4lTWmml8b0q2llen2K7YQ40rwopfLft6PicZtBQ0Ju7abTiLrqvwfJr26nLddT8jBmE9/9dhf9b/ZpiszViDq3dInvJ68hJrfus2nBgJbUvPsUGtzAVjddiE6vWlQ9jxVlLVaHaiQMTiE2rTXzGRsWSm9S+OxiU/krbfnHRthPJZp1IHH7llrVSHiviW3Zb0ibfiIp+L8QI4/rTiFxbvLt2pzyCJ+reLyD1h6O0L2gZV2xFTVXrzvlc9q9fh+90U3XekP7N/5Njm27k8/H1a6i4I2zad0jGXlV9KSYBG3SC3plW5I8tY0ShZ/5m46lqFEStpxDHfLr4UUJWmtbb6rgaaXZnoqnj+mJ/va08aJa1fOQVdZiVKdG0QR9zkVCDGhTVBiFJggCR2r6UzfyVF8mCj9Ga9bdS7iulfdo04YrVLFrZyqhXhS19GyLmVEpSN9CA1yqOfUfOJAGfvwZREOGj6WZfx6kXb9W1CW3hIQ6SPv/9g6kvtckieiztPdwiOYmwDwFCya4mSOehIo1/I5KqqNPFUrH9p2iD9oXtIwkEw2pPdmbuONJZG9PWdUvI4Yi3kdqJ34K1sL60PTKF5J9VHR8A//uGB04Gy7sVBdpVuOqVLVqwp9ag4+SpEAhKlTIjZyjXtDT5NqImEu0adt1ihWOj0uUKZPkBkoNYSMZXEOWnhdLEWcl+7g7GmLklPSwxvj2NpfhT4ims3sPU4iwscR5ClJBw8FKkmIN6TttsFLosX10KkGwmpDschlgif3HEkyt8lTvgxIq2W8vPf3wlm4tak654/JH9H90ZuNuuvxeu9d8iIiI33/MlGxeimNqueJYl6Eh84dQeaERj727kLoNuUrfzZ1NP+RNQXpNxPTqtDdxE6eQp+2zav4eMRH0KVOaWUwtWNxGEYj0/v2ROD+1bFlVu+yKf+nSpXfa6eYy8t0Rx/6iv1+qSFqiLJWLr3/j2XlR17nb6K/l/alSdt00gaRkP9r79AO9vbWImscHJ/13ZiPtvvxeG5MfIigipcFpdCWlb/4RZ7X/eKNYjNxyJ4vs63elVoWE+VEXwev2JiiCVW8f0aNQ9QpSUdiBDbRL2A5xVM+20p+H3ahjl3J6hec7OnbgLIULB8YXZzVO0iZVrTWYjkoKCG1SIXJzjqIXFmmUrMnBQXvjIORRFK2/PSUlqd/ep/Th7S1a1Dx+ONPo/87Qxt2XSZuiPlBEoiCQlulO3avbkghyurBuDV3Wm03F9Q20+VEd6tLKNb5A+1Lb4kwu9Rk8ASvybPU9ecVHsdlUr+7S/Vfa4ycgYRDpkxbzpBKavVfYkR4/oNfG35qUsXyjEV8cKlWqFDe0aWJgvhT3b9K/kRAOvFvR8tsP6eFD4z//7h9Knsmsc9Wr83ThgbB+RRJyzJkrRRvc0vOS4ale0d37r7RH+4DxWJEWI88Sujuxwx7TgxQFa8p8kv3HEtKwD4ol2tMoHx4fo6XDO1CT1mNof1ReypfqoT4sz6b8MJo/uKxwAAqCyI5y5jA9Ok1amV6dH9cmqYT1mXmIydHLi9w0Z8oUFBbyWjs5TRR079JVzVleUdZslD2lG00sEQ7jBB8e07Glw6lDk9Y0Zn8U5c1nmZEgEvgC849ZrKtR1/aeJBMJBfuBdbTjRdz8KOnOij/okHNVqphDTKp3R2jD9me65VLSv2tX00XvztShWNxpVIHiPt38N5Igzk2tlt822BZ9/Pl3Pw21WKNkamuKSZuiPtDjY0tpeIcm1HrMforKm8/4gaykEHXo2YjUPflib22glcfjjmLkdG7NFnrbpBs1yaGbJOC2+POwWA6XFPOjxbNbJrocmDyER5Cw3QUqehdm4lKp1ImcHLUfjpgYitH8TeajDH2tSdaqsBf0Ilo3MQ1Uwc/plUpYWULxFBubsoHpLT0vGR7CKUIbrEIyDzNx6VRKTk6O2p0LQqymY7B+DfuP8sVJmutXlTwbzKbgauNo8+5VNLl7BXKSWbwESQNbcq9aXnOZEzG36I8Bk+j0l3b2NhOQOOUiR81mF5GNraHTvSmlpJCQUM1+g/C3Ke4OIQQnnZzrR1U9G9Ds4Go0bvNuWjW5O1Vwklm+QP4C8495pFS6U0eqYiMivD9K67cEaYv8yGP0x4qHVHfYahrj60ISRNKpTVvoofrFmEBate4x1e3ailz1awplKL3WNkr04otplJT04uRc8qvqSQ1mB1O1cZtp96rJ1L2Ck3BQoHuLATmb96JWBYWEoQyiHX/qupdEHqU1f8moVXefBN08uC3+PPRDL23ETlSilIuRS7zGiXLlJEfNE5BUFHb/Ln08uExMJCWpVP0+EVnnzktOegeVmYq1tWYdIvYu3bgZo52WFpobMdX/UNGLp08pRVdeLD0vGZ0oF+UUikxNtIbdp7vGg1WIVanmfSLr3JQ3HYM1s+8/kf/MI9/K39LQY0Vo+qG/aHwz94T9A78QqrD9NGrQfirWuh7lFoPk1+fRgCkBxDWyhSmU2oNAsT255s+pmZRW6v7Caoo7V+hylOaf5on8h+b5VqZvhx6jItMP0V/jm5F7egbnF5h/zCUp3J46181GIkTRmQ0b6F+lip5tmktbrTrS4FaF6dsuP5D6PmL5uY204baCIo4sp81Rzah7E0fdJ8SxJmtto0R3b9ykz98qRdI/83yp8rdD6ViR6XTor/HUzNwgsK1NvTp9ozmzHrL3T9oWrKS3+9fRgbztqEv5RJUUt8WfheUK5FQS5yhP5YtprwcorgVQgLFuZcIRY5j6EEokI6+qVRLdmJJ5SAsUIBf1VlE8pF2bAkz0FVXRS/9JNPNIwpseEhPny0d5NIWRgv49fy5Fl9YtPS8ZnjgHlS9fTNsfTnGNAowHK4VpzuaKSOZVlaqkY7Bm6v0n5gJN7f4L+T8Blesxilrk/0KrelUI+Q/7ifZ4TKKlfy6jKY2dSIxouvr7APrfeYv39v6qKYKfag4CRVkqUM0qNrqpaSGjwkUKkjpFql4foE17XmkLcEMU92nfniu6X2LowtTu9Iv/E0K5HjSqRX5tV4v09AXmH7OJ81KLLo1JPYBH7KVNtD4wkJYuDKAyfftRZWEzWlfpTG08ZUSx12jL+iO0Y+Uesm+jf3OejrQAFdA2SvRw1yYKMLF7qV7606SZRyg9W6WYC1Op+y/+9ATlqMeoFpSyFCWl0t26UQ31ECnvj9Kadedp+/qTVKpTRyqe6HO4Lf48ki2Q1X0C40D4n8VJy9APLTw1d2Wr3p+gXQdCdS8kpLh3hW68E3b5bLWpQ6tC6Z+MkiUmiWbtCTu8XG6xNSPJX52qFFGnQAU9WDmcZgYa3hXk/66kvpOekHs509lPnLsGVfdQn00ARZxYS+vvafurGgPt6WYNS8/Ll0Ks3XDC0bic5CnacFIq80ML7egjqvd0YtcBMhitint05cY7UomyUe0OrahQegarhfYf7WpIh/07DRTXd5P/7RhhrkSUPUdOzRmxj6AilVI3v3oxqyGW6C4vx5I8ZRs4FVT0Yucv9LN/CRr3W0cqYOVG3X6fRPXV43RFXabZ/afTxS/mkqiIxGLtGUhER+m65ujBO3r3Pm6dpuBIWif1+5W5lPTg9Hl6qhJTzoadyNc52ebLDGJyqetDpdXXwlWvaee4UbRX70axeG/p1ISfacs7Z+2viuu02/+2pquSKHsOypkwOEmlUn7cpxKuirS0G19g/kkBx0ZdNQe5iL1Na/v1peWhvjSwky4XSb+hDu0qkrUolu6s7kNjDhdNdHOejiQ/Va9SRDNd8WAlDZ8ZaLhYlP9LK/tOoifu5dLxZICCru/2p9vaIKAcCYNA2IVUZCxFxZG4taeejXMJB9RyOrewO80IrEpdWufX5i89mbUt/tIlk2FA4eFxRyKgyPDwFO7QSqHA1v4LsTEUYzDnSsmr3zjqVEhGIlUo+S9cQbeT9AOQ0+WN2+m6Iit5/zyRumju0oijIKXJmk8IUu1dDRQTo25sExES2cc/NxbFhoidKJemT6eKXgc9/niUqnj1gjT3TAmNc0ys+vOE742WC+9KRCU0Ipq+YUKijI2Nny+rCtS1i3ZEEERepCnft6CJ+x/pJYEI+td/IvnWn0ayn8ZS08RXoBKTlqIufj6am08QeZr+N2AeXUuwb6no1YnTdEOzzlUUGvJKWKM6aZmXmFiK6/GsFDZAkuWPVWhfFxpi9XZJTGXob+Kooik6rgVWxXUh0RMdretja6j/nZiccmn756leB9Hj+A1HL3Q3u6nvFo/W/V3imJF69aNxQlLX3HDiv5BWJA1Wkl/eSNuvKyir9880sYtbgmI0TctlUFr3H2H7RAnrS/0PRFNUlNG5MyF99kFVRLiuiFPQ1SPau/e1FPT8qD+dDVW/CGGeoxKsU7G6n6p2A1NQ/AamVy9e6f5tTl7Sio7Wza+RftuqZ1to4MC9VGzMHOquq0QkhXvQvAn1hHkAffjnN+o/PVCIqBRQ6K0PQ+LWl5H+peoYi5MwhiSUL5+zNvZfnaR9p/XOQCpD6MzcP+nEB/UfqCgiLCzp5Wso1LOmpW78df/UMme/Sn59aqnbGt0oEPqE/LV07RVS2lejX8b+kOh+F5AifubUqygJY98t9ehO/dVFivBqrFBgdPyuG80//uRjnlO8PE8rf/yOul1sSCPb5dVOVEVQuO4IQ3H1CB2OD05SPD9K/mdDNd8FITYT7FLJtRtqJvJX2vKPej80Huwq4Xvj00+iwv7NURrrU5AcHPJRhS5L6ErcjKeEbS3q1q6EkLEUFHTpJrn2+JnqfxwVRELF2nWkWllFpHz+hN5WSXRz3kdWVKFrF6qobZTo4pTvqcXE/fRIr02L+NefJvrWp2myn2hssg2kmrDdhfZKs71ihHWQZBWphANtbexAaKs1zbqGsJ+ER2rXk+IqHdGMJqSjeE5H/c+SNkUJMWA0r+akZr1aUUGJEL9P7lNUw67UVO/mvI8sXRcw82iHQzZC8QDz6mqfvKR+q8zzFwQYetqNMRH70bOAeoBtgrTYTzhm6DGNOm8DpqGOsxQi3QMU4gfjVuLlkWGokM0W7h3XIMHTJtXebEE7zcDrIlj5zE0yMLjy8WzU1DyBSQS7bxckGbhfHjdQOclQauSFFDyeMhQb26gHg1cPBO6BTrM3YfPSkfBtOgrH3qrHR1+JZpoBxIX15j0B1xN9sOLGRJTXDWhu33h5wqfpRF3EtJq6pympf0RWcCzoifIVvVHCNTtkEifUnRmYcDBzU2JvY1GTvNqnVIkkcCzbDmMXbcaunesxf4QvylXwQmHNOhCWxSYfvBt0xIzjukHoUzkvEft6IJ/mSXlSFBt4IslDB95v74jc6hZJeN1j+PlEA+bH4tr4ctqBzyUF0PtAosCJOoYBmgdfECT5e2J/gpcVePS7D7JoltUaNWYlepKVIHRjG80A7uqHTHh0mo1Nm5dipG9TjFJvOIHi0e/w0Tz9SQTrGrMSPAVJ420AptVRP55ZDIcqo3BUb+R45csjGFYhG2zdO2JNkmBNy3KZlur9R5inS6O9dIPMO+D7VQkfWmOW9NoHw7ahg7P6c4XXhOXyaj0ME8YORue6peH9w09opXs4iZV7C4yeNBR+kw9p/y50I9qoHyIivGbr0QmzN23G0pG+aDrqmPZ1c/OS4hF+98miyX8i6xqYlTgQ5LexsLEzbLzH4UqSTX0dE7x1DyPJUhoD9pu/Xt9saad90Imwr/nMTTzovxKPZ9eEephb9aO0v10QlOj1+IcekKxUkocfxV6dhIq62JY4lkGrIeMxflhPNC9XBJUGrcToGla6eS6C+r1H48/zeg9vCN2EtuoO1sLr6icbXk6U05Lbr5Jbn7HXJ8BblxNl+Rpj2pGg+LwRdQdrO7nD2rooOqy7byBPh2JT29zaPKV+sl3imUvmuxWPN6JjEeuPbZ36SYR2TgVQuGAeZLMSw7Z0f/gnSNJh2NYh7gmkQh7wao1hE8ZicOe6KO39A35qpXvwhJU7WoyehKF+k3FIszCm2w1hTpLNX6nOP7HXML6cNiYlBXojafoZgCK6B7Xk77kf+i9HbtI9FEWzbrKg4qSrBrZB8hS3pqKy+nHfTj9gXYInbgiUIVjbQmhrxLnRdnOYbqIhUbg4rabuaafqHyEHOBaEZ/mK8C7hiuwyCZzqzkSguQ2k8iVWNtM+kIhk3piQtLH++IAckX1jLNeLg7BtHeCsmw+xgxdaD5uAsYM7o25pb/zwUyvdA3+s4N5iNCYN9cNkbRAkFHsFY8vKIJKWxLCzSRJ0PEvXBSxZhgtk+TnM92uBOqWctI88/bhBxMhWuCqadhiMtbdM7B6KJ/Cf7IdGpXPG/71Ihjzlf8CPo+bhkJHH20Td340Jrcoht7UU9gUqoFmXnujcxBtFi/ug98IAvNTPFIogHJw7At1r59c2FsJ3iIQA8W79MyZsuYFYxR3smNQfLcvmhOTj67ng3WYQJm+7hdjoy1gzvBvqFdU+RlT9uji7B5r1HY2VZw09oSipqMBZqJtHKEp0y+dUeQC2PniNc0sHonV55/hlF2dD8Ya9MG7bHc18bR/fCw2Lxz2PXZgvaS6UbTkE62/Er1PlmwtY0qMqXGxECZJ2jjLtMGXPvZTvBJE3sWFgHbjZiT9+nkhsC7cGY7D/9nI0sbGGc5km6DNlHU49TvjpKZqX8AtYNbo36hezjf8e28Ko030E/rwQDsWzw5g7tAtqFbCJf92uGL7rMRZbhJhSvjyO+T/7orT6cbma10WwyV8TnYctw9k3CgTtn44ewja3/hhXNihQuzsm7foXQQfmYHivZvB01D7ZUVsElEbz3iOxLEBvm0YFYlbdPLrH2gqNsVNlDNj6AB+CDmDO8F5o5umoFzOOKN28N0YuC0CCqIi6j90TWqFcbmtI7QugQrMu6Nm5CbyLFodP74UISBCs6hyc2uV6oPuE5KVo/8F7nP9zDH7qWAsFNQWTdp4kDqXQ2G8wxvy+H4+TtMyJpPs+qMCTnQNR2Um3j6nXmWt19F5yAaHKaJwbU073hDMxsnv1wsb7cY1LFAJn1UUe3eOkRTInVB6wFQ8+mJmXhOU6MGc4ejXzhKPmyW3q9wkHlqWbo/fIZQh4o8SzQzPRvbqr8DlC41ysKYatCEBYXFpTPsOhOb1RM6+2CNfMg50banSag9MmHlCmCDqIuSO6o3Z+q/j4dfJG658nYIuQGxR3dmBS/5Yom1MvvnN5o82gydgm7DvRl9dgeLd6KJo1bnsK68WjGfqOXinEmO5LhJLzxvKO8MgWlwfU29wDrWadwuvYx5hdyxYO7j7oOPx3bDn9AG/VMSDs03+O6o3vy+TS7TPCj9ge7g388Mtv++LjxMh+JU92fWr/PL5AFg4MhsxEB8/ccP2mFup/WwlFHLMij3cHzDgWnKgwC8eFP0eh9/dlkEu3vdXLbe/eAH6//IZ9Dx6Z9d1qsY/3YpyvBxw0j01Xf46w3axcUKP/KlwWtnliiic7MbCy+vHkuvfauKJ67yW4EKpE9LkxKKd7nLA4uxd6bbz/8SSA4Xbjg/n5Sy1F+Uc4SD4+Hz/7loZDXFEp5Jf8NTtj2LKzeCNsn/3TewhxF3+AILIpgNrdJ2GX7kBCcWse6ueO2w8J1g2XJXmKnVmUT7GscS54Dj+b9EmNgve7uiJf0b44nNzJAeUbXFjSA1VdhHYkLiaF9SXNUQbtpuzBPTMbyPfnlmJg6/Jw/rjNhRqneEP0GrcNd2IVuLN9PHo1LI5sH9ebFLnKtsSQ9Te0HyDUOjsHVoZTXOwJ69W1em8suRAKZfQ5jCmnbQdF4uzw6rURH1NUAgo8mOODnDVn4W4yOdfidQEzSaT+j7CSvyiKNw/oyrV79DxcQo4FPKispyvZCdXkl0gRdp8C/7lHH3KUooreBSze30kprIt/rtylEIUjFfLwpOKu9kn7ZaWAKvwxXf7nFj2LsKbcJcpRhaKOJFEG0+27Mirm4WTysy09L5+VIozuB/5D9z7koFIVvalAajec4g09uHKN7j0PJ4ljAfIo60munzlYM9L+Yw7lu8d05dJtei1zo7IVS1LuuBu8Ve/ofkAA3Y3NTxWqecZP11BQ2P1A+ufeB8pRqiJ5p3oDZ07KiGd06/ItCrEqRGXLFqUcmnUnp+AHLyl7kQKpHykkDfuV4sZEqlxuHP0Ta03NVofSrjaRdON8ID0Mt6HcRUtTueJOKR4lKTU+BF+jf67/Rx/sC5GXVwnKY2rnUb6jx1cu0e3XMnIrW5FKxgcnvbsfQAF3Yyl/hWrkmTA4LddufML8o4oIpnv/Cfvc4h+od/h0ur+yCaXmNkn5w6v0IEdp8jD0hB5lEF2+bk1eZbRdgZKlFJb/nyt0N0RBjoU8yLO4K9l/8kZJSe8eX6FLt1+TzK0sVSyZ+2Ocqt7dp4CAuxSbvwJV84yfnkT4bbr8LD+VLWFeJGSqtvgL9kUWyIwxxr4uSQrkzl/igH5fOcUtmlGvHf03NoDm1+HtwzK3DHxeiTHGGGOfhPIF7fulJ+0sM53G1ubimGV+XCAzxhj7/PQuZqqHyGJfkjDy/6Ubrc41gbb/1iDFT8xlLCPiMGeMMfbZqd6+Je0wzCp6G/ra9FB37BPLQd9N20Wbf61HLoZGX2MsE+ICmTHG2Ofz4TldP7aRpkzZSg81w/oq6OLyX+n3bUfp3PUgCte8iX1uVppnPDP29eCb9BhjjH02qhcBtHn3NXpnoFeFyK4kNWxfiwrwWUvG2CfGBTJjjDHGGGN6uIsFY4wxxhhjerhAZowxxhhjTA8XyIwxxhhjjOnhApkxxhhjjDE9XCAzxhhjjDGmhwtkxhhjjDHG9HCBzBhjjDHGmB4ukBljjDHGGNPDBTJjjDHGGGN6uEBmjDHGGGNMDxfIjDHGGGOM6eECmTHGGGOMMT1cIDPGGGOMMaaHC2TGGGOMMcb0cIHMGGOMMcaYHi6QGWOMMcYY08MFMmOMMcYYY3q4QGaMMcYYY0wPF8iMMcYYY4zp4QKZMcYYY4wxPVwgM8YYY4wxpocLZMYYY4wxxvRwgcwYY4wxxpgeLpAZY4wxxhjTwwUyY4wxxhhjerhAZowxxhhjTA8XyIwxxhhjjOnhApkxxhhjjDE9XCAzxhhjjDGmhwtkxhhjjDHG9HCBzBhjjDHGmB4RBLp/M8a+GkqKiZaTQiX8UywhKytrkho6XFYpSEHS+NdUSlIK75fofmWMMcYyIz6DzNhXR0G3V/ShZg3rUtkC2SlrFlty+WE1BauL5QQU9M/8jlTbw5nshPfYOuQjzxotafqpaN3rjDHGWObEZ5AZ+1op79K0us1o5YOH9OBlCRp+KpCmVbLWvagn8i/q4jGVCmw5SpMqZdVNZIwxxjIvPoPM2FdKFXqKzku60KJfapO94hYtn7mVXiQ5iyy879UjelGyA/WswMUxY4yxrwMXyIx9paICAii0XC2q0X0otXcTUeie2bTwcozu1XjvTp+j6Eq1yIWzBWOMsa8EN3mMfZVi6PLpf6lYtTJknbUeDepfnWxjr9KyWX/RqwRnkeV0/sx/5FmjJEl1UxhjjLHMjgtkxr5Gykd06nIuqlo1i/CLhNz9hlLbfCJ6+dcsWnJToX2PmuI6nbnpRtUrGOibzBhjjGVSXCAz9hXS9D+mSlQjpy4FZG9Ig/tWJBv5JVo8aw+90U4l1bPTdDFrFapur5vAGGOMfQW4QGbsK6Ttf1yTCn0c0FhCHr2G0g95iYK3zqKlt5Waqe9PnyV5xZqUlzMFY4yxrwg3e4x9deL7H1vppmjkaEZDe5clq+jztPC3A/RO0/84mDxrlOD+x4wxxr4qXCAz9rVJ0P9Yn5Q8fxxC3+cG/bd5Fq28fY3O3CpA1ctz/2PGGGNfFy6QGfvKJOl/rEfs1IKG9ixNsshTNO/XmXTKrir3P2aMMfbV4QKZsa9M1Jkz9LpsDb3+x/qsqFzfwdQ4B+jxzr/ofcWa5MxZgjHG2FeGmz7GvibRd2ntn4fIyjW/0X7F4rxt6Be/EiST5KMqNd25/zFjjLGvDhfIjH0NlP/Siu61qJxHDRp5KpL+mVKbyn87kva91b2egDVV+ukXalK8BtXl8Y8ZY4x9hUQQ6P7NGGOMMcbYV4/PIDPGGGOMMaaHC2TGGGOMMcb0cIHMGGOMMcaYHi6QGWOMMcYY08MFMmOMMcYYY3q4QLYoOT04cYoeKHS/fmKqV4F04sobUul+Z4x9geQP6MSpB/Rp04SKXgWeoCtvODswy5A/OEGnPldjp8ExzdIXF8iWonpFJya1o8GHFeRo0bWqoPCXj+n25bN04sh5evxBN9kAcTZbujOzPfXb/KkbX8aYOVSvTtCkdoPpsMLxEydfMWWzvUMz2/ejzZ+1qGEZn1CYnphE7QYfJoVlGzstRTi9fHybLp89QUfOPybjTR7HNEtfXCBbRCRdnt2RfnnUkRZN8KEcBtdqNN3ZMYmGTPan/5S6SWZQ3l1DQzq3pSa1q5NP4xG067WJo2VrD+q9cAw5LepAg/a95DPJjH1JIi/T7I6/0KOOi2iCTw4jyTd1eSKxmAf+NG3oeNr5KP5DrD1608IxTrSowyDa95KzA0udyMuzqeMvj6jjognkY7ixixfzgPynDaXxOx/pJiRHSXfXDKHObZtQ7eo+1HjELjLd5HFMs3SkflAIS5uIU8NQpkhHbH2h1E0xIHov/FwkkLkPwkm5bpq5Yq9iXDkZZN/8isBY3TQTos6ORFm3Vlj31MT8sEzh/fqWyCYSqR/28/l/RNnQYFEQOOoMicCpYWVQpONWmEoTacoTH0XjSN+CkEjd0O9ItG5anCicHVkWbq3WgdMDS7GIUxhWpgg6bn1h1n4efaQvCkqkcOt3RDfFPLFXx6GcTIZvfg1E8k0exzRLH/wkvbRS3KApNb6l013O0d4+BU2cklfQi6sB9NypMpV1sdJNM4/q+SJqUGQA3eroT/eXNiAb3XTj3tK+XuWpn3IOXV7RlBx0U1nmE3NlKtWuOZrOhsfvxiLr4vTDiN5U1UGkm5JSIJVSSUpFDEV9iKSId28oLOw1hTwPpmdBj+nBo2B6HwtNVZyQiKzKjaUL58eTl1Q3iWkobkyhGt+epi7n9lKfgqbOuqU+T+hThtygi6/zUgWPnCTRTfvo7T7qVb4fKedcphVNOTswcynoxpQa9O3pLnRubx8yGcZxlCF04+JrylvBg3ImCURjVPR8UQMqMuAWdfS/T0sbJN/icUyzdKEpk1mqvd/jh/wuHbH9jW5COgjf0g45JNnhuzZMNyV5sYG/4hsHH8x9oNBNYZlTLG7N+xY5xfpnciVwbbMeQel0NkUZFYI7p7Zj0YQ+aFo2D6xFet8tcUOfgxG6dzKt99jjlx8uHbcjHdNECsQi8Ndv4OAzF5wemNne74Fffhd0TM/GTiMcW9rlgCS7L8xv8jimmeWZcwzIjHpHBzf5U2TVRlTH5EGrgmJiUts/Sk6BJ8/RO4kX1aieXTdNSxUTY/RmPGnpJlQ/73navO0BpaErI/viSalk32U029cl/kwhlPRs68/Ue8m/RuMjLcQ2TlS8egvqM3YR7b70hJ6cW0W/NHYne7GISBlEWxbtIO4OqOfdQdrkH0lVG9VJ5mpOWvJEHCXJ5cltdSmVblKf8p7fTNsecHZg5nl3cBP5R1alRqYbu4+Ucnnq8o88kE6ee0cSrxqUsMlTCfuH0RaPY5pZHBfIaSE/RwdPvCPPqlUom25SQip68fcE6ty6B/Vs5EVenVfR3ZRmDMU9Onn2KYndq1H1fNrNFXFtNQ3v3pV69e9C9Wv1oe3PDTSqVt9QtQp2dOXwEQrhYiVzkxSkjgsWUJfCMvrYqUL1mv4e6Uczr8h1E9KLFTlX7EIz/K/Rtd2jyCevmN4cWEpr7nEjFUd+7iCdeOdJVasYzhIWyRP0gW6tH0rtW3enfl3r0jfVB9LO/4zv+FbfVKMKdlfo8JEQvpmXmUFO5w6eoHeeVcloGOt8uLWehrZvTd37daW631SngTv/S1GMKe6dpLNPxeRerTppm7wIurZ6OHXv2ov6d6lPtfpsJ8NNHsc0sywukNNA+fgSXXvlQEXd8xhckcqHK2jwUjv6Ze0qWtDdnR5tmk4rAmN0r5pH9eoUnb6lIqdK1am0NIYebBtO/VaKqcsfS6iL/SU6fWYX7fvH0GdaUzF3N1LeukRXYnWTWKYldv6eflvWn0pZx/c7Vr07Q5O6j6fT4boJ6cqa3BpPpv3HV1I7l39o5bJzQpPK1Gd0H1+6Rq8cipJ7HsPpNu15QklP1ven4f/Uod82rqblK3pT0csLaPicADL6KdbFyN1NSbcuXSFODyxZysd06dorcijqTkbCWEP5ZD31H/4P1fltI61evoJ6F71MC4bPoQCzw1lFr06dplsqJ6pUvTRJYx7QtuH9aKW4C/2xpAvZXzpNZ3btI8NNHsc0s6yvq0COuEKLunxPY09G6yakjeLxY3qKXOSc29AdSTF0dtFWytGnL5W2jqDjR87TB+tCVLRgyu5e+nD6FP0jt6UK1T3o2ry+NOluQ5o5uxN52Eopt3dT6jxoOv1cx9BNDBJyyeNE9DqIgt7pJjEdBV2e1ZY6zD5HmWmMeYc6k2nFiAqU9WONDIq68hv5DdtHoZ9oOa3dO9Gy7RPIZd8S8n+jm5jRWDRPKOjx46eEXM5kME1YIE+oQnfSxPX5aey0RpRXoq5lHtHTWBFZ21gbT/ASF9KmhyDi9JCI4jLNatuBZp/LyA9diqAri7rQ92NPkkVaO8VjevwUlMs5NxmNTFUo7Zy4nvKPnUaNtIFIj57GksjahqzNrjQ+0OlT/5DctgJV97hG8/pOorsNZ9LsTh5kK81N3k0706DpP5PhJo9j2qhMEdOfga4v8qelfIPbB1dg4s/d0da3GXzbdsfAqWtxOihuSKJo3Fo9CSuumzGmmbmiruL3hqXRaO514dMtI3JrOzhYVcDkW4buClDg8fkLCBJeUoasQ8scEjj6rkFIim6cisax/oUgkTihVKVaaL/gMlJy+1Pkxh9gb1UV0+9lhLsW5AgPC8Xr16/N/wkNQ3hqh8JSPMbGTt6oO+UcwnWTMgX5Dcyp46i+ueDjjXMiaX602/T0Ew6/FourU+rh+wWP0/idSry5fRArJv6M7m190cy3LboPnIq1p4M+7sPRt1Zj0orrut8swOJ5IhJb2znAqsJkGEwTFsgTyjc3cP7m27jf8HxJA9hK8qDb7kjdNEMisfEHe1hVnY4MkR4+cX5QPN6ITt51MeVcWrPDZ4hhROHq7w1RutFcXLdcY4d2DlaoMPmWELFGCO36jfM38TESny9BA1sJ8nTbLUSbmaKPoX8hCSROpVCpVnssuJyiFi9jxbQ8HGGhBuLWxE9oWLiwJ6SO5WL66/GJC2QlQs/9gW7l86Nw7e4YPWcN/M9cxLnDO7FqRj/U86qKn3YG4fnevijl+B0WBluoSVeGYF/f0ijptyuFBappUTs6IIdVeUy6aWpvVOLJwu+QVZIXnXfGpQ4zxV7HBG8ZpEV8MXJsf7QsXxCuno0wfMdDs3aSyPUtYGdVC3Mef7rSKHUUuDm1Mmz0R0MQSWGTPSfy5CuIQoUKJfhxFRK1SPOeLKg89YbuM1Ih4gxGVvBA5y2fsnhMf4qHK+GbVxK/LoUfce4mWPIpW42oRwi8Gmy8MU2GMvQc/uhWHvkL10b30XOwxv8MLp47jJ2rZqBfPS9U/Wkngp7vRd9SjvhuYbDur9IoXfJEFHZ0yAGr8pNgMk2kJU8kEIHtHXNBkrUpVr7WTTIoEutb2MGq1hx88enhM+WHiDMjUcGjM7akcnDdzxLDQhyF7OuL0iX9sMuyjR065LBC+Uk3zd6nI7Z3RC5JVjQ1HYgJxF6fAG+ZFEV8R2Js/5YoX9AVno2GY8dDs1q8jBPTipuYWtlGG6e6H5HUBtlz5kG+ggnjuVAhVzhYace6F2WpjKk3Un/iMK0xnX4icWfrGIzd+Fj3ux5lKALXjkffDk1Ry9sTpcv7wPfHadh+w1CeDMeR//2EmcdS3/bo+4QFsgJB23qhlEN+NJl9Hm8MbB/ls+3oXq4wCjqKIfOeAMucQFbixaZ2yFe4G/6yZMIQyE/8jKJWJfHLWRM7r+I2plWxForc/jgaJfwuD8Gzl+Yd1iuDF+LbLBLk731Qe7Yh9iEWNXKExKEl1uuGv4l+8QwhRtZTyOLvYJ2lGValpb39FIR1NLWyDCKRGNk9fDF88V5cCnpvMMDld1egRT6p8F4J8jZegBtpPEMSGTAcXi5NsfyxJXanL4USz7d3gZtM/wEiYjjUmo6rljqjlI4UQdvQq5QD8jeZjfOGEwW2dy+HwgUdIZZ5Y4JFEkV65Qk5TvxcFFYlf4GpNJGWPJGA/CR+LiqFrNoM3DcZ0iFY/J01sjRb9fGM3xfrs+WHSAQM94JL0+VIaXr4PDEsfOyLTWiXrzC6/RUiRLQFyU8IcWWFkr+cNfMMphwnhbiXyqphhulA1KNE8MJvkUWSH70Pajdc7MNFaOQogUPL9dA2edF48SzEyMNDMk5MK25PRWUhP4vE2eHhOxyL915C0HuDEY27K1ogn1R4r3Dw3HjBjTRe2Up9TKebqNvY8GNt+PTfjkeJNmzswx0YUssVViIRJNY2sBLHt2kiu5Lw2/IkSR5Qhp7GtCaV0HzW2TQPq/nJCuSoi5NQJbsNvIadwnvdtKSUeLq4AeyF5Fao31HLXOJ8fwQD3B1Rb/5DixxR6FM+m486No5ot9X4BaTYi7+itEwGr9GXhJ1aaIRXtUOL+fpHSUqEXd+H7UfuJlkv2vGPHdByfdxmjsahHwtAkqUhloWof3+NdZ3bY9lzQ6lQPS5kaViXGIoA8zLaZ6N4OBu1bKxQuO1K3DJxLU75fDf6eGQRjrqFhrLyGJyyxHCcypfY1NYVBTptw0uLtiifWxgO/eSRcIxikS28R535sruURF3EpCrZYeM1DKeMJwoony5GA3shaRbqh6OWSBTplieUeDa/Dmwc28FEmkg+TyjDcH3fdhy5a2KlCBS3JqOCTIqSw5IpZGID8Wtpa5QYGmBmwfP5fM78oHy5CW1dC6DTtpfCVjHT54phoQU5MsAdjvXm46HlGzvMr2MDx3ZbhRLLDIpbmFxBBmnJYUkPDI3Gsm78Y/UJoI9N3iH8WECCLA2XCeWv4PU6dG6/DIabvIwS0wo8nF0LNlaF0XblLRPrU4nnu/vAI4tQFAqFdOUxpywyjnqqYjq9vL+AWfWLoGy/PUjSYeD9SQwr4wSPHyZj+5UXiBJel4fdw6E5HeCZTaxp08R52mGLoQsUkVcwp6EH6vzvQprau09TICvuYo5PNkhytcGmZAb+VtyZhspWjmiz2XRDYJ5YXJtSGfYFe2JfelQF8nMY7mGDsmOvGDmiBd6uaoYs0hIYqq5SI89ibLNe2KF/hiryL3TOLRaODl3Read++Gv7H0uta+P3J3Hvj8aBXvkgy9cLB4SEqrj7O1p1W2/k0bWhWNXcHjnbbP7Cj6aFg6IF3yKn92icM5V53wZgfDUHiEkEm+I9sPOZwYVOFXnAUJSwKY5BJ9Wn7jKRiLMYU94u4WU8qxLodyD08ydGgxS4O8cH2SS50Cb5RIFpla3gKMR32jNF+uYJ+bnh8LApi7FXjJ8lTC5PRP7VGbnFQjHl2hkJ0kQCcf2P86L7nmRiOXQVmtvnFPLsl36u7XPnBzkChpYQPnMQzEsPnyuGhSi+NgWV7QuiZ/o0djg33AM2ZcfCRBh/FNf/OG/3PUi82ozGsqb/sRTWtX9HfJN3AL3yyZCv1wGh9RPW7e+t0G29kcdcZ5SYVj7Fgm9zwnv0OZMHG28DxqOag1AIimxQvMdOWK7JS2lMpxPFA6xqmR85a8/E9SRHNArcmvEdqg3cb6C+EQ4wFtaHg/rhWOJc6LTT8EIogzehXcHCaL/xSarbu09SIMdeHosyMhGsv1uMl7ppRr1diSYOdfGHJfrIRAg7V0EZig08aZmz0UnIcWqQO7L6zDXa50n5dDO6Fy+IOj+Nx4BWbTDucKJLX7FXMKuuCxzyuMB70EndRIGwE83zsYZt9Rm4rXc2IPr6AjQv7ImWo0aha4sfsc7YY4Mi/eHn6gjfNeb3//oslC+wvFlRdNhmojGJvoUlzVwhFYkgdW2OJbctfH4g9homeFshV6sNFu2j/iWQX58FH3WS/VgkC+uwYEdssVT/fkuKvYyxZWQQWX+HxcknCqxs4oC6f1ig/3h65wn5KQxyzwqfucZvWkwuT8RemYW6Lg7I4+ItHMgZi39d/2P7Zvgzmd0+0t8Pro6++NLTw5eQH2KvTYC3VS602mBGt4XPFcPCtj/QqyBkxQbiZPo0dkIYD4J7Vh/MNaODr7b/sT2aGQhEY7GsfDoPPta2qD7jtlACxYnG9QXNUdizJUaN6ooWP64z+qS8jBLTyhfL0axoB5gO6SVo5qruKiSFa/MlsHyTl4KYThdyXJ1eEw425TA20MDCyc9jYvepCDQSy8qXi/CdtUg4eMiGVpuMHWYIhfT8esjm6IPZN1K3Aj9Jgfx6WUPYCMnLuv5i7WUSE9QL3qjyOFw14yg1Oe93dIKzrCh+PmHh6NITe3U8vB1qY7apflZRL3H36g08DTceisrH89D71wDdb1rylw/wKNTA50Y+x+2rt/HcxNFf+B4/FCjghz2WODWRnkLXoVX5gThubFmUz7CjR3HNDTpih2qYEJAeCxSLi7+WhixbU6wwfDo+A1PgwbJmcNZ/FDWJ4dxs+Zf3SNbXy9DQRiQUF/WxOPlEgUWNKmOcBRJF+ueJWFwd7w2H2rNN9wtONk8o8Xheb/xqrM+Urv+xVfWZyWzbcOzxK4ACfnsscuYyXX0J+SH2In4tLUO2piuMXK3T85liWAhidHKWoejPJ4TSI53EXsV4bwfUnn1fr4A1RNf/2Ko6ZhoNREOxLMfLB49guMm7jau3nyc5Gx0v48R06LpWKD/wuNFlUT7bgR7F1TfwieFQbQLSp8lLQUynA8XtOfDJLoFDs5Wp+/6w5Wik2c8qYYqpu5/fbEPHPBJkF3Kv4VGETPsEBbLQQM+sDpn68m622ph1y/Tuqww5iMXrrhvtsmC+KOz1c4HUqRN2pmSkmJRSvsDm9gVQashp8/pmGaREyPof8dMOC+0JyidY0rgAfH4zMSTPF0IZfAhrdhvr9/kGJ8dUQnahuBNl8UCf3c/T7Wg3+khfFJRmh+/aUN2UTEQZjC0dC0Kq3x9Z7ACfWdfTrzFNBcWDmaguE+ZNlA21Z90yPW/KEBxcvM4CN/J+mjyhfLEZ7QuUwpDTqc8S6mVe/+NP+Jgmoh7h7JFABOtWlPzMEBSX2qDK//TPwCWlfLIEjQv44LfUtBif2JeRH6JxpK+w/2T3RXLp4fPEsBAKe/3gInVCp/Rt7PBic3sUKDUECcM4Co/OHkFgfCBiSHEpbKr8L8HVzwQSx3IaZZyYViL40BrsNtZJ/M1JjKmUHequQlk8+mC3wc7WlmB+TFveG+zqmg8SoQ1K7RXutzu7wEViA4+fDiDU5Cp6j+0dnCAW50HbTSk/W/5JziBH7uqKPJozWCLI8tTAwOVHcet1OjfNwhHSKE8ZrHzmIigFayX89i5M79UEPnWbwNe3OXz9fscZ9RaIuoFlnVtg0vmk860MWoNW7rUwPWlHGvNEnsP4LuNxziKXxpR4vcsPpWtOxdV0XsXpKxo3/miMvBLhKFGaD74r7qZvMfd6ORrbSuDity99LrN/ZsrQA+hXXDf8le5HZFceY86mZ4OaQpG70DWPtjuISJYHNQYux9Fbr9N3u3+yPKFE0JpWcK813UB/O/NEnhuPLuPP6eIzGscGFIZU4gK/fcKUqCuY4ZMDDuVH4bipLpjK19jlVxo1p179og6OUu7T5ofXyxvDNm5dm/I5Ylh9BWyUJ2RWPpibsiDGrum90MSnLpr4+qK5rx9+P6O+PyEKN5Z1RotJ53Vv1KMMwppW7qg1Pf7gOvrYABSWxuXOKFyZ4YMcDuUxykQgJozlNMosMR19A380zguJuqtQPl+suJu+S2N2TFuY8tlSNMom7LdWNfHboxTEa5y3pzGyvCsqDEg66oUhr1c0gZ2wTrPUmIW7KTx++jQ36UWdwfDS1gkbZ1l2FPRugM5DZ2Lt0Xt4m4r1ZIry2R+oa603RFqyInFteWeUcsiLOuMO4almxSsRenwEGnWeh2XdisLK4QdsMLjPKxF2bARq1h6JE8ncl5FUFE5O7okZFhq8O/bBarSr3gFrH1jgtMRno0DQ1q4oph77UeyImlPOp//IC/IADC0hhazilFRdiskIws+Mgret/tBvIlh7/IRDKY7Z9BKFM8NLJxp5Q4bsBb3RoPNQzFx7FPcsnCg+aZ5QhuHYiJqoPfKEbsiqFIg6ick9ZyA+TcTi5vyGcMldFb3Hj0DHWt6o7bcA5wwNKfZRLB6sbofqHdYiQ6eHz5AfNDfySmWoOCW5q3KfPobV3Uz+qGsNSf7e0I2OlqzIa8vRuZQD8tYZh0PaIBYOoo9jRKPOmLesG4paOeAHw42dEMbHMKJmbYzUNXaxN+ejoUtuVO09HiM61oJ3bT8sOPdG2CuMSBLLaZFJYloRhK1di8FK3VXIsSamnE/3Fi8FMW1JSrxY1ghZheWUuPXDkRTW5pH3tmNItVyQ5a2Nwasv4rUZu1JsoHqEIKHmtKqC/91J2ZJ+mgJZEHVnDbp6ZE1QJMcnEClyevfBpvuWi3D1DQXFhI1faYrpy41actxa8j3yyWzwzeCjCEuw0kOxsXUuzVGdtc/c+LtrkxA2/JGJaNNh3mc7c6se5miIrx9W3EjDZdzPTnuwUV49jIvIFqX77/00faSUQZjrYwWxix/2pnCnlQdMh2/NKqhcqRIqpeWncmVUrz8EO9LxstoV9Y0R+v2Rhcbbrct2w8MmfQ5Rd7Cmq4cmgX6cx48/IkhzeqPPpvtCs2gZnzxPKF/gyMQ26DDPMme7Il/exdXLN42MoapPPWTUEPj6rUCGTg+fKT8og+bCx0oMF7+9yR9IfeIY1twEWkw4uK80xXiXBj3yW0vwfT4ZbL4ZjKMJgxihG1sjl/qsvLUP5hpv7IQwPoKJbTpgXlxjF6nuP38ZN42MT50+MklMaw6cyyObuquQbWn032tklA4LS1FMW0wk/ursBPWTXmVV/mfmEw+j8ezcBkzxq4WC+id4RNYo3HIRriZ3EfTNSjSxUd/QZ4vGy5O7MSAhkfo/wpd9GvJndHrTn7R531E6cfoC3XoeScqP3y4iW+/RdPT0RKqU6DnrihcXaPumvXTx/nN6G5uFcruVphq+rah+iexk7BHvEetbUN5O+6jmsue0189RN9Ww6MCJVNtnPAXm6E5/XVlOTRK8PYbOjyhL1affo1JjzlPgxLLGn0UvUEREkCJrVjL0qPh0p4ikSKUd2Vnrfs+Aoq/Npe+/G0IHQ8SU/4dldHRDFypiaoXHUbygC9s30d6L9+n521jKktuNStfwpVb1S1B2Y0GSwAfa0saF2u6qRAuD9lOf3Gb9kYbq5TnasuMCvZSrNHtu6olImq0UNexQj4qk1zZU3Kcl31ejvntD4p/JL8lLvsvO0NZuhUiim/R5yenZ6U305+Z9dPTEabpw67kQ1/FrVmTrTaOPnqaJiRPFR+F0fe3/aKt1DxrX2vQyfZ48oaCICAVlzfpps4QiUsi3dnaUgdND6vPDR+bHRgIftlAbl7a0q9JCCtrfh5JPD6mMYUUIBe5YS9uO3aDgmKzkWrg4la3jS82ruBrfbhHrqUXeTrSv5jJ6vtePTEZxdCBNrO1D4wNzUPe/rtDyhEFMMedHUNnq0+leqTF0Xoj3sqYbO4pQZKVPHMYJZPyYjqZrc7+n74YcpBBxfvph2VHa0KWIyRojjiIkkHas3UbHbgRTTFZXKly8LNXxbU5VXM1cGymOaQtQ3qGpVb+hXy8oyKbZnxSyqwvZ614yShVGVw/8TddDIigs+F8677+Btp8LJrl6dxJZkcfgQ3RhVk2y0747Kfk+6lG4Ga0IFlHRn4/Szd9rkJXupWRpyuTPIgrPrx7An+M7obyTTHtmWZwb7bfqD4yoRMjBUWjcZACWHL4NdbdlZfg9+I+sgRzWrmgw09ilNSVeLKwHK5G9iSFAdBT3MbeOPUQiGbzHX0t6VK8M0gyQLpLkQy/14MMs3aifFd+xsDoWxMjp8z9cNLN7rPrGzlGNm2DAksO4rQ0S3PMfiRo5rOHaYCbMu1oVhT3dnCGWVca0lHZUymCUTzeiXX5pgqs5Ysc6mJPKoXDSW9Tzqzjw53h0Ku8EmeasnBi5229NOGh++E3sX7UIs8b2Qxuf4nAQS1B4wPFkztJynshIUpsfUhcbiUTtQTdnMWSVp6W4H6OaOTGsfHkIoxvURrtJG3D82l3cCTyIZYN94CKzR4n2S3HNSIgqXyxEPSsR7FttSuZGcQXuz60De5EIMu/xuJY0iBGkfqiNSKIbd5ilLwUeb+yIwuonnopzwud/F2FeSCvx8tBoNKjdDpM2HMe1u3cQeHAZBvu4QGZfAu2XXjNvwIA0xnSqRB9F/0ISIf5FyNZ6s3nzmcRbXF3cCoV0T4oVO7bEelM3GspPYmAxqfY7k91HEvqMBXI8+c3ZqKMZq1UGz1EX4xsfzfi0tshR9mfs0R+gVn4ewz2EBt6mqpE+JUo8+q0GZOIc6LDdxFhoAvnpwXCXCglLZmQg/7eb0NpRDFH2FlhndID+zCAWN36rjwJOOZEjR45U/uRErryeGLAv5WGvfH0YQ8qpu+CIYOc1EAeMDEiseLACg6ee1mvcYnFtgjdsc5TFz3v071KV4/xwD0hFNqj6vztmXPaLxqE+BSAxFgeZihKv9/aBe6JHUTt12mFmgv5M5Dcxu476YRAEmecoXNTfTG8uYsvCZdh05CZeXJuMijLzCmTOE+bKqPlBkKrYSCT6EPoUkEBm5oMyjDIWw8rX2NalKvx2Jn66WSTOjiwjHMTJUHLwCYONu/LRb6ghEyNHh+3CYb4J8tMY7K4uFGRGHm71FptaO0Isyo4Wmbux04q9gd/qF4BTTkOxauZPzlzI6zkAKQ9pIQcfHoJyWdWX/u3gNfCAkTH4FXiwYjCmno6PVuXrbehS1Q87Ez/6NfIsRpaxgkhWEoNPmDFDlorplIjaC7+86lpPOMjtuMN0vJoUhcDxFWGrPtjUezS5QUK9OKKUOu4J1k1WpmgYwHQ8qa6iZ3/NpbU3FbrfjbPy6EbdfLKSellj5DHxl35JSUoo6M2/V+jeO/Xy6UhyUk5H4d2KEHoeotRNTMhKJhVSqYoUyvhPSyqGLu3eTw+FWZQWrEn1Sia9sCH/5yRdeC+0i2VqUPVsuomZkpRKdJpN6zasp/XrU/+zYf0qGlrTVveZZoq8THPatKU5lyJJ6taGFu+cSfWdDIWmgm6sWUOPnIsmuASlVIIUb/6lK/feaao9LQnlzOkoxICCQp6HCJGUPIVC/S4pWVmJtBMyLTHlbDSDlg/2oiyaRRWRJE8DGj+isfHLVOlI9ewvmrv2prB1k2HlQd26+VBW9anvGDnF6O/aDuWp1Y89qE0dD8olNX/7cZ4wV8bND6mNjYQUQowI/ye1IkPpIc0xHH2Utu66SNtGT6T9b3TTNGypYq/OVFkWS3c3rqHj0brJ+qxkJBXqLJUwgyaj+NJu2q8NYqpZr2TCdaQm/4dOXngvVO5lqEbmbuy0pCWo0+x1QkwajlXzfjbQ+lVDKeUhPYfatJ1DlyKl5NZmMe2cWZ8Mh/QNWrPmETkXjd9a0Ue30q6L22j0xP2UMFQqUq/OlUkWe5c2rjlOhkIlIdMxnS5EViSTqb8MpIxVmIxX02yo7I99qJ698FmqMHr92lQLL9SRmpdFJJZKjXbLNUhXKFue8iWW+/pgsllDAkTB3y+vcOSaBd8tCk5wBK0IvYfrDxPdEftmM9rmEkOctxO2GznQfbOyCWyEz2u+2sT1deULLKxnpTmacWy7xUB3jVhcGVsGMuGIu7T+mW2d2OfnsWnOWAzp1xN+vX7CyKnLsO/220RnAJhJsQ+wtq2b5rKj2KkeZl02ceQbfQIDyzbF0sR3lClCce/6QyS8gf8NNrfNBbE4LzoZC5IEorCjY06IrWpjjombUwxTIurNS7x4/hzP0/Lz4gVeh3+qQ3lhroMWoYF6uB27Mhhy+HM9flqJl8t94TPZvDupo/z9kFcsQpbvFiV9dr+O4tYUs88Sfoo8Eef9tTUYNWYzjA2BygywRH7Qk5LYSCBqBzrmFMOq9hwDN2BaIIajDuFHNynEOX2xOvFdh5Eb0DKr+sa5JlhpaGAJ3U1IWZqvNjGah647kdDkix3bYouBN8ZeUT/xVqiPSye6OiOIfXkRm2cNR5+undC9/whMnr8ZAU+5E0ZqxD5Yi7Zu2q5CTvVmwXRID0TZpksT3EQddehHuEnFyOm7OskNqpEbWiKr+kbhJithfJA9HZMxnU50T5pUd3fI0nxN2kafifss9VB1pu6s1zzCXN2tQ4y83f1TdNY6/c4gRwUIR6NiypbNjEMTVQjdfxBGyFKZGjdwTlDhS3IUJc9CDvHTVK/o+LQZtCeyKHWeM5maO+imJ5LFxYVyiRUU9uqV8bOHqpf0Mkx9zlFCJcuWpSzaqfFUwXTi1G1SSHJTpRqeekfcKnp16Ff6vuc6ele6HY2cvZSW/jaAqoWvoY5lSlHjWRcoQvdOZoKw3Q8MbUF9Nj8mhV05GrxxEw0qY+xQXEWh/stob97G1Djx3QSSHFTUsxA5xAcJvTo+jWbsiaSinefQZGNBksAHCg2NINjmIddcKdstov17UKGczpQnb17Km5afPHnIybk+/RGU+uNqs324QnO6jaGDH1zo+3lb6X91c6TsyNpioijg5AUSZ8smHN8nR0Uh9x9QGLJQ5cYNyNkCM5y+eSKCbh1YTYt/G0f929ahCjW70vT1pynI1MkOFs9S+cESPoRSaATINo+rEC+6aR9ZIIZt6tHvF/6lB/9upc6JAltx9xbdlwt1QKESVCJJ8AmyuJCLMFOKsFf0yngQ08uXQhsr/EtSsiyVTRrEFHziFN1WSCh3pRrk+TGIhfk9PIaatplN/7o0pL4jf6W+zYpQ2I5BVKtkGeqw7LqQOZm5VCEHaGiLPrT5sYLsyg2mjZsGkfGQDiX/ZXspb+PGCW6gs6n3O1349wH9u7VzohyooLu37pMcEipUokTSPJWYyZhOJ1I3KlYoi6a3gCIsxES8mgOkUpfaNqWpvHBkZxTC6I2mB4KEChQpQibemUS6rZaYSyfo7Otgevo02YtOpLyzgbacV1KB9kOos5uhWVLQ7Z3Taezw/tSxdgX6wd+dph45TSvaFDB6F7LUzY3yiUEvnj413vCJ7MlefU1ZZEMuBVySftab43Tsnxgiu4pUU/9uY8VNWjTydzr7TEwu37hTTuGwXJy1KDUeP4t6FnlJf48ZRAvucitoWgRdnNGWOs6/Sh+khYVEu0Mo0nIaDUhV2CEaN9qf3Bo3oTxG3qS4vZOmjx1O/TvWpgo/+JP71CN0ekUbKmDOreqKZ/QsRCUcjBakgkmuPZpm02Qp/fv8GT0NCqKgNP08peCn+6hvgXTOVqpntKN/axp1LIa8h2+kP7snuiT9KcVcohNnXwvL/TT5y9PKO7Rhy3lSFmhPQzq7WSR5pWueEJboQ/gHkuarRX3nzqVO7maPmcDSIT+kheLZMwpRScilYMGk+4qFYtjKqRC55UgcI+/o4MJ1dEOZk+r93IcqGrr9Xig63PKJCS+e0lPjQUz22iAmG5cC5JI0iOn4sX8ohuyoYs1KH0dhUoXupGHjnlPvzetodLtaVNq9OHl/24N+899OQ4s8pI392tCYk1wimyXiIs1o25HmXxVyQuEOtGzH/6huTqMRTWGHxtFofzdq3CRPori3IqdCbpQ0VA7SwnU3SJmzHv3cp2KyIzWYjGkd+bt39MGi52vsqWJlT1L3ssDz/0zEa/JUoZfo8kMVOTXoSM1N7PSqV0K7GiEshCQvlauYwpGadGeSLUyB21MqQkZSlBh00vSNP7G3saChE6yL+mGniUtjEc/v4dbNqwjYvxpjm7vDpVQLTDr0zPglrajd6OosRpbGK2D8Bkc5Tg1yh1RkD991ibtuv8XJYWWRRSSCVY3fEl4WVZ/aL2cFkV0tzNYfyE9xHzOqyUDSovj5ZIou4H1lYnHvzx+QXyaCSJIb9X+/avKyhyL4MMbWdoIkSx3MM3UtKOI57t26iasB+7F6bHO4u5RCi0mH8Myc656R29DOUQLHNpu/+Gf5p004zk2qDgexDG7tN+CxOesmHSluqy95E6QlBuGk6USB2wsawsm6KPx2mn6kcIouo6dnntCnuIUpFWWQFB6A45wakpFO+UGQ2i4WkdvawVHiiDabk2aH9IhhLSVe7++L4lZ28BpgarznKOzu6gxxlsZYYeJufvWY3+5SEex91yXJcW9PDkPZLML6tqqB3/SCOHJLGzjIsqNUP/9ED7dR4tHsmrBSX7b225uiy9Zfpdh7+POH/JAJeUKSuz5+v2oyohF8eCxqO0mQpc4887o/KF9jf9/isLLzwgAzx1E2FdNANC5Mq4mcEjHsvX7C3sQ3BKaB4uYUVLJSdxmqh4VGaz4lQm+dxPGLTxBu8C1RCBxbHnbOjbDotuluidEHeyOfhCBx6Y49KbwLPX0KZOVLLGtkB7FdMXiVKoP2K64Z7mvy9jIWty2G7G6+WHAlBXOuuI2ZNYXPz1IaQ44a6WmjfIGlDe0gLdQPR010T1HcngMfByny99gbP4/C/J+c4gvPPLYQCUV+qRHnk/QrTG3faKbEC/9+8BSSMYntUX7EsUQPXBDWbXQ4QoPvIfDgBswZ0gJlNMMAipDF53eY/2RK4SBtZk3YibOg9JCjyfbHir08Bl4ya/jMCzIruWRMCjxa3w5uMjEcqk8yc/i79KTEy2WNhG1kh2JepVCm/QpcM5wocHlxWxTL7gbfBVeSHWkjRUVQOueJj7hANlP65ofUFcixuDzGCzJrH8xL8ijn9IlhtfCLv+E7V1fUGX8MpusTYZ0tbQg7aSH0Mx3EmOPjAGn+HtgbH8R4eXIKfD3zaEYEkJYagfN6QWyx/q5fMyHH+PfzFA6iCWL78hhxLExY6/oUiA4PRfC9QBzcMAdDWpSBk3qEIVEW+Pz+KNF7DQnHxd++g6trHYw/lngUFGNMxbRAcQfTKqv7CpNmPmrPeah7wQKUQVjSKDtE4tzotMNII/RmPVo6qNeBDE7eXTD72NP4/VX5BpcWtUPpEk0x80xyhVYsbkz01pysLfbziRQfyKVPgRz5F7q4uqH1moeQP9+P0fWKIX/phug1bj5Wb9mBLStnYWRPX1TM74SSLSfjwBPTRwBJKfF4Ti3h6FUEu3p/GDnCUuDhnNqwkZXHxBumTpMpELRrMKrmK4ZGw37Hgpkj4Ne8KXovP4gZmnFN1R3AzVityhAcG+YNuyzu6LrpifCpzCD5cfxUJOEYvOb8iMQOaLDosZk7v5by8RzUshL+1q4e/jB5GK7Ek7k+2li5ntJYzDjenByFCvZiWLl3x/ZnKVmT6SUSf3VxhVvrNXgof479o+uhWP7SaNhrHOav3oIdW1Zi1sie8K2YH04lW2LygSfGC1A9KSuCPlGe4ALZPOmcH1JVICufYK6PDWTlJyJpekifGH5/YSbqF6+IflvumzUeseLhHNS2kaH8xBsm2x5F0C4MrpoPxRoNw+8LZmKEX3M07b0cB2doxz9WP1UtYRTLEfLwEUKTfGgsLo0WCiz1VeKhASk42Pj6yI//hCLqYUYMxK3xHxHEDg2w6HFyEf0eF2bWR/GK/bDlvjmRomMyptVicWd5GxTPkRPFqnqj0o8HdNMtI/LMMHgK+6GrEG8GDxZjr2NeAxfdmOHq/dsOrt/UQoMGtVG5ynfoPHY9LoWa0YYpbmJyRSthXdbHwlTcHZ0uBbIyZD/+WHZB76xxJB6d2oi5YweiZ9cO6NitL4ZOWoK911+bSBZKPN/eF+XyFUCd/wUm2QEj1vlqj3iL/gxjvRmUj+ejnp01qk6/m3zBGvUSt07txd7T9xCmnqn3unFN7ZtjldHLVrG4teN/GDOsHzrUKIicHu0wN0B/LF6W3pTPt6NvuXwoUOd/CEwaJPBVP5oyuS4vymAsbZQNNlWmwaxBVzKg2LvL4esqhThXXfx2JaXH0elEOKjc/8cyXNA7iRD56BQ2zh2LgT27okPHbug7dBKW7L2O1+ZUFTopLYLSP08IuED+IqSmQFYGL0WjbDaoMs3AKBXpEMNvz/0Pjau2waLLeh8qfM/2URNx2Niuq3yM+fXsYF11uhkPfYjCy1unsHfvadzTBrFu/GN7NDcZxHre7kUPNwnEOYUi7n4mTZpfvLc497/GqNpmERKGynaMmnjY5NlSkzGdiDJ4Ibr036/7zVLCcLCfO6xz/YD1RsY0Vz/w61HAHmz8czH+WLAMqzftxsmbISl6gE3kyUEoLrNHtWmpe7R/OvVBtgQ5zv5SElISI2fbLYn6TClwb3pV4ehVBPtGy4wO9wSEYnM7Z9hUnIybKdyHo4/0g5tEBKtqM2Bq/09x32hmUfKzv6CklIRE3RZbEnWlUtybjqoy4ejTvhGWGQ8STYFUN2sONF/5LFMe3ChfH8IgL1uIbTzQ1//TPOf/c0p5EZT+eYIL5C9DymNDicfz6yJrjuZY+QmuurwJmIoWTYdhb+IbJyL2oGfdkThnYqZDN7eDs01FTE55EKOfUOyKrKphhjnFbir6uzJLe4OAqS3QdNjeJPfYROzpibojz5mI75TFdPSxQWg3/Y7uNwt6fwq/ls+JsiMDDD4AJ81ib2G2jwOcGy5AMt2UjfqCC2ThOPfMSHiX6IhNifvIhJ/E0FJWENuVw8hTpntzxd6YgRoORdD3UAr6OCMWV8eV01w+KjnsrPlHHub0jWaWFXUGI71LoOOmxH2Hw3FyaClYie1QbuQpE33+onFuZGlkqzABlzNj4RJ9A/MbOEMsyYPGC2+aH8sZWGzgr/hGc/lun9l9ztI9T3CB/EVIcWxEn8PI0tlQYcLldN53lAg7PRG1nbKjYLlqqFZN76dqJZRzzw2HZn8mulEukdgbmFHDAUX6HjKrj3Oc2KvjUE59k2HJYTib7EKmpr8rsyhlGE5PrA2n7AVRTj9OhJ+qlcrBPbcDmv1pIlJSFNPRQjv6PX7V75huQbH3V6FVcW8MPmLpcfjf4+y4qnD1HoyDxs5Qm+GLLpDVZ5EfbB+G732awm/sPKze9he2r56B3tVckMO9GSYcNOdMbZTmUZ1Odeaa/7xxXf8ckdgZXXen5NjGnL7RzNLkD7Zj2Pc+aOo3FvNWb8Nf21djRu9qcMnhjmYTDpocxUIZtBLN87ij3yFDd/JmcMrn2NOnJGyEg4QyQw7DnC5bFhNxF6fPB326KynRJzCxWV3Uq1sL3kWd4eDgCMdcBeFV3Qd163yLITuTu3ScznmCC+TPJ9WxoUTQyubI494P6Z4ewneis7M4UT9U/R/z+vpGnR2JMk51MNf8INbefyESw7nr7mTO5KWyvyuzqPCdneEsNhQjuh9pCQwNMBYpKYtp5ZOVaP/D7+bnxFSIuLoQLcr5YMxRSx1wvRcO4pqgTN2xOGx86BezfOEFsk5sKO6e2Y9tq5dg4eJV2HHiLsJSssHensQI74JouuyRyQY7+vl1nD56ANvndkQJa3Xf1UJoO38vjp4MxOOPh+Rp7xvN0kMsQu+ewf5tq7Fk4WKs2nECd5MLEmUwNrYtgtIDDuB1pjuYicSlmT7IKZbC1Xcl7qXPCQAjFLg/tzGa/v4wY3U1smieSIQL5AxHGbwRbYuUxoADry3UcH8Kb3FyhDcKNl2GR6aDGNdPH8WB7XPRsYS1ZhSWQm3nY+/Rkwg0GMSp7+/Kvhwpimn5TSxs/wOmX0r/rRsbtBdjvv8OP+0M1k1Jrfc4OakFWo7ahYcWyLMi9X+Eo45MT/Hvcmrtu57Kr/KnURXUA6YnpqBri3rSqH1hZGVtTdbWMhIpYihaLie50pl8py+iHh7q4bRj6NywMlRj5l3K3nYTPdrYiuy1HyBQ0v0ZNclj+FmyabSU7u7pQXnTYdB6ZglyurXwB2q9uy5t3DWQSlvrJmcKKnq2zY9qd1hDIWVG0d6Dk6h6dt1Ln4Dy4XJqUX8XNTm5i3pmsB3AcnkiEeVtmlrVi8a+7kNHbs+jWsmN4s8+L/ktWvhDa9pddyPtGliaMlR6UPxLy1v70vryq8h/VAUyGMXXFlHPUfsozEodw9YkEykoJlqIYbmSnH2n06IeHnoPj3hLZ6f50bS3frR4aqMEDxmJ9O9FzQP8aN/USsk+mIJ9ZimM6Zh//qQ/ntejn5vkT9nDNVJLFU7vIu0ou33a2oyI8Aiytc9qkQdJZYwzyBby/vxvaFatI9Y+SNt5LUv0jWafkxLPdvWFT8NJOPlJ+x18GuFnJ6Cqgxgyt/bY8ImfBKII9scAL3vkarUBr3XTMhpL5YkEYgPx6zcySFz9sI9Pt33ZlM+wq68PGk46+Wm7JVnS+/P4rVk1dFz7IG1XcdLa35V9GTJDTH8GX80Z5DiK4EC6ElOGyrsZe7iiOWLo4Y4xNOSP25SzxrdU85sClDXyXzq49Hfa+qo8/fzHIvr1WwOPpGVfCCU9u3yZFB7lqWCmOnMsLNmjddS+dnfa9r4yTfx7P/1a0dD5o/SgpJen51Lfbr/Szkc5qPP2O7Sqefy1lYzGMnlCTicntaaJJyNJ8eYJ3XnwmmJEUspWoAQVzmVF0jIDaNOs7ymH7t3sC6F8RpcvK8ijfMGMdeY4MUUwBV6JoTLl3VL9KPmIv7pQ0ZZr6KWxxw1LS9DQk1dpZhU+f/xFyywx/Yl9dQWyRSnC6N8LF+j6/SAKibKmPCWrUO1q7uTIlTH7HN6eoJH1mtKM63mp66ZjtMzXxTKXmUxS0tvb+2n5rCn029rz9CIWJHH7kf6+vZDq2ujewhhjjGUwXCAzlhnE3KXlretSnz1yqj3zMPkP9qJ0q08V7+jJ9Yt0+she2rltOx24+JQiVXFpREolfjlJV2dU4T6JjDHGMiwukBnL6FSv6NDgevT9vOsUW6gx/dS1EjmIdK+lFlSkVChJEfOBIsLf07s3ofQq5AUF//eEHj15Tm+jlZoxhRITycrRmIvnaYJXWromMMYYY58XF8iMZWhyujG/OdUd+DeFGOsn+MmIyKbadLp64hdy525GjDHGMjAehIyxDCzm/ETq8MvBL6A4FojsqEb7NlSUi2PGGGMZHJ9BZiwjU4RTyMv3JFd9ARWy2IqyOTlTdu58zBhjLIPjApkxxhhjjDE93MWCMcYYY4wxPVwgM8YYY4wxpocLZMYYY4wxxvRwgcwYY4wxxpgeLpAZY4wxxhjTwwUyY4wxxhhjerhAZixTiqEH/tNo6Pid9Eipm5Rewq/T2l/H0pZ0/yLGGGPs0+BxkBnLjORHqV/x72ipqA/9fecPqmOtm24hEbcO0PaTN+nhjYt06vDfdOJ+Dup35DbNq8VPCWGMMZbx8RlkxjIj61o0zv80XQ2ca/HiWE3xIZw+SPNRrb5zaW4nd+KnSzPGGMtMuEBmLFOSUG7PyuSRM31KV4fyrejHHm2ojkcukop0ExljjLFMggtkxjIbpZzkCt2/GWOMMZZiXCAzlll8uEXrh7an1t37Ude631D1gTvpP5XuNcYYY4yZjQtkxjID5RNa3384/VPnN9q4ejmt6F2ULi8YTnMCYnRvIFLcmkMNCualPM7O5JySnzx5qWDDOXSLB6lgjDH2leBRLBjL8FQUuq0ndbreh3ZOqEDWpKRbU6pQmQlRNPTMZZpaQap7n4LevXxJETEq4S9SQCwmq6xCoZw97nP0Ken21KrkNfY19eFRLBhjjGUSXCAzluGp6O3NQArOV5E8sqt/fUFLGxehvlfa0M4HK6mprfZd6YMLZMYYY5kPd7FgLMMTk0MpXXGsFhVApwLllKVCDaqarsUxY4wxljnxGWTGMpmYUwOpVJ2F5Dz1Np34pUj8GMXvrtPuLafoP7mKUrTTi8Rknb8GtW5WmuJq8Hh8BpkxxljmwwUyY5mKULBOqUJe4yNo0KkrNL1yfMGqDNpFkybuoEcxSGGBLCKrQi1p7JhmVCDJsMpcIDPGGMt8uEBmLDOJ6398tS399XAFNbHRTU83CvpntDdV+V8odd5zn5Y3TPcvZIwxxtId90FmLDPR9T+2rVCDqqRjrSo/OYma1/uW6tWuTG2XB5Fdtg+068fKVKNOPar73VD6K0z3RsYYYywD4jPIjGUi2v7HiyjPtNt0fGjh+P7HjDHGGDMbn0FmLAOLfnyOjv7znLSPA4mhwF0H6LHUm5o0KcjFMWOMMZZKXCAzllHJj9OwujXou2Zj6IhcKJavzqXRf76kMoOnUZ8SXB4zxhhjqcUFMmMZlSQ3uRfPTTndpHRhfCdq4LePCk86QIcm1TIwHBtjjDHGzMV9kBnL0D5QyL/3KVjhSEWK5yd7PnHMGGOMpRkXyIwxxhhjjOnhLhaMMcYYY4zp4QKZMcYYY4wxPVwgM8YYY4wxpocLZMYYY4wxxvRwgcwYY4wxxpgeLpAZY4wxxhjTwwUyY4wxxhhjerhAZowxxhhjTA8XyIwxxhhjjOnhApkxxhhjjDE9XCAzxhhjjDGmhwtkxhhjjDHG9HCBzBhjjDHGmB4ukBljjDHGGNPDBTJjjDHGGGN6uEBmjDHGGGNMDxfIjDHGGGOMfUT0f+/Y0/XxdTo9AAAAAElFTkSuQmCC)"
      ],
      "metadata": {
        "id": "yZ7KUX8duwOU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH1UdDIvPSRO"
      },
      "source": [
        "# **pre-processing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMEgIBPiMAWA"
      },
      "source": [
        "**device**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-10T18:14:58.899380Z",
          "iopub.status.busy": "2024-03-10T18:14:58.898400Z",
          "iopub.status.idle": "2024-03-10T18:14:58.906131Z",
          "shell.execute_reply": "2024-03-10T18:14:58.905099Z",
          "shell.execute_reply.started": "2024-03-10T18:14:58.899340Z"
        },
        "id": "omvoHqrldT13",
        "outputId": "7f3321b6-e7a7-4289-f2f0-0c30706fbe05",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.transforms as transforms\n",
        "no_cuda = False\n",
        "use_gpu = not no_cuda and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rmo_V2N8L155"
      },
      "source": [
        "**training, validation, test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-10T18:14:58.917692Z",
          "iopub.status.busy": "2024-03-10T18:14:58.917419Z",
          "iopub.status.idle": "2024-03-10T18:15:00.688383Z",
          "shell.execute_reply": "2024-03-10T18:15:00.687373Z",
          "shell.execute_reply.started": "2024-03-10T18:14:58.917658Z"
        },
        "id": "Z_afz4wleLNb",
        "outputId": "fb3f768a-9b5d-484f-b6fd-fdc0ca779a45",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 47828714.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Train: 40000\n",
            "Val: 10000\n",
            "Test: 10000\n"
          ]
        }
      ],
      "source": [
        "batch_size = 16\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_set_size = int(len(trainset) * 0.8)\n",
        "valid_set_size = len(trainset) - train_set_size\n",
        "train_set, val_set = torch.utils.data.random_split(trainset, [ train_set_size , valid_set_size ])\n",
        "train_loader = torch.utils.data.DataLoader( train_set, batch_size=batch_size, shuffle=True,drop_last=True, num_workers=2)\n",
        "val_loader = torch.utils.data.DataLoader( val_set, batch_size=batch_size, shuffle=True,drop_last=True, num_workers=2)\n",
        "\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1, shuffle=False)\n",
        "\n",
        "print('Train: {}\\nVal: {}\\nTest: {}'.format(len(train_set), len(val_set), len(test_set)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2GOFW-nMC4p"
      },
      "source": [
        "**model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T18:15:00.691030Z",
          "iopub.status.busy": "2024-03-10T18:15:00.690703Z",
          "iopub.status.idle": "2024-03-10T18:15:00.871621Z",
          "shell.execute_reply": "2024-03-10T18:15:00.870598Z",
          "shell.execute_reply.started": "2024-03-10T18:15:00.691004Z"
        },
        "id": "rgh1Dln4ePVr",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        #stack 1\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1, padding_mode='zeros')\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        #stack 2\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        #stack 3\n",
        "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.conv7 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        #stack 4\n",
        "        self.conv8 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.conv9 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.conv10 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        #stack 5\n",
        "        self.conv11 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.conv12 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.conv13 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "        self.classifier2 = nn.Linear(512 * 1 * 1, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv6(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv7(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.conv8(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv9(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv10(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.conv11(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv12(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv13(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        #x = torch.flatten(x, 1)\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = self.classifier2(x)\n",
        "        #x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "model_to_quantize = Net().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2kC5PCOtn8x"
      },
      "source": [
        "**1.   floating point model size 60.62MB**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-10T18:15:00.873299Z",
          "iopub.status.busy": "2024-03-10T18:15:00.872978Z",
          "iopub.status.idle": "2024-03-10T18:15:14.017461Z",
          "shell.execute_reply": "2024-03-10T18:15:14.016129Z",
          "shell.execute_reply.started": "2024-03-10T18:15:00.873272Z"
        },
        "id": "gRW0VT8NmP7d",
        "outputId": "644be0db-6f09-4698-f4ff-5f088ba9dcd8",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "              ReLU-2           [-1, 64, 32, 32]               0\n",
            "            Conv2d-3           [-1, 64, 32, 32]          36,928\n",
            "              ReLU-4           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-5           [-1, 64, 16, 16]               0\n",
            "            Conv2d-6          [-1, 128, 16, 16]          73,856\n",
            "              ReLU-7          [-1, 128, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]         147,584\n",
            "              ReLU-9          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-10            [-1, 128, 8, 8]               0\n",
            "           Conv2d-11            [-1, 256, 8, 8]         295,168\n",
            "             ReLU-12            [-1, 256, 8, 8]               0\n",
            "           Conv2d-13            [-1, 256, 8, 8]         590,080\n",
            "             ReLU-14            [-1, 256, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         590,080\n",
            "             ReLU-16            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-17            [-1, 256, 4, 4]               0\n",
            "           Conv2d-18            [-1, 512, 4, 4]       1,180,160\n",
            "             ReLU-19            [-1, 512, 4, 4]               0\n",
            "           Conv2d-20            [-1, 512, 4, 4]       2,359,808\n",
            "             ReLU-21            [-1, 512, 4, 4]               0\n",
            "           Conv2d-22            [-1, 512, 4, 4]       2,359,808\n",
            "             ReLU-23            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-24            [-1, 512, 2, 2]               0\n",
            "           Conv2d-25            [-1, 512, 2, 2]       2,359,808\n",
            "             ReLU-26            [-1, 512, 2, 2]               0\n",
            "           Conv2d-27            [-1, 512, 2, 2]       2,359,808\n",
            "             ReLU-28            [-1, 512, 2, 2]               0\n",
            "           Conv2d-29            [-1, 512, 2, 2]       2,359,808\n",
            "             ReLU-30            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-31            [-1, 512, 1, 1]               0\n",
            "           Linear-32                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,719,818\n",
            "Trainable params: 14,719,818\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 4.46\n",
            "Params size (MB): 56.15\n",
            "Estimated Total Size (MB): 60.62\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "\n",
        "summary(model_to_quantize,(3,32,32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHRyjDdoMlEX"
      },
      "source": [
        "**pre-training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-10T18:15:14.020754Z",
          "iopub.status.busy": "2024-03-10T18:15:14.020364Z",
          "iopub.status.idle": "2024-03-10T18:15:59.478406Z",
          "shell.execute_reply": "2024-03-10T18:15:59.477165Z",
          "shell.execute_reply.started": "2024-03-10T18:15:14.020722Z"
        },
        "id": "LrOvcugbpJtM",
        "outputId": "117fa1d6-6e67-4b1a-d425-d339bf35aa97",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished \n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "LR = 0.01\n",
        "n_epoch = 1\n",
        "optimizer = optim.SGD(model_to_quantize.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "\n",
        "train_loss = []\n",
        "train_accu = []\n",
        "total_train = 0\n",
        "correct_train = 0\n",
        "\n",
        "train_loss_compare=[]\n",
        "train_accu_compare=[]\n",
        "val_loss = []\n",
        "val_accu = []\n",
        "total_val = 0\n",
        "correct_val = 0\n",
        "for epoch in range(n_epoch):  # loop over the dataset multiple times]\n",
        "    running_loss_train = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        if use_gpu:\n",
        "            inputs, labels = inputs.cuda(),labels.cuda()\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad() #reset gradient\n",
        "        # forward + backward + optimize\n",
        "        # compute gradient and do SGD steps\n",
        "        outputs = model_to_quantize(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step() #更新權重\n",
        "        #將data傳入model進行forward propagation\n",
        "        #計算loss\n",
        "        #清空前一次的gradient\n",
        "        #根據loss進行back propagation，計算gradient\n",
        "        #做gradient descent\n",
        "        _, predicted = torch.max(outputs.data, 1) #不加_returen數值,加return位置\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "        accu = 100.*correct_train/total_train\n",
        "        # print statistics\n",
        "        running_loss_train += loss.item()\n",
        "        if ( (i >= 1875) and (i <= 2500) ):\n",
        "            train_accu_compare.append(accu)\n",
        "            train_loss_compare.append(loss.item())\n",
        "        #print(\"count %d\" %(i) )\n",
        "        if i % 100 ==99:   # print every 100 mini-batches\n",
        "            #print(f'[{epoch + 1}, {i + 1:5d}] Training loss: {running_loss_train / 100:.3f}')\n",
        "            #print(f'Correct train: {correct_train} Total train: {total_train} Train accu: {accu} ')\n",
        "            train_loss.append(loss.item())\n",
        "            train_accu.append(accu)\n",
        "            running_loss_train = 0.0\n",
        "            total_train = 0\n",
        "            correct_train = 0\n",
        "        i += 1\n",
        "\n",
        "    running_loss_val = 0.0\n",
        "    for i, data in enumerate(val_loader, 0):\n",
        "        inputs, labels = data\n",
        "        if use_gpu:\n",
        "            inputs, labels = inputs.cuda(),labels.cuda()\n",
        "        outputs = model_to_quantize(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1) #不加_returen數值,加return位置\n",
        "        total_val += labels.size(0)\n",
        "        correct_val += (predicted == labels).sum().item()\n",
        "        accu = 100.*correct_val/total_val\n",
        "        # print statistics\n",
        "        running_loss_val += loss.item()\n",
        "        val_accu.append(accu)\n",
        "        #print(\"count %d\" %(i) )\n",
        "        if i % 100 ==99:   # print every 100 mini-batches\n",
        "            #print(f'[{epoch + 1}, {i + 1:5d}] validation loss: {running_loss_val / 100:.3f}')\n",
        "            #print(f'Correct validation: {correct_val} Total validation: {total_val} validation accu: {accu} ')\n",
        "            running_loss_val = 0.0\n",
        "            total_val = 0\n",
        "            correct_val = 0\n",
        "        i += 1\n",
        "\n",
        "print('Finished ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dWo7NZSM_MP"
      },
      "source": [
        "## **quantization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T18:15:59.480707Z",
          "iopub.status.busy": "2024-03-10T18:15:59.480256Z",
          "iopub.status.idle": "2024-03-10T18:15:59.486463Z",
          "shell.execute_reply": "2024-03-10T18:15:59.485548Z",
          "shell.execute_reply.started": "2024-03-10T18:15:59.480647Z"
        },
        "id": "tCnR4tzIqdp3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from torch.ao.quantization import get_default_qconfig\n",
        "from torch.ao.quantization.quantize_fx import prepare_fx, convert_fx\n",
        "from torch.ao.quantization import QConfigMapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T18:15:59.488346Z",
          "iopub.status.busy": "2024-03-10T18:15:59.487959Z",
          "iopub.status.idle": "2024-03-10T18:15:59.498430Z",
          "shell.execute_reply": "2024-03-10T18:15:59.497453Z",
          "shell.execute_reply.started": "2024-03-10T18:15:59.488311Z"
        },
        "id": "m7l467EGq4or",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# set different quantization config\n",
        "qconfig = get_default_qconfig('qnnpack')\n",
        "\"\"\" (below is example of different configuration)\n",
        "qconfig = get_default_qconfig(\"fbgemm\")\n",
        "qconfig = torch.ao.quantization.default_qconfig\n",
        "qconfig = torch.ao.quantization.qconfig.QConfig(\n",
        "    activation=torch.ao.quantization.observer.HistogramObserver.with_args(\n",
        "        qscheme=torch.per_tensor_symmetric,\n",
        "        dtype=torch.qint8,\n",
        "    ),\n",
        "    weight=torch.ao.quantization.observer.PerChannelMinMaxObserver.with_args(\n",
        "        #ch_axis=1,\n",
        "        qscheme=torch.per_channel_symmetric,\n",
        "        dtype=torch.qint8,\n",
        "        ))\n",
        "\"\"\"\n",
        "qconfig_mapping = QConfigMapping().set_global(qconfig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T18:15:59.500028Z",
          "iopub.status.busy": "2024-03-10T18:15:59.499674Z",
          "iopub.status.idle": "2024-03-10T18:15:59.993730Z",
          "shell.execute_reply": "2024-03-10T18:15:59.992846Z",
          "shell.execute_reply.started": "2024-03-10T18:15:59.500003Z"
        },
        "id": "H-LL1H9Lq_zL",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "example_inputs = (next(iter(train_loader))[0]) #to know model input data type\n",
        "prepared_model = prepare_fx(model_to_quantize, qconfig_mapping, example_inputs) # prepare to quantize model (fuse module (ex:CONV+BN+RELU...)，insert observer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-hs6ppgABOj"
      },
      "source": [
        "## **PTQ : do calibration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T18:15:59.995631Z",
          "iopub.status.busy": "2024-03-10T18:15:59.995229Z",
          "iopub.status.idle": "2024-03-10T18:20:01.595482Z",
          "shell.execute_reply": "2024-03-10T18:20:01.594268Z",
          "shell.execute_reply.started": "2024-03-10T18:15:59.995600Z"
        },
        "id": "MQ9iNs1orUd6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def calibrate(model, device, data_loader):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data, target in data_loader:\n",
        "            data, target = data.to(device), target.to(device) #device\n",
        "            model(data)\n",
        "calibrate(prepared_model, 'cpu', test_loader)  # run calibration on sample data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T18:20:01.597866Z",
          "iopub.status.busy": "2024-03-10T18:20:01.597390Z",
          "iopub.status.idle": "2024-03-10T18:20:02.296920Z",
          "shell.execute_reply": "2024-03-10T18:20:02.295969Z",
          "shell.execute_reply.started": "2024-03-10T18:20:01.597814Z"
        },
        "id": "lYYfxl9Ygx3n",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "quantized_model = convert_fx(prepared_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-10T18:20:02.303131Z",
          "iopub.status.busy": "2024-03-10T18:20:02.302800Z",
          "iopub.status.idle": "2024-03-10T18:20:15.449320Z",
          "shell.execute_reply": "2024-03-10T18:20:15.448104Z",
          "shell.execute_reply.started": "2024-03-10T18:20:02.303100Z"
        },
        "id": "gkKXwg_MllW_",
        "outputId": "0d9f324f-f0df-427e-eb6b-c99118ff32eb",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.15.0\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-10T18:20:15.451257Z",
          "iopub.status.busy": "2024-03-10T18:20:15.450943Z",
          "iopub.status.idle": "2024-03-10T18:20:17.136419Z",
          "shell.execute_reply": "2024-03-10T18:20:17.135442Z",
          "shell.execute_reply.started": "2024-03-10T18:20:15.451229Z"
        },
        "id": "JDLcJVLBlqen",
        "outputId": "8c0395fc-1933-428e-faba-10d87d84a499",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:1531: OnnxExporterWarning: Exporting to ONNX opset version 19 is not supported. by 'torch.onnx.export()'. The highest opset version supported is 17. To use a newer opset version, consider 'torch.onnx.dynamo_export()'. Note that dynamo_export() is in preview. Please report errors with dynamo_export() as Github issues to https://github.com/pytorch/pytorch/issues.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "data = torch.randn(1, 3, 32, 32)\n",
        "data.to(device)\n",
        "torch.onnx.export(\n",
        "    model_to_quantize,\n",
        "    data,\n",
        "    'float_model.onnx',\n",
        "    export_params=True,\n",
        "    opset_version=19,\n",
        ")\n",
        "\n",
        "torch.onnx.export(\n",
        "    quantized_model,\n",
        "    data,\n",
        "    'PTQ_model.onnx',\n",
        "    export_params=True,\n",
        "    opset_version=19,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CIcw562NqCg"
      },
      "source": [
        "**print out each node name**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-10T18:20:17.138268Z",
          "iopub.status.busy": "2024-03-10T18:20:17.137942Z",
          "iopub.status.idle": "2024-03-10T18:20:17.158367Z",
          "shell.execute_reply": "2024-03-10T18:20:17.157250Z",
          "shell.execute_reply.started": "2024-03-10T18:20:17.138239Z"
        },
        "id": "91HZ1WvL0R6G",
        "outputId": "492d0bd5-f843-44c8-cb6c-38a227b0a180",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['x', 'quantize_per_tensor', 'conv1', 'conv2', 'pool', 'conv3', 'conv4', 'pool_1', 'conv5', 'conv6', 'conv7', 'pool_2', 'conv8', 'conv9', 'conv10', 'pool_3', 'conv11', 'conv12', 'conv13', 'pool_4', 'size', 'reshape', 'classifier2', 'dequantize']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
            "  torch.has_cuda,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'\n",
            "  torch.has_cudnn,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
            "  torch.has_mps,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'\n",
            "  torch.has_mkldnn,\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision.models import vgg16_bn\n",
        "from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names\n",
        "\n",
        "train_nodes, eval_nodes = get_graph_node_names(quantized_model)\n",
        "print(train_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wdnD0lq7CVW"
      },
      "source": [
        "**put test image[0] into PTQ quant model**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-10T18:20:17.160701Z",
          "iopub.status.busy": "2024-03-10T18:20:17.159959Z",
          "iopub.status.idle": "2024-03-10T18:20:17.172835Z",
          "shell.execute_reply": "2024-03-10T18:20:17.171819Z",
          "shell.execute_reply.started": "2024-03-10T18:20:17.160638Z"
        },
        "id": "oT8IxX5g25Hz",
        "outputId": "b307a6c6-9225-48a9-a411-b5a5e897d74d",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 32, 32])\n",
            "tensor(3)\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "print(images.shape)\n",
        "print(labels[0])\n",
        "\n",
        "#torch.set_printoptions(profile='full')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-10T18:20:17.174958Z",
          "iopub.status.busy": "2024-03-10T18:20:17.174219Z",
          "iopub.status.idle": "2024-03-10T18:20:17.194989Z",
          "shell.execute_reply": "2024-03-10T18:20:17.193337Z",
          "shell.execute_reply.started": "2024-03-10T18:20:17.174917Z"
        },
        "id": "MMpQOGpS4qfv",
        "outputId": "a0519607-4566-4084-8018-b83d30a7faa4",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "input_image = images[0].unsqueeze(0)\n",
        "print(input_image.shape)\n",
        "output = quantized_model(input_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpOvWi0qN55Z"
      },
      "source": [
        "**use create feature extractor or hook to print out first layer ofmap**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-10T18:20:17.196527Z",
          "iopub.status.busy": "2024-03-10T18:20:17.196222Z",
          "iopub.status.idle": "2024-03-10T18:20:17.237384Z",
          "shell.execute_reply": "2024-03-10T18:20:17.236432Z",
          "shell.execute_reply.started": "2024-03-10T18:20:17.196501Z"
        },
        "id": "ZELcj-Fm-mV3",
        "outputId": "5a32d6c0-0666-4cad-a896-98935a8d0593",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0,  0,  0,  ...,  0,  0,  0],\n",
            "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
            "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
            "         ...,\n",
            "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
            "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
            "         [ 0, 14, 11,  ...,  7,  9,  5]],\n",
            "\n",
            "        [[ 0,  0,  0,  ...,  0,  0, 20],\n",
            "         [ 0,  0,  0,  ...,  0,  0, 18],\n",
            "         [ 0,  0,  0,  ...,  0,  0, 19],\n",
            "         ...,\n",
            "         [81, 66, 50,  ..., 65, 46,  0],\n",
            "         [68, 66, 52,  ..., 63, 50,  0],\n",
            "         [63, 50, 45,  ..., 52, 31,  3]],\n",
            "\n",
            "        [[ 0,  0,  0,  ...,  0,  0,  0],\n",
            "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
            "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
            "         ...,\n",
            "         [10,  0,  0,  ...,  0,  0,  0],\n",
            "         [14,  0,  0,  ...,  0,  0,  0],\n",
            "         [ 1,  0,  0,  ...,  0,  0,  0]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0,  0,  0,  ...,  0,  0, 10],\n",
            "         [ 0,  0,  1,  ...,  7, 10, 13],\n",
            "         [ 0,  0,  0,  ...,  8,  9, 15],\n",
            "         ...,\n",
            "         [16, 17, 21,  ..., 14, 23, 21],\n",
            "         [20, 11, 20,  ..., 24,  8, 34],\n",
            "         [18,  9, 18,  ..., 23, 23, 37]],\n",
            "\n",
            "        [[ 0, 11, 11,  ..., 13, 16, 27],\n",
            "         [16, 31, 36,  ..., 22, 23, 10],\n",
            "         [15, 27, 33,  ..., 22, 19,  8],\n",
            "         ...,\n",
            "         [ 0,  0,  0,  ...,  0,  1, 35],\n",
            "         [ 4,  0,  0,  ...,  8,  0, 30],\n",
            "         [ 7,  0,  0,  ...,  0,  0,  3]],\n",
            "\n",
            "        [[ 0,  9,  6,  ..., 26, 28, 16],\n",
            "         [ 0, 25, 24,  ..., 43, 49, 11],\n",
            "         [ 0, 26, 22,  ..., 39, 43,  8],\n",
            "         ...,\n",
            "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
            "         [ 0,  0,  0,  ...,  1,  8,  0],\n",
            "         [ 0,  0,  0,  ...,  0,  0,  0]]], dtype=torch.uint8)\n",
            "torch.Size([1, 64, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "features = []\n",
        "def hook(module, input, output):\n",
        "    features.append(output.clone().detach())\n",
        "model2 = create_feature_extractor(quantized_model, [\"conv1\"])\n",
        "handle = model2.conv1.register_forward_hook(hook)\n",
        "output = quantized_model(input_image)\n",
        "print(features[0][0].int_repr()) #[batch][channel][row][column]\n",
        "print(features[0].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-10T18:20:17.239160Z",
          "iopub.status.busy": "2024-03-10T18:20:17.238841Z",
          "iopub.status.idle": "2024-03-10T18:20:17.329366Z",
          "shell.execute_reply": "2024-03-10T18:20:17.328354Z",
          "shell.execute_reply.started": "2024-03-10T18:20:17.239114Z"
        },
        "id": "3IhpFrdmHMnR",
        "outputId": "8a429994-6058-41df-89da-00a4e0e93ddc",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GraphModule(\n",
            "  (conv1): QuantizedConvReLU2d(3, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.005269043147563934, zero_point=0, padding=(1, 1))\n",
            "  (conv2): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.001722783432342112, zero_point=0, padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): QuantizedConvReLU2d(64, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.000698996998835355, zero_point=0, padding=(1, 1))\n",
            "  (conv4): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.00029162937426008284, zero_point=0, padding=(1, 1))\n",
            "  (conv5): QuantizedConvReLU2d(128, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.0001658321125432849, zero_point=0, padding=(1, 1))\n",
            "  (conv6): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.0001236225652974099, zero_point=0, padding=(1, 1))\n",
            "  (conv7): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.00010973600728902966, zero_point=0, padding=(1, 1))\n",
            "  (conv8): QuantizedConvReLU2d(256, 512, kernel_size=(3, 3), stride=(1, 1), scale=9.657555347075686e-05, zero_point=0, padding=(1, 1))\n",
            "  (conv9): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=7.829765672795475e-05, zero_point=0, padding=(1, 1))\n",
            "  (conv10): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=7.099544745869935e-05, zero_point=0, padding=(1, 1))\n",
            "  (conv11): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=6.575716543011367e-05, zero_point=0, padding=(1, 1))\n",
            "  (conv12): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=6.199235212989151e-05, zero_point=0, padding=(1, 1))\n",
            "  (conv13): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=5.678638262907043e-05, zero_point=0, padding=(1, 1))\n",
            "  (classifier2): QuantizedLinear(in_features=512, out_features=10, scale=0.0007401232724078, zero_point=93, qscheme=torch.per_tensor_affine)\n",
            ")\n",
            "\n",
            "\n",
            "\n",
            "def forward(self, x):\n",
            "    conv1_input_scale_0 = self.conv1_input_scale_0\n",
            "    conv1_input_zero_point_0 = self.conv1_input_zero_point_0\n",
            "    quantize_per_tensor = torch.quantize_per_tensor(x, conv1_input_scale_0, conv1_input_zero_point_0, torch.quint8);  x = conv1_input_scale_0 = conv1_input_zero_point_0 = None\n",
            "    conv1 = self.conv1(quantize_per_tensor);  quantize_per_tensor = None\n",
            "    conv2 = self.conv2(conv1);  conv1 = None\n",
            "    pool = self.pool(conv2);  conv2 = None\n",
            "    conv3 = self.conv3(pool);  pool = None\n",
            "    conv4 = self.conv4(conv3);  conv3 = None\n",
            "    pool_1 = self.pool(conv4);  conv4 = None\n",
            "    conv5 = self.conv5(pool_1);  pool_1 = None\n",
            "    conv6 = self.conv6(conv5);  conv5 = None\n",
            "    conv7 = self.conv7(conv6);  conv6 = None\n",
            "    pool_2 = self.pool(conv7);  conv7 = None\n",
            "    conv8 = self.conv8(pool_2);  pool_2 = None\n",
            "    conv9 = self.conv9(conv8);  conv8 = None\n",
            "    conv10 = self.conv10(conv9);  conv9 = None\n",
            "    pool_3 = self.pool(conv10);  conv10 = None\n",
            "    conv11 = self.conv11(pool_3);  pool_3 = None\n",
            "    conv12 = self.conv12(conv11);  conv11 = None\n",
            "    conv13 = self.conv13(conv12);  conv12 = None\n",
            "    pool_4 = self.pool(conv13);  conv13 = None\n",
            "    size = pool_4.size(0)\n",
            "    reshape = pool_4.reshape(size, -1);  pool_4 = size = None\n",
            "    classifier2 = self.classifier2(reshape);  reshape = None\n",
            "    dequantize_20 = classifier2.dequantize();  classifier2 = None\n",
            "    return dequantize_20\n",
            "    \n",
            "# To see more debug info, please use `graph_module.print_readable()`\n"
          ]
        }
      ],
      "source": [
        "print(quantized_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMsT7s--OH8g"
      },
      "source": [
        "**print bias, weight & weight scale & weight zero point , ifmap scale**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-10T18:20:17.331439Z",
          "iopub.status.busy": "2024-03-10T18:20:17.330839Z",
          "iopub.status.idle": "2024-03-10T18:20:17.339302Z",
          "shell.execute_reply": "2024-03-10T18:20:17.338232Z",
          "shell.execute_reply.started": "2024-03-10T18:20:17.331405Z"
        },
        "id": "eczd-XnJH3hK",
        "outputId": "5874b6c5-96d4-4a5c-81fa-50e8849aa78e",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-0.1345)\n",
            "tensor([[[-0.0653, -0.0040, -0.0613],\n",
            "         [-0.1212, -0.0013,  0.0306],\n",
            "         [ 0.0972,  0.1279, -0.0386]],\n",
            "\n",
            "        [[-0.0440,  0.0266,  0.1172],\n",
            "         [ 0.0067, -0.1199, -0.0506],\n",
            "         [ 0.1425,  0.1678,  0.1066]],\n",
            "\n",
            "        [[ 0.0373,  0.1412,  0.1279],\n",
            "         [ 0.0666,  0.1452, -0.0799],\n",
            "         [ 0.0280, -0.0320, -0.0280]]], size=(3, 3, 3), dtype=torch.qint8,\n",
            "       quantization_scheme=torch.per_tensor_affine, scale=0.0013320236466825008,\n",
            "       zero_point=0)\n",
            "0.005269043147563934\n"
          ]
        }
      ],
      "source": [
        "print(quantized_model.conv1.bias()[0])\n",
        "print(quantized_model.conv1.weight()[0]) #print kernel 0\n",
        "print(quantized_model.conv1.scale) #conv1 ifmap scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-10T18:25:50.499899Z",
          "iopub.status.busy": "2024-03-10T18:25:50.499083Z",
          "iopub.status.idle": "2024-03-10T18:25:50.509169Z",
          "shell.execute_reply": "2024-03-10T18:25:50.508152Z",
          "shell.execute_reply.started": "2024-03-10T18:25:50.499863Z"
        },
        "id": "pKZiN18nuyVs",
        "outputId": "c2efe001-8d95-475f-de8a-62c05e5d5a9d",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.0653, -0.0040, -0.0613],\n",
            "         [-0.1212, -0.0013,  0.0306],\n",
            "         [ 0.0972,  0.1279, -0.0386]],\n",
            "\n",
            "        [[-0.0440,  0.0266,  0.1172],\n",
            "         [ 0.0067, -0.1199, -0.0506],\n",
            "         [ 0.1425,  0.1678,  0.1066]],\n",
            "\n",
            "        [[ 0.0373,  0.1412,  0.1279],\n",
            "         [ 0.0666,  0.1452, -0.0799],\n",
            "         [ 0.0280, -0.0320, -0.0280]]])\n"
          ]
        }
      ],
      "source": [
        "array = [[[-0.0653, -0.0040, -0.0613],\n",
        "         [-0.1212, -0.0013,  0.0306],\n",
        "         [ 0.0972,  0.1279, -0.0386]],\n",
        "\n",
        "        [[-0.0440,  0.0266,  0.1172],\n",
        "         [ 0.0067, -0.1199, -0.0506],\n",
        "         [ 0.1425,  0.1678,  0.1066]],\n",
        "\n",
        "        [[ 0.0373,  0.1412,  0.1279],\n",
        "         [ 0.0666,  0.1452, -0.0799],\n",
        "         [ 0.0280, -0.0320, -0.0280]]]\n",
        "tensor = torch.tensor(array)\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-10T18:26:00.797783Z",
          "iopub.status.busy": "2024-03-10T18:26:00.797079Z",
          "iopub.status.idle": "2024-03-10T18:26:00.804724Z",
          "shell.execute_reply": "2024-03-10T18:26:00.803657Z",
          "shell.execute_reply.started": "2024-03-10T18:26:00.797748Z"
        },
        "id": "OElJuFZirjvY",
        "outputId": "b5d0318f-bd84-480b-9f7f-08b5152d06ae",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-49,  -3, -46],\n",
            "         [-91,  -1,  23],\n",
            "         [ 73,  96, -29]],\n",
            "\n",
            "        [[-33,  20,  88],\n",
            "         [  5, -90, -38],\n",
            "         [107, 126,  80]],\n",
            "\n",
            "        [[ 28, 106,  96],\n",
            "         [ 50, 109, -60],\n",
            "         [ 21, -24, -21]]], dtype=torch.int8)\n"
          ]
        }
      ],
      "source": [
        "kernel0_quant = torch.quantize_per_tensor(tensor, scale = 0.0013320236466825008, zero_point = 0, dtype=torch.qint8).int_repr()\n",
        "print(kernel0_quant)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRtJOHW7QoJo"
      },
      "source": [
        "**use create feature extractor or hook to print out calibrated image data and first layer ofmap**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Lf-dsbtREeo"
      },
      "source": [
        "**do image padding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-10T18:20:17.364710Z",
          "iopub.status.busy": "2024-03-10T18:20:17.364357Z",
          "iopub.status.idle": "2024-03-10T18:20:17.407982Z",
          "shell.execute_reply": "2024-03-10T18:20:17.406918Z",
          "shell.execute_reply.started": "2024-03-10T18:20:17.364658Z"
        },
        "id": "uXocQHazyYi5",
        "outputId": "2d4511d6-bdfe-40bd-ed64-420c97cf3f83",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 3, 32, 32)\n",
            "[[[[   0.    0.    0. ...    0.    0.    0.]\n",
            "   [   0.   31.   32. ...   -2.  -12.    0.]\n",
            "   [   0.   25.   24. ...   -3.   -9.    0.]\n",
            "   ...\n",
            "   [   0.  -67.  -79. ...  -99. -108.    0.]\n",
            "   [   0.  -74.  -72. ...  -94. -107.    0.]\n",
            "   [   0.    0.    0. ...    0.    0.    0.]]\n",
            "\n",
            "  [[   0.    0.    0. ...    0.    0.    0.]\n",
            "   [   0.  -16.  -17. ...  -37.  -43.    0.]\n",
            "   [   0.  -16.  -18. ...  -37.  -40.    0.]\n",
            "   ...\n",
            "   [   0.  -12.  -26. ...  -46.  -64.    0.]\n",
            "   [   0.  -21.  -23. ...  -44.  -61.    0.]\n",
            "   [   0.    0.    0. ...    0.    0.    0.]]\n",
            "\n",
            "  [[   0.    0.    0. ...    0.    0.    0.]\n",
            "   [   0.  -79.  -81. ...  -92.  -95.    0.]\n",
            "   [   0.  -77.  -88. ...  -96.  -94.    0.]\n",
            "   ...\n",
            "   [   0.   41.   21. ...   -2.  -21.    0.]\n",
            "   [   0.   33.   22. ...    2.  -18.    0.]\n",
            "   [   0.    0.    0. ...    0.    0.    0.]]]]\n"
          ]
        }
      ],
      "source": [
        "model_ofmap = create_feature_extractor(quantized_model, [\"quantize_per_tensor\"])\n",
        "ofmap = model_ofmap(images)\n",
        "input_layer = ofmap['quantize_per_tensor'].int_repr().numpy()\n",
        "print(input_layer.shape)\n",
        "\n",
        "(batch, channel, row, col) = input_layer.shape\n",
        "new_row = 2*1 + row\n",
        "new_col = 2*1 + col\n",
        "#image = image.astype(\"float16\")\n",
        "#print(format)\n",
        "input_layer_pad = np.zeros((batch,channel,new_row,new_col))\n",
        "for i in range(0,new_row):\n",
        "    for j in range(0,new_col):\n",
        "        if( i>= 1 and i<=(new_row-1-1) and j>= 1 and j<=(new_col-1-1)):\n",
        "            input_layer_pad[:,:,i,j] = input_layer[:,:,(i-1),(j-1)]\n",
        "            input_layer_pad[:,:,i,j] = input_layer_pad[:,:,i,j] - 128\n",
        "        else:\n",
        "            input_layer_pad[:,:,i,j] = 0\n",
        "print(input_layer_pad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQzrroQMSo0q"
      },
      "source": [
        "**turn to numpy if you need to compute the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-10T18:20:17.409524Z",
          "iopub.status.busy": "2024-03-10T18:20:17.409223Z",
          "iopub.status.idle": "2024-03-10T18:20:17.436551Z",
          "shell.execute_reply": "2024-03-10T18:20:17.435467Z",
          "shell.execute_reply.started": "2024-03-10T18:20:17.409499Z"
        },
        "id": "rDkVbKio3gqK",
        "outputId": "a621ab21-bc02-429f-f5fd-38d02fabc0cd",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 64, 32, 32)\n"
          ]
        }
      ],
      "source": [
        "model_ofmap = create_feature_extractor(quantized_model, [\"conv1\"])\n",
        "ofmap = model_ofmap(images)\n",
        "conv1_layer = ofmap['conv1'].int_repr().numpy()\n",
        "print(conv1_layer.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2cYNVYOtn82"
      },
      "source": [
        "**2. PTQ model size 14.750436 MB**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T18:20:17.440254Z",
          "iopub.status.busy": "2024-03-10T18:20:17.439646Z",
          "iopub.status.idle": "2024-03-10T18:20:17.572183Z",
          "shell.execute_reply": "2024-03-10T18:20:17.570934Z",
          "shell.execute_reply.started": "2024-03-10T18:20:17.440225Z"
        },
        "trusted": true,
        "id": "-n9GgBvotn9D",
        "outputId": "d8137316-7d04-4f0e-8b39-a3f136b1bd07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the int8 model(MB): 14.750436\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "torch.save(quantized_model.state_dict(), \"PTQ_model.p\")\n",
        "print('Size of the int8 model(MB):', os.path.getsize(\"PTQ_model.p\")/1e6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4pJmuxN_a3Z"
      },
      "source": [
        "# **QAT : Do Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-10T18:20:17.574975Z",
          "iopub.status.busy": "2024-03-10T18:20:17.573964Z",
          "iopub.status.idle": "2024-03-10T18:20:17.742188Z",
          "shell.execute_reply": "2024-03-10T18:20:17.741223Z",
          "shell.execute_reply.started": "2024-03-10T18:20:17.574944Z"
        },
        "id": "PMO-Sz86UFY7",
        "outputId": "1392fffa-2e98-45e6-f322-148b4d8a9a48",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GraphModule(\n",
              "  (activation_post_process_0): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "  (conv1): ConvReLU2d(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (activation_post_process_1): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "  (conv2): ConvReLU2d(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (activation_post_process_2): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (activation_post_process_3): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "  (conv3): ConvReLU2d(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (activation_post_process_4): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "  (conv4): ConvReLU2d(\n",
              "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (activation_post_process_5): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "  (activation_post_process_6): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "  (conv5): ConvReLU2d(\n",
              "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (activation_post_process_7): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "  (conv6): ConvReLU2d(\n",
              "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (activation_post_process_8): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "  (conv7): ConvReLU2d(\n",
              "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (activation_post_process_9): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "  (activation_post_process_10): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "  (conv8): ConvReLU2d(\n",
              "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (activation_post_process_11): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "  (conv9): ConvReLU2d(\n",
              "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (activation_post_process_12): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "  (conv10): ConvReLU2d(\n",
              "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (activation_post_process_13): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "  (activation_post_process_14): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "  (conv11): ConvReLU2d(\n",
              "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (activation_post_process_15): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "  (conv12): ConvReLU2d(\n",
              "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (activation_post_process_16): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "  (conv13): ConvReLU2d(\n",
              "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (activation_post_process_17): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "  (activation_post_process_18): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "  (activation_post_process_19): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "  (classifier2): Linear(in_features=512, out_features=10, bias=True)\n",
              "  (activation_post_process_20): HistogramObserver(min_val=inf, max_val=-inf)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "model_to_quantize.train()\n",
        "prepared_model_QAT = prepare_fx(model_to_quantize, qconfig_mapping, example_inputs) # prepare to quantize model (fuse module (ex:CONV+BN+RELU...)，insert observer)\n",
        "prepared_model_QAT.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-10T18:20:17.744254Z",
          "iopub.status.busy": "2024-03-10T18:20:17.743873Z",
          "iopub.status.idle": "2024-03-10T18:22:01.221511Z",
          "shell.execute_reply": "2024-03-10T18:22:01.220295Z",
          "shell.execute_reply.started": "2024-03-10T18:20:17.744202Z"
        },
        "id": "OsBR_cWS_YoV",
        "outputId": "29f93525-151d-443b-d23b-773a1826d20b",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] Training loss: 2.304\n",
            "Correct train: 171 Total train: 1600 Train accu: 10.6875 \n",
            "[1,   200] Training loss: 2.305\n",
            "Correct train: 158 Total train: 1600 Train accu: 9.875 \n",
            "[1,   300] Training loss: 2.304\n",
            "Correct train: 170 Total train: 1600 Train accu: 10.625 \n",
            "[1,   400] Training loss: 2.303\n",
            "Correct train: 148 Total train: 1600 Train accu: 9.25 \n",
            "[1,   500] Training loss: 2.302\n",
            "Correct train: 171 Total train: 1600 Train accu: 10.6875 \n",
            "[1,   600] Training loss: 2.305\n",
            "Correct train: 151 Total train: 1600 Train accu: 9.4375 \n",
            "[1,   700] Training loss: 2.305\n",
            "Correct train: 149 Total train: 1600 Train accu: 9.3125 \n",
            "[1,   800] Training loss: 2.305\n",
            "Correct train: 149 Total train: 1600 Train accu: 9.3125 \n",
            "[1,   900] Training loss: 2.306\n",
            "Correct train: 144 Total train: 1600 Train accu: 9.0 \n",
            "[1,  1000] Training loss: 2.304\n",
            "Correct train: 152 Total train: 1600 Train accu: 9.5 \n",
            "[1,  1100] Training loss: 2.305\n",
            "Correct train: 162 Total train: 1600 Train accu: 10.125 \n",
            "[1,  1200] Training loss: 2.303\n",
            "Correct train: 169 Total train: 1600 Train accu: 10.5625 \n",
            "[1,  1300] Training loss: 2.303\n",
            "Correct train: 180 Total train: 1600 Train accu: 11.25 \n",
            "[1,  1400] Training loss: 2.305\n",
            "Correct train: 147 Total train: 1600 Train accu: 9.1875 \n",
            "[1,  1500] Training loss: 2.303\n",
            "Correct train: 172 Total train: 1600 Train accu: 10.75 \n",
            "[1,  1600] Training loss: 2.303\n",
            "Correct train: 150 Total train: 1600 Train accu: 9.375 \n",
            "[1,  1700] Training loss: 2.303\n",
            "Correct train: 165 Total train: 1600 Train accu: 10.3125 \n",
            "[1,  1800] Training loss: 2.307\n",
            "Correct train: 142 Total train: 1600 Train accu: 8.875 \n",
            "[1,  1900] Training loss: 2.305\n",
            "Correct train: 151 Total train: 1600 Train accu: 9.4375 \n",
            "[1,  2000] Training loss: 2.304\n",
            "Correct train: 173 Total train: 1600 Train accu: 10.8125 \n",
            "[1,  2100] Training loss: 2.304\n",
            "Correct train: 151 Total train: 1600 Train accu: 9.4375 \n",
            "[1,  2200] Training loss: 2.304\n",
            "Correct train: 170 Total train: 1600 Train accu: 10.625 \n",
            "[1,  2300] Training loss: 2.304\n",
            "Correct train: 159 Total train: 1600 Train accu: 9.9375 \n",
            "[1,  2400] Training loss: 2.302\n",
            "Correct train: 188 Total train: 1600 Train accu: 11.75 \n",
            "[1,  2500] Training loss: 2.303\n",
            "Correct train: 179 Total train: 1600 Train accu: 11.1875 \n",
            "[1,   100] validation loss: 2.303\n",
            "Correct validation: 190 Total validation: 1600 validation accu: 11.875 \n",
            "[1,   200] validation loss: 2.303\n",
            "Correct validation: 165 Total validation: 1600 validation accu: 10.3125 \n",
            "[1,   300] validation loss: 2.304\n",
            "Correct validation: 157 Total validation: 1600 validation accu: 9.8125 \n",
            "[1,   400] validation loss: 2.306\n",
            "Correct validation: 148 Total validation: 1600 validation accu: 9.25 \n",
            "[1,   500] validation loss: 2.308\n",
            "Correct validation: 153 Total validation: 1600 validation accu: 9.5625 \n",
            "[1,   600] validation loss: 2.304\n",
            "Correct validation: 169 Total validation: 1600 validation accu: 10.5625 \n",
            "Finished \n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "LR = 0.01\n",
        "n_epoch_QAT = 1\n",
        "optimizer = optim.SGD(model_to_quantize.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "train_loss = []\n",
        "train_accu = []\n",
        "total_train = 0\n",
        "correct_train = 0\n",
        "\n",
        "train_loss_compare=[]\n",
        "train_accu_compare=[]\n",
        "val_loss = []\n",
        "val_accu = []\n",
        "total_val = 0\n",
        "correct_val = 0\n",
        "for epoch in range(n_epoch_QAT):  # loop over the dataset multiple times]\n",
        "    running_loss_train = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        if use_gpu:\n",
        "            inputs, labels = inputs.cuda(),labels.cuda()\n",
        "            #print(\"gpu\")\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad() #reset gradient\n",
        "        # forward + backward + optimize\n",
        "        # compute gradient and do SGD steps\n",
        "        outputs = prepared_model_QAT(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step() #更新權重\n",
        "        #將data傳入model進行forward propagation\n",
        "        #計算loss\n",
        "        #清空前一次的gradient\n",
        "        #根據loss進行back propagation，計算gradient\n",
        "        #做gradient descent\n",
        "        _, predicted = torch.max(outputs.data, 1) #不加_returen數值,加return位置\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "        accu = 100.*correct_train/total_train\n",
        "        # print statistics\n",
        "        running_loss_train += loss.item()\n",
        "        if ( (i >= 1875) and (i <= 2500) ):\n",
        "            train_accu_compare.append(accu)\n",
        "            train_loss_compare.append(loss.item())\n",
        "        #print(\"count %d\" %(i) )\n",
        "        if i % 100 ==99:   # print every 100 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] Training loss: {running_loss_train / 100:.3f}')\n",
        "            print(f'Correct train: {correct_train} Total train: {total_train} Train accu: {accu} ')\n",
        "            train_loss.append(loss.item())\n",
        "            train_accu.append(accu)\n",
        "            running_loss_train = 0.0\n",
        "            total_train = 0\n",
        "            correct_train = 0\n",
        "        i += 1\n",
        "\n",
        "    running_loss_val = 0.0\n",
        "    for i, data in enumerate(val_loader, 0):\n",
        "        inputs, labels = data\n",
        "        if use_gpu:\n",
        "            inputs, labels = inputs.cuda(),labels.cuda()\n",
        "        outputs = prepared_model_QAT(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1) #不加_returen數值,加return位置\n",
        "        total_val += labels.size(0)\n",
        "        correct_val += (predicted == labels).sum().item()\n",
        "        accu = 100.*correct_val/total_val\n",
        "        # print statistics\n",
        "        running_loss_val += loss.item()\n",
        "        val_accu.append(accu)\n",
        "        #print(\"count %d\" %(i) )\n",
        "        if i % 100 ==99:   # print every 100 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] validation loss: {running_loss_val / 100:.3f}')\n",
        "            print(f'Correct validation: {correct_val} Total validation: {total_val} validation accu: {accu} ')\n",
        "            running_loss_val = 0.0\n",
        "            total_val = 0\n",
        "            correct_val = 0\n",
        "        i += 1\n",
        "\n",
        "print('Finished ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-10T18:22:01.224010Z",
          "iopub.status.busy": "2024-03-10T18:22:01.223533Z",
          "iopub.status.idle": "2024-03-10T18:22:01.234325Z",
          "shell.execute_reply": "2024-03-10T18:22:01.233528Z",
          "shell.execute_reply.started": "2024-03-10T18:22:01.223966Z"
        },
        "id": "Jk9f8WcoJHF4",
        "outputId": "63c99481-a86e-49b9-eb34-e30606988f11",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GraphModule(\n",
              "  (activation_post_process_0): HistogramObserver(min_val=-1.0, max_val=1.0)\n",
              "  (conv1): ConvReLU2d(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (activation_post_process_1): HistogramObserver(min_val=0.0, max_val=1.5611714124679565)\n",
              "  (conv2): ConvReLU2d(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (activation_post_process_2): HistogramObserver(min_val=0.0, max_val=0.6222428679466248)\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (activation_post_process_3): HistogramObserver(min_val=0.0, max_val=0.6222428679466248)\n",
              "  (conv3): ConvReLU2d(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (activation_post_process_4): HistogramObserver(min_val=0.0, max_val=0.22827841341495514)\n",
              "  (conv4): ConvReLU2d(\n",
              "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (activation_post_process_5): HistogramObserver(min_val=0.0, max_val=0.09949850291013718)\n",
              "  (activation_post_process_6): HistogramObserver(min_val=0.0, max_val=0.09949850291013718)\n",
              "  (conv5): ConvReLU2d(\n",
              "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (activation_post_process_7): HistogramObserver(min_val=0.0, max_val=0.05288086459040642)\n",
              "  (conv6): ConvReLU2d(\n",
              "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (activation_post_process_8): HistogramObserver(min_val=0.0, max_val=0.03608258441090584)\n",
              "  (conv7): ConvReLU2d(\n",
              "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (activation_post_process_9): HistogramObserver(min_val=0.0, max_val=0.029498321935534477)\n",
              "  (activation_post_process_10): HistogramObserver(min_val=0.0, max_val=0.029498321935534477)\n",
              "  (conv8): ConvReLU2d(\n",
              "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (activation_post_process_11): HistogramObserver(min_val=0.0, max_val=0.025077851489186287)\n",
              "  (conv9): ConvReLU2d(\n",
              "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (activation_post_process_12): HistogramObserver(min_val=0.0, max_val=0.020307471975684166)\n",
              "  (conv10): ConvReLU2d(\n",
              "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (activation_post_process_13): HistogramObserver(min_val=0.0, max_val=0.01830938085913658)\n",
              "  (activation_post_process_14): HistogramObserver(min_val=0.0, max_val=0.01830938085913658)\n",
              "  (conv11): ConvReLU2d(\n",
              "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (activation_post_process_15): HistogramObserver(min_val=0.0, max_val=0.016911687329411507)\n",
              "  (conv12): ConvReLU2d(\n",
              "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (activation_post_process_16): HistogramObserver(min_val=0.0, max_val=0.015933044254779816)\n",
              "  (conv13): ConvReLU2d(\n",
              "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (activation_post_process_17): HistogramObserver(min_val=0.0, max_val=0.01529146172106266)\n",
              "  (activation_post_process_18): HistogramObserver(min_val=0.0, max_val=0.01529146172106266)\n",
              "  (activation_post_process_19): HistogramObserver(min_val=0.0, max_val=0.01529146172106266)\n",
              "  (classifier2): Linear(in_features=512, out_features=10, bias=True)\n",
              "  (activation_post_process_20): HistogramObserver(min_val=-0.1790921986103058, max_val=0.2344132363796234)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "prepared_model_QAT.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T18:22:01.235612Z",
          "iopub.status.busy": "2024-03-10T18:22:01.235320Z",
          "iopub.status.idle": "2024-03-10T18:22:01.809641Z",
          "shell.execute_reply": "2024-03-10T18:22:01.808543Z",
          "shell.execute_reply.started": "2024-03-10T18:22:01.235576Z"
        },
        "id": "qP6Ngr-6JMKp",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "QAT_model = convert_fx(prepared_model_QAT) # convert the calibrated model to a quantized model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-10T18:22:01.812134Z",
          "iopub.status.busy": "2024-03-10T18:22:01.811646Z",
          "iopub.status.idle": "2024-03-10T18:22:01.818247Z",
          "shell.execute_reply": "2024-03-10T18:22:01.817204Z",
          "shell.execute_reply.started": "2024-03-10T18:22:01.812095Z"
        },
        "id": "kBtv3JJ2JXmw",
        "outputId": "a8420ecc-7891-4c0a-a584-d59f4380e833",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GraphModule(\n",
            "  (conv1): QuantizedConvReLU2d(3, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.005034108646214008, zero_point=0, padding=(1, 1))\n",
            "  (conv2): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.0015834880759939551, zero_point=0, padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): QuantizedConvReLU2d(64, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.0006154565489850938, zero_point=0, padding=(1, 1))\n",
            "  (conv4): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.0002648263762239367, zero_point=0, padding=(1, 1))\n",
            "  (conv5): QuantizedConvReLU2d(128, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.00014976027887314558, zero_point=0, padding=(1, 1))\n",
            "  (conv6): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.00011704178177751601, zero_point=0, padding=(1, 1))\n",
            "  (conv7): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.00010579496301943436, zero_point=0, padding=(1, 1))\n",
            "  (conv8): QuantizedConvReLU2d(256, 512, kernel_size=(3, 3), stride=(1, 1), scale=9.368659812025726e-05, zero_point=0, padding=(1, 1))\n",
            "  (conv9): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=7.539864600403234e-05, zero_point=0, padding=(1, 1))\n",
            "  (conv10): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=6.857603875687346e-05, zero_point=0, padding=(1, 1))\n",
            "  (conv11): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=6.372970528900623e-05, zero_point=0, padding=(1, 1))\n",
            "  (conv12): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=5.781464642495848e-05, zero_point=0, padding=(1, 1))\n",
            "  (conv13): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=5.1709408580791205e-05, zero_point=0, padding=(1, 1))\n",
            "  (classifier2): QuantizedLinear(in_features=512, out_features=10, scale=0.00133337767329067, zero_point=134, qscheme=torch.per_tensor_affine)\n",
            ")\n",
            "\n",
            "\n",
            "\n",
            "def forward(self, x):\n",
            "    conv1_input_scale_0 = self.conv1_input_scale_0\n",
            "    conv1_input_zero_point_0 = self.conv1_input_zero_point_0\n",
            "    quantize_per_tensor = torch.quantize_per_tensor(x, conv1_input_scale_0, conv1_input_zero_point_0, torch.quint8);  x = conv1_input_scale_0 = conv1_input_zero_point_0 = None\n",
            "    conv1 = self.conv1(quantize_per_tensor);  quantize_per_tensor = None\n",
            "    conv2 = self.conv2(conv1);  conv1 = None\n",
            "    pool = self.pool(conv2);  conv2 = None\n",
            "    conv3 = self.conv3(pool);  pool = None\n",
            "    conv4 = self.conv4(conv3);  conv3 = None\n",
            "    pool_1 = self.pool(conv4);  conv4 = None\n",
            "    conv5 = self.conv5(pool_1);  pool_1 = None\n",
            "    conv6 = self.conv6(conv5);  conv5 = None\n",
            "    conv7 = self.conv7(conv6);  conv6 = None\n",
            "    pool_2 = self.pool(conv7);  conv7 = None\n",
            "    conv8 = self.conv8(pool_2);  pool_2 = None\n",
            "    conv9 = self.conv9(conv8);  conv8 = None\n",
            "    conv10 = self.conv10(conv9);  conv9 = None\n",
            "    pool_3 = self.pool(conv10);  conv10 = None\n",
            "    conv11 = self.conv11(pool_3);  pool_3 = None\n",
            "    conv12 = self.conv12(conv11);  conv11 = None\n",
            "    conv13 = self.conv13(conv12);  conv12 = None\n",
            "    pool_4 = self.pool(conv13);  conv13 = None\n",
            "    size = pool_4.size(0)\n",
            "    reshape = pool_4.reshape(size, -1);  pool_4 = size = None\n",
            "    classifier2 = self.classifier2(reshape);  reshape = None\n",
            "    dequantize_20 = classifier2.dequantize();  classifier2 = None\n",
            "    return dequantize_20\n",
            "    \n",
            "# To see more debug info, please use `graph_module.print_readable()`\n"
          ]
        }
      ],
      "source": [
        "print(QAT_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TUBm3Zptn9F"
      },
      "source": [
        "**3. QAT model size 14.751396 MB**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-10T18:22:01.823793Z",
          "iopub.status.busy": "2024-03-10T18:22:01.823428Z",
          "iopub.status.idle": "2024-03-10T18:22:01.892510Z",
          "shell.execute_reply": "2024-03-10T18:22:01.891513Z",
          "shell.execute_reply.started": "2024-03-10T18:22:01.823769Z"
        },
        "id": "xZnPHeKQqvOo",
        "outputId": "fa1f069d-5666-44a3-c03c-47cee0a6c2be",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the int8 model(MB): 14.751396\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "torch.save(QAT_model.state_dict(), \"QAT_model.p\")\n",
        "print('Size of the int8 model(MB):', os.path.getsize(\"QAT_model.p\")/1e6)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30665,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}